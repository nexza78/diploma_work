{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import cai.util\n",
    "import cai.models\n",
    "import cai.layers\n",
    "\n",
    "import math\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "import tensorflow\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DepthwiseConv3D import DepthwiseConv3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaaaaaaaaaaaaaa\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([5, 30, 30, 30, 5])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = np.random.rand(5, 32, 32, 32, 5)\n",
    "x = DepthwiseConv3D(kernel_size=(3,3,3), depth_multiplier=1, padding='valid')(input)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_pad3d(backend, inputs, kernel_size):\n",
    "    \"\"\"Returns a tuple for zero-padding for 3D convolution with downsampling.\n",
    "    # Arguments\n",
    "        input_size: An integer or tuple/list of 3 integers.\n",
    "        kernel_size: An integer or tuple/list of 3 integers.\n",
    "    # Returns\n",
    "        A tuple.\n",
    "    \"\"\"\n",
    "    #A string, either 'channels_first' or 'channels_last'\n",
    "    img_dim = 1 # 2 if backend.image_data_format() == 'channels_first' else 1\n",
    "    #Returns the shape of tensor or variable as a tuple of int or None entries.\n",
    "    #извлечение чисел - d1, d2, d3\n",
    "    input_size = backend.int_shape(inputs)[img_dim:(img_dim + 3)]\n",
    "    print(input_size)\n",
    "\n",
    "    if isinstance(kernel_size, int):\n",
    "        kernel_size = (kernel_size, kernel_size, kernel_size)\n",
    "    \n",
    "    if input_size[0] is None:\n",
    "        adjust = (1, 1, 1)\n",
    "    else:\n",
    "        adjust = (1 - input_size[0] % 2, 1 - input_size[1] % 2, 1 - input_size[2] % 2)\n",
    "\n",
    "    correct = (kernel_size[0] // 2, kernel_size[1] // 2, kernel_size[2] // 2)\n",
    "\n",
    "    return ((correct[0] - adjust[0], correct[0]),\n",
    "            (correct[1] - adjust[1], correct[1]),\n",
    "            (correct[2] - adjust[2], correct[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONV_KERNEL_INITIALIZER = {\n",
    "    'class_name': 'VarianceScaling',\n",
    "    'config': {\n",
    "        'scale': 2.0,\n",
    "        'mode': 'fan_out',\n",
    "        # EfficientNet actually uses an untruncated normal distribution for\n",
    "        # initializing conv layers, but keras.initializers.VarianceScaling use\n",
    "        # a truncated distribution.\n",
    "        # We decided against a custom initializer for better serializability.\n",
    "        'distribution': 'normal'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_BLOCKS_ARGS = [\n",
    "    {'kernel_size': 3, 'repeats': 1, 'filters_in': 32, 'filters_out': 16,\n",
    "     'expand_ratio': 1, 'id_skip': True, 'strides': 1, 'se_ratio': 0.25},\n",
    "    {'kernel_size': 3, 'repeats': 2, 'filters_in': 16, 'filters_out': 24,\n",
    "     'expand_ratio': 6, 'id_skip': True, 'strides': 2, 'se_ratio': 0.25},\n",
    "    {'kernel_size': 5, 'repeats': 2, 'filters_in': 24, 'filters_out': 40,\n",
    "     'expand_ratio': 6, 'id_skip': True, 'strides': 2, 'se_ratio': 0.25},\n",
    "    {'kernel_size': 3, 'repeats': 3, 'filters_in': 40, 'filters_out': 80,\n",
    "     'expand_ratio': 6, 'id_skip': True, 'strides': 2, 'se_ratio': 0.25},\n",
    "    {'kernel_size': 5, 'repeats': 3, 'filters_in': 80, 'filters_out': 112,\n",
    "     'expand_ratio': 6, 'id_skip': True, 'strides': 1, 'se_ratio': 0.25},\n",
    "    {'kernel_size': 5, 'repeats': 4, 'filters_in': 112, 'filters_out': 192,\n",
    "     'expand_ratio': 6, 'id_skip': True, 'strides': 2, 'se_ratio': 0.25},\n",
    "    {'kernel_size': 3, 'repeats': 1, 'filters_in': 192, 'filters_out': 320,\n",
    "     'expand_ratio': 6, 'id_skip': True, 'strides': 1, 'se_ratio': 0.25}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swish(x):\n",
    "    \"\"\"Swish activation function.\n",
    "    # Arguments\n",
    "        x: Input tensor.\n",
    "    # Returns\n",
    "        The Swish activation: `x * sigmoid(x)`.\n",
    "    # References\n",
    "        [Searching for Activation Functions](https://arxiv.org/abs/1710.05941)\n",
    "    \"\"\"\n",
    "    if backend.backend() == 'tensorflow':\n",
    "        try:\n",
    "            # The native TF implementation has a more\n",
    "            # memory-efficient gradient implementation\n",
    "            return backend.tf.nn.swish(x)\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "    return x * backend.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = np.random.rand(30, 32, 32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([30, 30, 30, 3])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = layers.DepthwiseConv2D(kernel_size=(3,3), depth_multiplier=1, padding='valid')(inp)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def D6_32ch(): return 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3d_bn(x,\n",
    "    filters,\n",
    "    num_d1,\n",
    "    num_d2,\n",
    "    num_d3,\n",
    "    padding='same',\n",
    "    strides=(1, 1, 1),\n",
    "    name=None,\n",
    "    use_bias=False,\n",
    "    activation='relu', \n",
    "    has_batch_norm=True,\n",
    "    has_batch_scale=False,  \n",
    "    groups=0,\n",
    "    kernel_initializer=\"glorot_uniform\",\n",
    "    kernel_regularizer=None\n",
    "    ):\n",
    "    \"\"\"Practical Conv3D wrapper.\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        filters: filters in `Conv3D`.\n",
    "        num_row: height of the convolution kernel.\n",
    "        num_col: width of the convolution kernel.\n",
    "        padding: padding mode in `Conv3D`.\n",
    "        strides: strides in `Conv3D`.\n",
    "        name: name of the ops; will become `name + '_conv'`\n",
    "            for the convolution and `name + '_bn'` for the\n",
    "            batch norm layer.\n",
    "        use_bias: True means that bias will be added,\n",
    "        activation: activation function. None means no activation function. \n",
    "        has_batch_norm: True means that batch normalization is added.\n",
    "        has_batch_scale: True means that scaling is added to batch norm.\n",
    "        groups: number of groups in the convolution\n",
    "        kernel_initializer: this is a very big open question.\n",
    "        kernel_regularizer: a conservative L2 may be a good idea.\n",
    "    # Returns\n",
    "        Output tensor after applying `Conv3D` and `BatchNormalization`.\n",
    "    \"\"\"\n",
    "    if name is not None:\n",
    "        bn_name = name + '_bn'\n",
    "        conv_name = name + '_conv'\n",
    "    else:\n",
    "        bn_name = None\n",
    "        conv_name = None\n",
    "    if tensorflow.keras.backend.image_data_format() == 'channels_first':\n",
    "        bn_axis = 1\n",
    "    else:\n",
    "        bn_axis = 4\n",
    "\n",
    "    # groups parameter isn't available in older tensorflow implementations\n",
    "    if (groups>1) :\n",
    "        x = tensorflow.keras.layers.Conv3D(\n",
    "            filters, (num_d1, num_d2, num_d3),\n",
    "            strides=strides,\n",
    "            padding=padding,\n",
    "            use_bias=use_bias,\n",
    "            groups=groups,\n",
    "            name=conv_name,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            kernel_regularizer=kernel_regularizer)(x)\n",
    "    else:\n",
    "        x = tensorflow.keras.layers.Conv3D(\n",
    "            filters, (num_d1, num_d2, num_d3),\n",
    "            strides=strides,\n",
    "            padding=padding,\n",
    "            use_bias=use_bias,\n",
    "            name=conv_name,\n",
    "            kernel_initializer=kernel_initializer,\n",
    "            kernel_regularizer=kernel_regularizer)(x)\n",
    "\n",
    "    if (has_batch_norm): x = tensorflow.keras.layers.BatchNormalization(axis=bn_axis, scale=has_batch_scale, name=bn_name)(x)\n",
    "    if activation is not None: x = tensorflow.keras.layers.Activation(activation=activation, name=name)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kConv3DType2(last_tensor, filters=32, channel_axis=4, name=None, activation=None, has_batch_norm=True, has_batch_scale=True, use_bias=True, min_channels_per_group=16, kernel_size=1, stride_size=1, padding='same'):\n",
    "    \"\"\"\n",
    "    This ktype is composed by a grouped convolution followed by interleaving and another grouped comvolution with skip connection. This basic architecture can\n",
    "    vary according to the input tensor and its parameters. This is the basic building block for the papers:\n",
    "    https://www.researchgate.net/publication/360226228_Grouped_Pointwise_Convolutions_Reduce_Parameters_in_Convolutional_Neural_Networks\n",
    "    https://www.researchgate.net/publication/355214501_Grouped_Pointwise_Convolutions_Significantly_Reduces_Parameters_in_EfficientNet\n",
    "    \"\"\"\n",
    "    output_tensor = last_tensor\n",
    "    prev_layer_channel_count = tensorflow.keras.backend.int_shape(last_tensor)[channel_axis]\n",
    "    output_channel_count = filters\n",
    "    max_acceptable_divisor = (prev_layer_channel_count//min_channels_per_group)\n",
    "    group_count = cai.util.get_max_acceptable_common_divisor(prev_layer_channel_count, output_channel_count, max_acceptable = max_acceptable_divisor)\n",
    "    if group_count is None: group_count=1\n",
    "    output_group_size = output_channel_count // group_count\n",
    "    # input_group_size = prev_layer_channel_count // group_count\n",
    "    if (group_count>1):\n",
    "        print ('Input channels:', prev_layer_channel_count, 'Output Channels:',output_channel_count,'Groups:', group_count, 'Input channels per group:', input_group_size, 'Output channels per group:', output_group_size)\n",
    "        output_tensor = conv3d_bn(output_tensor, output_channel_count, kernel_size, kernel_size, kernel_size, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, groups=group_count, use_bias=use_bias, strides=(stride_size, stride_size), padding=padding)\n",
    "        compression_tensor = output_tensor\n",
    "        if output_group_size > 1:\n",
    "            output_tensor = cai.layers.InterleaveChannels(output_group_size, name=name+'_group_interleaved')(output_tensor)\n",
    "        if (prev_layer_channel_count >= output_channel_count):\n",
    "            print('Has intergroup')\n",
    "            output_tensor = conv3d_bn(output_tensor, output_channel_count, 1, 1, 1, name=name+'_group_interconn', activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, groups=group_count, use_bias=use_bias)\n",
    "            output_tensor = tensorflow.keras.layers.add([output_tensor, compression_tensor], name=name+'_inter_group_add')\n",
    "    else:\n",
    "        #print ('Dismissed groups:', group_count, 'Input channels:', prev_layer_channel_count, 'Output Channels:', output_channel_count, 'Input channels per group:', input_group_size, 'Output channels per group:', output_group_size)\n",
    "        output_tensor = conv3d_bn(output_tensor, output_channel_count, kernel_size, kernel_size, kernel_size, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias)\n",
    "    return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def kConv3D(last_tensor, filters=32, channel_axis=4, name=None, activation=None, has_batch_norm=True, has_batch_scale=True, use_bias=True, kernel_size=1, stride_size=1, padding='same', kType=2):\n",
    "    prev_layer_channel_count = tensorflow.keras.backend.int_shape(last_tensor)[channel_axis]\n",
    "    if kType == D6_32ch():\n",
    "        return kConv3DType2(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kPointwiseConv3D(last_tensor, filters=32, channel_axis=4, name=None, activation=None, has_batch_norm=True, has_batch_scale=True, use_bias=True, kType=2):\n",
    "    \"\"\"\n",
    "    Parameter efficient pointwise convolution as shown in these papers:\n",
    "    https://www.researchgate.net/publication/360226228_Grouped_Pointwise_Convolutions_Reduce_Parameters_in_Convolutional_Neural_Networks\n",
    "    https://www.researchgate.net/publication/363413038_An_Enhanced_Scheme_for_Reducing_the_Complexity_of_Pointwise_Convolutions_in_CNNs_for_Image_Classification_Based_on_Interleaved_Grouped_Filters_without_Divisibility_Constraints\n",
    "    \"\"\"\n",
    "    return kConv3D(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=1, stride_size=1, padding='same', kType=kType)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kblock(inputs, activation_fn=swish, drop_rate=0., name='',\n",
    "          filters_in=32, filters_out=16, kernel_size=3, strides=1,\n",
    "          expand_ratio=1, se_ratio=0., id_skip=True, kType=1,\n",
    "          dropout_all_blocks=False):\n",
    "    \"\"\"A mobile inverted residual block.\n",
    "    # Arguments\n",
    "        inputs: input tensor.\n",
    "        activation_fn: activation function.\n",
    "        drop_rate: float between 0 and 1, fraction of the input units to drop.\n",
    "        name: string, block label.\n",
    "        filters_in: integer, the number of input filters.\n",
    "        filters_out: integer, the number of output filters.\n",
    "        kernel_size: integer, the dimension of the convolution window.\n",
    "        strides: integer, the stride of the convolution.\n",
    "        expand_ratio: integer, scaling coefficient for the input filters.\n",
    "        se_ratio: float between 0 and 1, fraction to squeeze the input filters.\n",
    "        id_skip: boolean.\n",
    "    # Returns\n",
    "        output tensor for the block.\n",
    "    \"\"\"\n",
    "    bn_axis = 4\n",
    "\n",
    "    # Expansion phase\n",
    "    filters = filters_in * expand_ratio\n",
    "    \n",
    "    if expand_ratio != 1:\n",
    "        #x = layers.Conv2D(filters, 1,\n",
    "        #                 padding='same',\n",
    "        #                  use_bias=False,\n",
    "        #                  kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "        #                  name=name + 'expand_conv')(inputs)\n",
    "        #x = layers.BatchNormalization(axis=bn_axis, name=name + 'expand_bn')(x)\n",
    "        #x = layers.Activation(activation_fn, name=name + 'expand_activation')(x)\n",
    "        x = cai.layers.kPointwiseConv2D(last_tensor=inputs, filters=filters, channel_axis=bn_axis, name=name+'expand', activation=activation_fn, has_batch_norm=True, use_bias=False, kType=kType)\n",
    "    else:\n",
    "        x = inputs\n",
    "\n",
    "    # Depthwise Convolution\n",
    "    if strides == 2:\n",
    "        x = layers.ZeroPadding3D(padding=correct_pad(backend, x, kernel_size),\n",
    "                                 name=name + 'dwconv_pad3d')(x)\n",
    "        conv_pad = 'valid'\n",
    "    else:\n",
    "        conv_pad = 'same'\n",
    "    x = DepthwiseConv3D(kernel_size,\n",
    "                               strides=strides,\n",
    "                               padding=conv_pad,\n",
    "                               use_bias=False,\n",
    "                               depthwise_initializer=CONV_KERNEL_INITIALIZER,\n",
    "                               name=name + 'dwconv')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name=name + 'bn')(x)\n",
    "    x = layers.Activation(activation_fn, name=name + 'activation')(x)\n",
    "\n",
    "    # Squeeze and Excitation phase\n",
    "    if 0 < se_ratio <= 1:\n",
    "        filters_se = max(1, int(filters_in * se_ratio))\n",
    "        se = layers.GlobalAveragePooling3D(name=name + 'se_squeeze')(x)\n",
    "        if bn_axis == 1:\n",
    "            se = layers.Reshape((filters, 1, 1, 1), name=name + 'se_reshape')(se)\n",
    "        else:\n",
    "            se = layers.Reshape((1, 1, 1, filters), name=name + 'se_reshape')(se)\n",
    "        #se = layers.Conv2D(filters_se, 1,\n",
    "        #                   padding='same',\n",
    "        #                   activation=activation_fn,\n",
    "        #                   kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "        #                   name=name + 'se_reduce')(se)\n",
    "        se = kPointwiseConv3D(last_tensor=se, filters=filters_se, channel_axis=bn_axis, name=name+'se_reduce', activation=activation_fn, has_batch_norm=False, use_bias=True, kType=kType)\n",
    "        #se = layers.Conv2D(filters, 1,\n",
    "        #                   padding='same',\n",
    "        #                   activation='sigmoid',\n",
    "        #                   kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "        #                   name=name + 'se_expand')(se)\n",
    "        se = kPointwiseConv3D(last_tensor=se, filters=filters, channel_axis=bn_axis, name=name+'se_expand', activation='sigmoid', has_batch_norm=False, use_bias=True, kType=kType)\n",
    "        x = layers.multiply([x, se], name=name + 'se_excite')\n",
    "\n",
    "    # Output phase\n",
    "    #x = layers.Conv2D(filters_out, 1,\n",
    "    #                  padding='same',\n",
    "    #                  use_bias=False,\n",
    "    #                  kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "    #                  name=name + 'project_conv')(x)\n",
    "    # x = layers.BatchNormalization(axis=bn_axis, name=name + 'project_bn')(x)\n",
    "    x = kPointwiseConv3D(last_tensor=x, filters=filters_out, channel_axis=bn_axis, name=name+'project_conv', activation=None, has_batch_norm=True, use_bias=False, kType=kType)\n",
    "\n",
    "    if (drop_rate > 0)  and (dropout_all_blocks):\n",
    "        x = layers.Dropout(drop_rate,\n",
    "                noise_shape=(None, 1, 1, 1, 1),\n",
    "                name=name + 'drop')(x)\n",
    "\n",
    "    if (id_skip is True and strides == 1 and filters_in == filters_out):\n",
    "        if (drop_rate > 0)  and (not dropout_all_blocks):\n",
    "            x = layers.Dropout(drop_rate,\n",
    "                               noise_shape=(None, 1, 1, 1, 1),\n",
    "                               name=name + 'drop')(x)\n",
    "        x = layers.add([x, inputs], name=name + 'add')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0, 1), (0, 1), (1, 1))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_pad3d(backend, np.random.rand(32, 32, 32, 5, 3), (3, 3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import ZeroPadding3D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GlobalAverageMaxPooling2D(previous_layer,  name=None):\n",
    "    \"\"\"\n",
    "    Adds both global Average and Max poolings. This layers is known to speed up training.\n",
    "    \"\"\"\n",
    "    if name is None: name='global_pool'\n",
    "    return tensorflow.keras.layers.Concatenate(axis=1)([\n",
    "      tensorflow.keras.layers.GlobalAveragePooling3D(name=name+'_avg')(previous_layer),\n",
    "      tensorflow.keras.layers.GlobalMaxPooling3D(name=name+'_max')(previous_layer)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kEffNet3D(\n",
    "        width_coefficient,\n",
    "        depth_coefficient,\n",
    "        skip_stride_cnt=-1,\n",
    "        dropout_rate=0.2,\n",
    "        drop_connect_rate=0.2,\n",
    "        depth_divisor=8,\n",
    "        activation_fn=swish,\n",
    "        blocks_args=DEFAULT_BLOCKS_ARGS,\n",
    "        model_name='efficientnet',\n",
    "        include_top=True,\n",
    "        input_tensor=None,\n",
    "        input_shape=None,\n",
    "        pooling=None,\n",
    "        classes=1000,\n",
    "        kType=2,\n",
    "        concat_paths=True,\n",
    "        dropout_all_blocks=False,\n",
    "        name_prefix='k_',\n",
    "        **kwargs):\n",
    "    #    \"\"\"Instantiates the EfficientNet architecture using given scaling coefficients.\n",
    "    #Optionally loads weights pre-trained on ImageNet.\n",
    "    #Note that the data format convention used by the model is\n",
    "    #the one specified in your Keras config at `~/.keras/keras.json`.\n",
    "    #    # Arguments\n",
    "    #    width_coefficient: float, scaling coefficient for network width.\n",
    "    #    depth_coefficient: float, scaling coefficient for network depth.\n",
    "    #    default_size: integer, default input image size.\n",
    "    #    dropout_rate: float, dropout rate before final classifier layer.\n",
    "    #    drop_connect_rate: float, dropout rate at skip connections.\n",
    "    #    depth_divisor: integer, a unit of network width.\n",
    "    #    activation_fn: activation function.\n",
    "    #    blocks_args: list of dicts, parameters to construct block modules.\n",
    "    #    model_name: string, model name.\n",
    "    #    include_top: whether to include the fully-connected\n",
    "    #        layer at the top of the network.\n",
    "    #    input_tensor: optional Keras tensor\n",
    "    #        (i.e. output of `layers.Input()`)\n",
    "    #        to use as image input for the model.\n",
    "    #    input_shape: optional shape tuple, only to be specified\n",
    "    #        if `include_top` is False.\n",
    "    #        It should have exactly 3 inputs channels.\n",
    "    #    pooling: optional pooling mode for feature extraction\n",
    "    #        when `include_top` is `False`.\n",
    "    #        - `None` means that the output of the model will be\n",
    "    #            the 4D tensor output of the\n",
    "    #            last convolutional layer.\n",
    "    #        - `avg` means that global average pooling\n",
    "    #            will be applied to the output of the\n",
    "    #            last convolutional layer, and thus\n",
    "    #            the output of the model will be a 2D tensor.\n",
    "    #        - `max` means that global max pooling will\n",
    "    #            be applied.\n",
    "    #    classes: optional number of classes to classify images\n",
    "    #        into, only to be specified if `include_top` is True, and\n",
    "    ## Returns\n",
    "    #    A Keras model instance.\n",
    "    ## Raises\n",
    "    #    ValueError: in case of invalid input shape.\"\"\"\n",
    "\n",
    "    if input_tensor is None:\n",
    "        #Input() используется для создания экземпляра тензора Keras.\n",
    "        #shape: Кортеж фигур (целые числа), не включая размер пакета. Например, shape=(32,) указывает, что ожидаемыми входными данными будут пакеты 32-мерных векторов\n",
    "\n",
    "        img_input = layers.Input(shape=input_shape)\n",
    "    else:\n",
    "        if not backend.is_keras_tensor(input_tensor):#Returns whether x is a Keras tensor.\n",
    "            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    bn_axis = 4  #???\n",
    "\n",
    "    #кол-во round фильтров\n",
    "    def round_filters(filters, divisor=depth_divisor):\n",
    "        \"\"\"Round number of filters based on depth multiplier.\"\"\"\n",
    "        filters *= width_coefficient\n",
    "        new_filters = max(divisor, int(filters + divisor / 2) // divisor * divisor)\n",
    "        # Make sure that round down does not go down by more than 10%.\n",
    "        if new_filters < 0.9 * filters:\n",
    "            new_filters += divisor\n",
    "        return int(new_filters)\n",
    "    #кол-во повторов\n",
    "    def round_repeats(repeats):\n",
    "        \"\"\"Round number of repeats based on depth multiplier.\"\"\"\n",
    "        return int(math.ceil(depth_coefficient * repeats))\n",
    "\n",
    "    \n",
    "    if isinstance(kType, (int)):#Позволяет проверить принадлежность экземпляра к классу\n",
    "        kTypeList = [kType]\n",
    "    else:\n",
    "        kTypeList = kType\n",
    "    \n",
    "    # Build stem\n",
    "    x = img_input\n",
    "    x = layers.ZeroPadding3D(padding=correct_pad3d(backend, x, (3, 3, 3)),\n",
    "                             name=name_prefix+'stem_conv_pad3d')(x)\n",
    "\n",
    "    first_stride = 1 if skip_stride_cnt >= 0 else 2\n",
    "    x = layers.Conv3D(round_filters(32), 3,\n",
    "                      strides=first_stride,\n",
    "                      padding='valid',\n",
    "                      use_bias=False,\n",
    "                      kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "                      name=name_prefix+'stem_conv')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name=name_prefix+'stem_bn3d')(x)\n",
    "    x = layers.Activation(activation_fn, name=name_prefix+'stem_activation3d')(x)\n",
    "\n",
    "    root_layer = x\n",
    "    output_layers = []\n",
    "    path_cnt = 0\n",
    "    for kType in kTypeList:\n",
    "        x = root_layer\n",
    "        blocks_args_cp = deepcopy(blocks_args)\n",
    "        b = 0\n",
    "        blocks = float(sum(args['repeats'] for args in blocks_args_cp))\n",
    "        #only the first branch can backpropagate to the input.\n",
    "        #if path_cnt>0:\n",
    "        #    x = keras.layers.Lambda(lambda x: tensorflow.stop_gradient(x))(x)\n",
    "        for (i, args) in enumerate(blocks_args_cp):\n",
    "            assert args['repeats'] > 0\n",
    "            # Update block input and output filters based on depth multiplier.\n",
    "            args['filters_in'] = round_filters(args['filters_in'])\n",
    "            args['filters_out'] = round_filters(args['filters_out'])\n",
    "\n",
    "            for j in range(round_repeats(args.pop('repeats'))):\n",
    "                #should skip the stride\n",
    "                if (skip_stride_cnt > i) and (j == 0) and (args['strides'] > 1):\n",
    "                    args['strides'] = 1\n",
    "                # The first block needs to take care of stride and filter size increase.\n",
    "                if (j > 0):\n",
    "                    args['strides'] = 1\n",
    "                    args['filters_in'] = args['filters_out']\n",
    "                x = kblock(x, activation_fn, drop_connect_rate * b / blocks,\n",
    "                          name=name_prefix+'block{}{}_'.format(i + 1, chr(j + 97))+'_'+str(path_cnt), **args,\n",
    "                          kType=kType, dropout_all_blocks=dropout_all_blocks)\n",
    "                b += 1\n",
    "        if (len(kTypeList)>1):\n",
    "            x = layers.Activation('relu', name=name_prefix+'end_relu'+'_'+str(path_cnt))(x)\n",
    "        output_layers.append(x)\n",
    "        path_cnt = path_cnt +1\n",
    "\n",
    "    if (len(output_layers)==1):\n",
    "        x = output_layers[0]\n",
    "    else:\n",
    "        if concat_paths:\n",
    "            x = keras.layers.Concatenate(axis=bn_axis, name=name_prefix+'global_concat')(output_layers)\n",
    "        else:\n",
    "            x = keras.layers.add(output_layers, name=name_prefix+'global_add')\n",
    "\n",
    "    x = cai.layers.kPointwiseConv2D(last_tensor=x, filters=round_filters(1280), channel_axis=bn_axis, name=name_prefix+'top_conv', activation=None, has_batch_norm=True, use_bias=False, kType=kType)\n",
    "\n",
    "    if pooling == 'avg':\n",
    "        x = layers.GlobalAveragePooling3D(name=name_prefix+'avg_pool')(x)\n",
    "    elif pooling == 'max':\n",
    "        x = layers.GlobalMaxPooling3D(name=name_prefix+'max_pool')(x)\n",
    "    elif pooling == 'avgmax':\n",
    "        x = GlobalAverageMaxPooling3D(x, name=name_prefix+'avgmax_pool')\n",
    "\n",
    "    if include_top:\n",
    "        if (dropout_rate > 0):\n",
    "            x = layers.Dropout(dropout_rate, name=name_prefix+'top_dropout')(x)\n",
    "        x = layers.Dense(classes,\n",
    "            activation='softmax', # 'softmax'\n",
    "            kernel_initializer=DENSE_KERNEL_INITIALIZER,\n",
    "            name=name_prefix+'probs')(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = utils.get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "\n",
    "    # Create model.\n",
    "    model = models.Model(inputs, x, name=model_name)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Please provide to Input a `shape` or a `tensor` or a `type_spec` argument. Note that `shape` does not include the batch dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m kEffNet3D(\u001b[39m3\u001b[39;49m, \u001b[39m3\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[20], line 65\u001b[0m, in \u001b[0;36mkEffNet3D\u001b[1;34m(width_coefficient, depth_coefficient, skip_stride_cnt, dropout_rate, drop_connect_rate, depth_divisor, activation_fn, blocks_args, model_name, include_top, input_tensor, input_shape, pooling, classes, kType, concat_paths, dropout_all_blocks, name_prefix, **kwargs)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mkEffNet3D\u001b[39m(\n\u001b[0;32m      2\u001b[0m         width_coefficient,\n\u001b[0;32m      3\u001b[0m         depth_coefficient,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[39m## Raises\u001b[39;00m\n\u001b[0;32m     59\u001b[0m     \u001b[39m#    ValueError: in case of invalid input shape.\"\"\"\u001b[39;00m\n\u001b[0;32m     61\u001b[0m     \u001b[39mif\u001b[39;00m input_tensor \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m         \u001b[39m#Input() используется для создания экземпляра тензора Keras.\u001b[39;00m\n\u001b[0;32m     63\u001b[0m         \u001b[39m#shape: Кортеж фигур (целые числа), не включая размер пакета. Например, shape=(32,) указывает, что ожидаемыми входными данными будут пакеты 32-мерных векторов\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m         img_input \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39;49mInput(shape\u001b[39m=\u001b[39;49minput_shape)\n\u001b[0;32m     66\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     67\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m backend\u001b[39m.\u001b[39mis_keras_tensor(input_tensor):\u001b[39m#Returns whether x is a Keras tensor.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\stan_\\lidc-idri-preproc\\diploma_work\\EfficientNet\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\stan_\\lidc-idri-preproc\\diploma_work\\EfficientNet\\.conda\\lib\\site-packages\\keras\\engine\\input_layer.py:427\u001b[0m, in \u001b[0;36mInput\u001b[1;34m(shape, batch_size, name, dtype, sparse, tensor, ragged, type_spec, **kwargs)\u001b[0m\n\u001b[0;32m    417\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    418\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mOnly provide the `shape` OR `batch_input_shape` argument \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    419\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mto Input, not both at the same time.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    420\u001b[0m     )\n\u001b[0;32m    421\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    422\u001b[0m     batch_input_shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    423\u001b[0m     \u001b[39mand\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    424\u001b[0m     \u001b[39mand\u001b[39;00m tensor \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    425\u001b[0m     \u001b[39mand\u001b[39;00m type_spec \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    426\u001b[0m ):\n\u001b[1;32m--> 427\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    428\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease provide to Input a `shape` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    429\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mor a `tensor` or a `type_spec` argument. Note that \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    430\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`shape` does not include the batch \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    431\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdimension.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    432\u001b[0m     )\n\u001b[0;32m    433\u001b[0m \u001b[39mif\u001b[39;00m kwargs:\n\u001b[0;32m    434\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    435\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized keyword arguments: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(kwargs\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    436\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Please provide to Input a `shape` or a `tensor` or a `type_spec` argument. Note that `shape` does not include the batch dimension."
     ]
    }
   ],
   "source": [
    "kEffNet3D(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
