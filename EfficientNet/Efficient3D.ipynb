{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2019 The TensorFlow Authors, Pavel Yakubovskiy, Björn Barz, Roman Solovyev (3D version),\n",
    "# Alexandros Stergiou (DepthwiseConv3D). All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\"\"\"Contains definitions for EfficientNet model.\n",
    "\n",
    "[1] Mingxing Tan, Quoc V. Le\n",
    "  EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks.\n",
    "  ICML'19, https://arxiv.org/abs/1905.11946\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import math\n",
    "import string\n",
    "import collections\n",
    "\n",
    "from six.moves import xrange\n",
    "from keras_applications.imagenet_utils import _obtain_input_shape\n",
    "from keras_applications.imagenet_utils import preprocess_input as _preprocess_input\n",
    "\n",
    "from . import get_submodules_from_kwargs\n",
    "from .weights import IMAGENET_WEIGHTS_PATH, IMAGENET_WEIGHTS_HASHES\n",
    "\n",
    "import tensorflow as tf\n",
    "try:\n",
    "    from keras import backend as K\n",
    "    from keras import initializers\n",
    "    from keras import regularizers\n",
    "    from keras import constraints\n",
    "    from keras import layers\n",
    "    from keras.legacy.interfaces import conv3d_args_preprocessor, generate_legacy_interface\n",
    "    from keras.layers import Conv3D\n",
    "    from keras.backend.tensorflow_backend import _preprocess_padding, _preprocess_conv3d_input\n",
    "    from keras.engine import InputSpec\n",
    "    from keras.utils import conv_utils\n",
    "except:\n",
    "    from tensorflow.keras import backend as K\n",
    "    from tensorflow.keras import initializers\n",
    "    from tensorflow.keras import regularizers\n",
    "    from tensorflow.keras import constraints\n",
    "    from tensorflow.keras import layers\n",
    "    from tensorflow.keras.layers import Conv3D\n",
    "    from tensorflow.keras.layers import InputSpec\n",
    "    # from tensorflow.keras.utils import conv_utils\n",
    "    import tensorflow.keras.utils as conv_utils\n",
    "    import six\n",
    "    import warnings\n",
    "    from distutils.version import StrictVersion\n",
    "\n",
    "\n",
    "    def generate_legacy_interface(allowed_positional_args=None,\n",
    "                                  conversions=None,\n",
    "                                  preprocessor=None,\n",
    "                                  value_conversions=None):\n",
    "        allowed_positional_args = allowed_positional_args or []\n",
    "        conversions = conversions or []\n",
    "        value_conversions = value_conversions or []\n",
    "\n",
    "        def legacy_support(func):\n",
    "            @six.wraps(func)\n",
    "            def wrapper(*args, **kwargs):\n",
    "                layer_name = args[0].__class__.__name__\n",
    "                if preprocessor:\n",
    "                    args, kwargs, converted = preprocessor(args, kwargs)\n",
    "                else:\n",
    "                    converted = []\n",
    "                if len(args) > len(allowed_positional_args) + 1:\n",
    "                    raise TypeError('Layer `' + layer_name +\n",
    "                                    '` can accept only ' +\n",
    "                                    str(len(allowed_positional_args)) +\n",
    "                                    ' positional arguments (' +\n",
    "                                    str(allowed_positional_args) + '), but '\n",
    "                                    'you passed the following '\n",
    "                                    'positional arguments: ' +\n",
    "                                    str(args[1:]))\n",
    "                for key in value_conversions:\n",
    "                    if key in kwargs:\n",
    "                        old_value = kwargs[key]\n",
    "                        if old_value in value_conversions[key]:\n",
    "                            kwargs[key] = value_conversions[key][old_value]\n",
    "                for old_name, new_name in conversions:\n",
    "                    if old_name in kwargs:\n",
    "                        value = kwargs.pop(old_name)\n",
    "                        kwargs[new_name] = value\n",
    "                        converted.append((new_name, old_name))\n",
    "                if converted:\n",
    "                    signature = '`' + layer_name + '('\n",
    "                    for value in args[1:]:\n",
    "                        if isinstance(value, six.string_types):\n",
    "                            signature += '\"' + value + '\"'\n",
    "                        else:\n",
    "                            signature += str(value)\n",
    "                        signature += ', '\n",
    "                    for i, (name, value) in enumerate(kwargs.items()):\n",
    "                        signature += name + '='\n",
    "                        if isinstance(value, six.string_types):\n",
    "                            signature += '\"' + value + '\"'\n",
    "                        else:\n",
    "                            signature += str(value)\n",
    "                        if i < len(kwargs) - 1:\n",
    "                            signature += ', '\n",
    "                    signature += ')`'\n",
    "                    warnings.warn('Update your `' + layer_name +\n",
    "                                  '` layer call to the Keras 2 API: ' + signature)\n",
    "                return func(*args, **kwargs)\n",
    "            return wrapper\n",
    "        return legacy_support\n",
    "\n",
    "\n",
    "    def conv3d_args_preprocessor(args, kwargs):\n",
    "        if len(args) > 5:\n",
    "            raise TypeError('Layer can receive at most 4 positional arguments.')\n",
    "        if len(args) == 5:\n",
    "            if isinstance(args[2], int) and isinstance(args[3], int) and isinstance(args[4], int):\n",
    "                kernel_size = (args[2], args[3], args[4])\n",
    "                args = [args[0], args[1], kernel_size]\n",
    "        elif len(args) == 4 and isinstance(args[3], int):\n",
    "            if isinstance(args[2], int) and isinstance(args[3], int):\n",
    "                new_keywords = ['padding', 'strides', 'data_format']\n",
    "                for kwd in new_keywords:\n",
    "                    if kwd in kwargs:\n",
    "                        raise ValueError(\n",
    "                            'It seems that you are using the Keras 2 '\n",
    "                            'and you are passing both `kernel_size` and `strides` '\n",
    "                            'as integer positional arguments. For safety reasons, '\n",
    "                            'this is disallowed. Pass `strides` '\n",
    "                            'as a keyword argument instead.')\n",
    "            if 'kernel_dim3' in kwargs:\n",
    "                kernel_size = (args[2], args[3], kwargs.pop('kernel_dim3'))\n",
    "                args = [args[0], args[1], kernel_size]\n",
    "        elif len(args) == 3:\n",
    "            if 'kernel_dim2' in kwargs and 'kernel_dim3' in kwargs:\n",
    "                kernel_size = (args[2],\n",
    "                               kwargs.pop('kernel_dim2'),\n",
    "                               kwargs.pop('kernel_dim3'))\n",
    "                args = [args[0], args[1], kernel_size]\n",
    "        elif len(args) == 2:\n",
    "            if 'kernel_dim1' in kwargs and 'kernel_dim2' in kwargs and 'kernel_dim3' in kwargs:\n",
    "                kernel_size = (kwargs.pop('kernel_dim1'),\n",
    "                               kwargs.pop('kernel_dim2'),\n",
    "                               kwargs.pop('kernel_dim3'))\n",
    "                args = [args[0], args[1], kernel_size]\n",
    "        return args, kwargs, [('kernel_size', 'kernel_dim*')]\n",
    "\n",
    "\n",
    "    def _preprocess_padding(padding):\n",
    "        \"\"\"Convert keras' padding to tensorflow's padding.\n",
    "\n",
    "        # Arguments\n",
    "            padding: string, `\"same\"` or `\"valid\"`.\n",
    "\n",
    "        # Returns\n",
    "            a string, `\"SAME\"` or `\"VALID\"`.\n",
    "\n",
    "        # Raises\n",
    "            ValueError: if `padding` is invalid.\n",
    "        \"\"\"\n",
    "        if padding == 'same':\n",
    "            padding = 'SAME'\n",
    "        elif padding == 'valid':\n",
    "            padding = 'VALID'\n",
    "        else:\n",
    "            raise ValueError('Invalid padding: ' + str(padding))\n",
    "        return padding\n",
    "\n",
    "\n",
    "    def dtype(x):\n",
    "        return x.dtype.base_dtype.name\n",
    "\n",
    "\n",
    "    def _has_nchw_support():\n",
    "        return True\n",
    "\n",
    "\n",
    "    def _preprocess_conv3d_input(x, data_format):\n",
    "        \"\"\"Transpose and cast the input before the conv3d.\n",
    "\n",
    "        # Arguments\n",
    "            x: input tensor.\n",
    "            data_format: string, `\"channels_last\"` or `\"channels_first\"`.\n",
    "\n",
    "        # Returns\n",
    "            A tensor.\n",
    "        \"\"\"\n",
    "        # tensorflow doesn't support float64 for conv layer before 1.8.0\n",
    "        if (dtype(x) == 'float64' and\n",
    "                StrictVersion(tf.__version__.split('-')[0]) < StrictVersion('1.8.0')):\n",
    "            x = tf.cast(x, 'float32')\n",
    "        tf_data_format = 'NDHWC'\n",
    "        return x, tf_data_format\n",
    "\n",
    "\n",
    "def depthwise_conv3d_args_preprocessor(args, kwargs):\n",
    "    converted = []\n",
    "\n",
    "    if 'init' in kwargs:\n",
    "        init = kwargs.pop('init')\n",
    "        kwargs['depthwise_initializer'] = init\n",
    "        converted.append(('init', 'depthwise_initializer'))\n",
    "\n",
    "    args, kwargs, _converted = conv3d_args_preprocessor(args, kwargs)\n",
    "    return args, kwargs, converted + _converted\n",
    "\n",
    "    legacy_depthwise_conv3d_support = generate_legacy_interface(\n",
    "    allowed_positional_args=['filters', 'kernel_size'],\n",
    "    conversions=[('nb_filter', 'filters'),\n",
    "                 ('subsample', 'strides'),\n",
    "                 ('border_mode', 'padding'),\n",
    "                 ('dim_ordering', 'data_format'),\n",
    "                 ('b_regularizer', 'bias_regularizer'),\n",
    "                 ('b_constraint', 'bias_constraint'),\n",
    "                 ('bias', 'use_bias')],\n",
    "    value_conversions={'dim_ordering': {'tf': 'channels_last',\n",
    "                                        'th': 'channels_first',\n",
    "                                        'default': None}},\n",
    "    preprocessor=depthwise_conv3d_args_preprocessor)\n",
    "\n",
    "# Implementation: https://github.com/alexandrosstergiou/keras-DepthwiseConv3D\n",
    "\n",
    "class DepthwiseConv3D(Conv3D):\n",
    "    \"\"\"Depthwise 3D convolution.\n",
    "    Depth-wise part of separable convolutions consist in performing\n",
    "    just the first step/operation\n",
    "    (which acts on each input channel separately).\n",
    "    It does not perform the pointwise convolution (second step).\n",
    "    The `depth_multiplier` argument controls how many\n",
    "    output channels are generated per input channel in the depthwise step.\n",
    "    # Arguments\n",
    "        kernel_size: An integer or tuple/list of 3 integers, specifying the\n",
    "            depth, width and height of the 3D convolution window.\n",
    "            Can be a single integer to specify the same value for\n",
    "            all spatial dimensions.\n",
    "        strides: An integer or tuple/list of 3 integers,\n",
    "            specifying the strides of the convolution along the depth, width and height.\n",
    "            Can be a single integer to specify the same value for\n",
    "            all spatial dimensions.\n",
    "        padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n",
    "        depth_multiplier: The number of depthwise convolution output channels\n",
    "            for each input channel.\n",
    "            The total number of depthwise convolution output\n",
    "            channels will be equal to `filterss_in * depth_multiplier`.\n",
    "        groups: The depth size of the convolution (as a variant of the original Depthwise conv)\n",
    "        data_format: A string,\n",
    "            one of `channels_last` (default) or `channels_first`.\n",
    "            The ordering of the dimensions in the inputs.\n",
    "            `channels_last` corresponds to inputs with shape\n",
    "            `(batch, height, width, channels)` while `channels_first`\n",
    "            corresponds to inputs with shape\n",
    "            `(batch, channels, height, width)`.\n",
    "            It defaults to the `image_data_format` value found in your\n",
    "            Keras config file at `~/.keras/keras.json`.\n",
    "            If you never set it, then it will be \"channels_last\".\n",
    "        activation: Activation function to use\n",
    "            (see [activations](../activations.md)).\n",
    "            If you don't specify anything, no activation is applied\n",
    "            (ie. \"linear\" activation: `a(x) = x`).\n",
    "        use_bias: Boolean, whether the layer uses a bias vector.\n",
    "        depthwise_initializer: Initializer for the depthwise kernel matrix\n",
    "            (see [initializers](../initializers.md)).\n",
    "        bias_initializer: Initializer for the bias vector\n",
    "            (see [initializers](../initializers.md)).\n",
    "        depthwise_regularizer: Regularizer function applied to\n",
    "            the depthwise kernel matrix\n",
    "            (see [regularizer](../regularizers.md)).\n",
    "        bias_regularizer: Regularizer function applied to the bias vector\n",
    "            (see [regularizer](../regularizers.md)).\n",
    "        dialation_rate: List of ints.\n",
    "                        Defines the dilation factor for each dimension in the\n",
    "                        input. Defaults to (1,1,1)\n",
    "        activity_regularizer: Regularizer function applied to\n",
    "            the output of the layer (its \"activation\").\n",
    "            (see [regularizer](../regularizers.md)).\n",
    "        depthwise_constraint: Constraint function applied to\n",
    "            the depthwise kernel matrix\n",
    "            (see [constraints](../constraints.md)).\n",
    "        bias_constraint: Constraint function applied to the bias vector\n",
    "            (see [constraints](../constraints.md)).\n",
    "    # Input shape\n",
    "        5D tensor with shape:\n",
    "        `(batch, depth, channels, rows, cols)` if data_format='channels_first'\n",
    "        or 5D tensor with shape:\n",
    "        `(batch, depth, rows, cols, channels)` if data_format='channels_last'.\n",
    "    # Output shape\n",
    "        5D tensor with shape:\n",
    "        `(batch, filters * depth, new_depth, new_rows, new_cols)` if data_format='channels_first'\n",
    "        or 4D tensor with shape:\n",
    "        `(batch, new_depth, new_rows, new_cols, filters * depth)` if data_format='channels_last'.\n",
    "        `rows` and `cols` values might have changed due to padding.\n",
    "    \"\"\"\n",
    "\n",
    "    #@legacy_depthwise_conv3d_support\n",
    "    def __init__(self,\n",
    "                 kernel_size,\n",
    "                 strides=(1, 1, 1),\n",
    "                 padding='valid',\n",
    "                 depth_multiplier=1,\n",
    "                 groups=None,\n",
    "                 data_format=None,\n",
    "                 activation=None,\n",
    "                 use_bias=True,\n",
    "                 depthwise_initializer='glorot_uniform',\n",
    "                 bias_initializer='zeros',\n",
    "                 dilation_rate = (1, 1, 1),\n",
    "                 depthwise_regularizer=None,\n",
    "                 bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 depthwise_constraint=None,\n",
    "                 bias_constraint=None,\n",
    "                 **kwargs):\n",
    "        super(DepthwiseConv3D, self).__init__(\n",
    "            filters=None,\n",
    "            kernel_size=kernel_size,\n",
    "            strides=strides,\n",
    "            padding=padding,\n",
    "            data_format=data_format,\n",
    "            activation=activation,\n",
    "            use_bias=use_bias,\n",
    "            bias_regularizer=bias_regularizer,\n",
    "            dilation_rate=dilation_rate,\n",
    "            activity_regularizer=activity_regularizer,\n",
    "            bias_constraint=bias_constraint,\n",
    "            **kwargs)\n",
    "        self.depth_multiplier = depth_multiplier\n",
    "        self.groups = groups\n",
    "        self.depthwise_initializer = initializers.get(depthwise_initializer)\n",
    "        self.depthwise_regularizer = regularizers.get(depthwise_regularizer)\n",
    "        self.depthwise_constraint = constraints.get(depthwise_constraint)\n",
    "        self.bias_initializer = initializers.get(bias_initializer)\n",
    "        self.dilation_rate = dilation_rate\n",
    "        self._padding = _preprocess_padding(self.padding)\n",
    "        self._strides = (1,) + self.strides + (1,)\n",
    "        self._data_format = \"NDHWC\"\n",
    "        self.input_dim = None\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if len(input_shape) < 5:\n",
    "            raise ValueError('Inputs to `DepthwiseConv3D` should have rank 5. '\n",
    "                             'Received input shape:', str(input_shape))\n",
    "        if self.data_format == 'channels_first':\n",
    "            channel_axis = 1\n",
    "        else:\n",
    "            channel_axis = -1\n",
    "        if input_shape[channel_axis] is None:\n",
    "            raise ValueError('The channel dimension of the inputs to '\n",
    "                             '`DepthwiseConv3D` '\n",
    "                             'should be defined. Found `None`.')\n",
    "        self.input_dim = int(input_shape[channel_axis])\n",
    "\n",
    "        if self.groups is None:\n",
    "            self.groups = self.input_dim\n",
    "\n",
    "        if self.groups > self.input_dim:\n",
    "            raise ValueError('The number of groups cannot exceed the number of channels')\n",
    "\n",
    "        if self.input_dim % self.groups != 0:\n",
    "            raise ValueError('Warning! The channels dimension is not divisible by the group size chosen')\n",
    "\n",
    "        depthwise_kernel_shape = (self.kernel_size[0],\n",
    "                                  self.kernel_size[1],\n",
    "                                  self.kernel_size[2],\n",
    "                                  self.input_dim,\n",
    "                                  self.depth_multiplier)\n",
    "\n",
    "        self.depthwise_kernel = self.add_weight(\n",
    "            shape=depthwise_kernel_shape,\n",
    "            initializer=self.depthwise_initializer,\n",
    "            name='depthwise_kernel',\n",
    "            regularizer=self.depthwise_regularizer,\n",
    "            constraint=self.depthwise_constraint)\n",
    "\n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(shape=(self.groups * self.depth_multiplier,),\n",
    "                                        initializer=self.bias_initializer,\n",
    "                                        name='bias',\n",
    "                                        regularizer=self.bias_regularizer,\n",
    "                                        constraint=self.bias_constraint)\n",
    "        else:\n",
    "            self.bias = None\n",
    "        # Set input spec.\n",
    "        self.input_spec = InputSpec(ndim=5, axes={channel_axis: self.input_dim})\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        inputs = _preprocess_conv3d_input(inputs, self.data_format)\n",
    "\n",
    "        if self.data_format == 'channels_last':\n",
    "            dilation = (1,) + self.dilation_rate + (1,)\n",
    "        else:\n",
    "            dilation = self.dilation_rate + (1,) + (1,)\n",
    "\n",
    "        if self._data_format == 'NCDHW':\n",
    "            outputs = tf.concat(\n",
    "                [tf.nn.conv3d(inputs[0][:, i:i+self.input_dim//self.groups, :, :, :], self.depthwise_kernel[:, :, :, i:i+self.input_dim//self.groups, :],\n",
    "                    strides=self._strides,\n",
    "                    padding=self._padding,\n",
    "                    dilations=dilation,\n",
    "                    data_format=self._data_format) for i in range(0, self.input_dim, self.input_dim//self.groups)], axis=1)\n",
    "\n",
    "        else:\n",
    "            outputs = tf.concat(\n",
    "                [tf.nn.conv3d(inputs[0][:, :, :, :, i:i+self.input_dim//self.groups], self.depthwise_kernel[:, :, :, i:i+self.input_dim//self.groups, :],\n",
    "                    strides=self._strides,\n",
    "                    padding=self._padding,\n",
    "                    dilations=dilation,\n",
    "                    data_format=self._data_format) for i in range(0, self.input_dim, self.input_dim//self.groups)], axis=-1)\n",
    "\n",
    "        if self.bias is not None:\n",
    "            outputs = K.bias_add(\n",
    "                outputs,\n",
    "                self.bias,\n",
    "                data_format=self.data_format)\n",
    "\n",
    "        if self.activation is not None:\n",
    "            return self.activation(outputs)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.data_format == 'channels_first':\n",
    "            depth = input_shape[2]\n",
    "            rows = input_shape[3]\n",
    "            cols = input_shape[4]\n",
    "            out_filters = self.groups * self.depth_multiplier\n",
    "        elif self.data_format == 'channels_last':\n",
    "            depth = input_shape[1]\n",
    "            rows = input_shape[2]\n",
    "            cols = input_shape[3]\n",
    "            out_filters = self.groups * self.depth_multiplier\n",
    "\n",
    "        depth = conv_utils.conv_output_length(depth, self.kernel_size[0],\n",
    "                                             self.padding,\n",
    "                                             self.strides[0])\n",
    "\n",
    "        rows = conv_utils.conv_output_length(rows, self.kernel_size[1],\n",
    "                                             self.padding,\n",
    "                                             self.strides[1])\n",
    "\n",
    "        cols = conv_utils.conv_output_length(cols, self.kernel_size[2],\n",
    "                                             self.padding,\n",
    "                                             self.strides[2])\n",
    "\n",
    "        if self.data_format == 'channels_first':\n",
    "            return (input_shape[0], out_filters, depth, rows, cols)\n",
    "\n",
    "        elif self.data_format == 'channels_last':\n",
    "            return (input_shape[0], depth, rows, cols, out_filters)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(DepthwiseConv3D, self).get_config()\n",
    "        config.pop('filters')\n",
    "        config.pop('kernel_initializer')\n",
    "        config.pop('kernel_regularizer')\n",
    "        config.pop('kernel_constraint')\n",
    "        config['depth_multiplier'] = self.depth_multiplier\n",
    "        config['depthwise_initializer'] = initializers.serialize(self.depthwise_initializer)\n",
    "        config['depthwise_regularizer'] = regularizers.serialize(self.depthwise_regularizer)\n",
    "        config['depthwise_constraint'] = constraints.serialize(self.depthwise_constraint)\n",
    "        return config\n",
    "\n",
    "DepthwiseConvolution3D = DepthwiseConv3D\n",
    "\n",
    "backend = None\n",
    "layers = None\n",
    "models = None\n",
    "keras_utils = None\n",
    "\n",
    "# Code of this model implementation is mostly written by\n",
    "# Björn Barz ([@Callidior](https://github.com/Callidior))\n",
    "\n",
    "BlockArgs = collections.namedtuple('BlockArgs', [\n",
    "    'kernel_size', 'num_repeat', 'input_filters', 'output_filters',\n",
    "    'expand_ratio', 'id_skip', 'strides', 'se_ratio'\n",
    "])\n",
    "# defaults will be a public argument for namedtuple in Python 3.7\n",
    "# https://docs.python.org/3/library/collections.html#collections.namedtuple\n",
    "BlockArgs.__new__.__defaults__ = (None,) * len(BlockArgs._fields)\n",
    "\n",
    "DEFAULT_BLOCKS_ARGS = [\n",
    "    BlockArgs(kernel_size=3, num_repeat=1, input_filters=32, output_filters=16,\n",
    "              expand_ratio=1, id_skip=True, strides=[1, 1, 1], se_ratio=0.25),\n",
    "    BlockArgs(kernel_size=3, num_repeat=2, input_filters=16, output_filters=24,\n",
    "              expand_ratio=6, id_skip=True, strides=[2, 2, 2], se_ratio=0.25),\n",
    "    BlockArgs(kernel_size=5, num_repeat=2, input_filters=24, output_filters=40,\n",
    "              expand_ratio=6, id_skip=True, strides=[2, 2, 2], se_ratio=0.25),\n",
    "    BlockArgs(kernel_size=3, num_repeat=3, input_filters=40, output_filters=80,\n",
    "              expand_ratio=6, id_skip=True, strides=[2, 2, 2], se_ratio=0.25),\n",
    "    BlockArgs(kernel_size=5, num_repeat=3, input_filters=80, output_filters=112,\n",
    "              expand_ratio=6, id_skip=True, strides=[1, 1, 1], se_ratio=0.25),\n",
    "    BlockArgs(kernel_size=5, num_repeat=4, input_filters=112, output_filters=192,\n",
    "              expand_ratio=6, id_skip=True, strides=[2, 2, 2], se_ratio=0.25),\n",
    "    BlockArgs(kernel_size=3, num_repeat=1, input_filters=192, output_filters=320,\n",
    "              expand_ratio=6, id_skip=True, strides=[1, 1, 1], se_ratio=0.25)\n",
    "]\n",
    "\n",
    "CONV_KERNEL_INITIALIZER = {\n",
    "    'class_name': 'VarianceScaling',\n",
    "    'config': {\n",
    "        'scale': 2.0,\n",
    "        'mode': 'fan_out',\n",
    "        # EfficientNet actually uses an untruncated normal distribution for\n",
    "        # initializing conv layers, but keras.initializers.VarianceScaling use\n",
    "        # a truncated distribution.\n",
    "        # We decided against a custom initializer for better serializability.\n",
    "        'distribution': 'normal'\n",
    "    }\n",
    "}\n",
    "\n",
    "DENSE_KERNEL_INITIALIZER = {\n",
    "    'class_name': 'VarianceScaling',\n",
    "    'config': {\n",
    "        'scale': 1. / 3.,\n",
    "        'mode': 'fan_out',\n",
    "        'distribution': 'uniform'\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def preprocess_input(x, **kwargs):\n",
    "    kwargs = {k: v for k, v in kwargs.items() if k in ['backend', 'layers', 'models', 'utils']}\n",
    "    return _preprocess_input(x, mode='torch', **kwargs)\n",
    "\n",
    "\n",
    "def get_swish(**kwargs):\n",
    "    backend, layers, models, keras_utils = get_submodules_from_kwargs(kwargs)\n",
    "\n",
    "    def swish(x):\n",
    "        \"\"\"Swish activation function: x * sigmoid(x).\n",
    "        Reference: [Searching for Activation Functions](https://arxiv.org/abs/1710.05941)\n",
    "        \"\"\"\n",
    "\n",
    "        if backend.backend() == 'tensorflow':\n",
    "            try:\n",
    "                # The native TF implementation has a more\n",
    "                # memory-efficient gradient implementation\n",
    "                return backend.tf.nn.swish(x)\n",
    "            except AttributeError:\n",
    "                pass\n",
    "\n",
    "        return x * backend.sigmoid(x)\n",
    "\n",
    "    return swish\n",
    "\n",
    "\n",
    "def get_dropout(**kwargs):\n",
    "    \"\"\"Wrapper over custom dropout. Fix problem of ``None`` shape for tf.keras.\n",
    "    It is not possible to define FixedDropout class as global object,\n",
    "    because we do not have modules for inheritance at first time.\n",
    "\n",
    "    Issue:\n",
    "        https://github.com/tensorflow/tensorflow/issues/30946\n",
    "    \"\"\"\n",
    "    backend, layers, models, keras_utils = get_submodules_from_kwargs(kwargs)\n",
    "\n",
    "    class FixedDropout(layers.Dropout):\n",
    "        def _get_noise_shape(self, inputs):\n",
    "            if self.noise_shape is None:\n",
    "                return self.noise_shape\n",
    "\n",
    "            symbolic_shape = backend.shape(inputs)\n",
    "            noise_shape = [symbolic_shape[axis] if shape is None else shape\n",
    "                           for axis, shape in enumerate(self.noise_shape)]\n",
    "            return tuple(noise_shape)\n",
    "\n",
    "    return FixedDropout\n",
    "\n",
    "\n",
    "def round_filters(filters, width_coefficient, depth_divisor):\n",
    "    \"\"\"Round number of filters based on width multiplier.\"\"\"\n",
    "\n",
    "    filters *= width_coefficient\n",
    "    new_filters = int(filters + depth_divisor / 2) // depth_divisor * depth_divisor\n",
    "    new_filters = max(depth_divisor, new_filters)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_filters < 0.9 * filters:\n",
    "        new_filters += depth_divisor\n",
    "    return int(new_filters)\n",
    "\n",
    "\n",
    "def round_repeats(repeats, depth_coefficient):\n",
    "    \"\"\"Round number of repeats based on depth multiplier.\"\"\"\n",
    "\n",
    "    return int(math.ceil(depth_coefficient * repeats))\n",
    "\n",
    "\n",
    "def mb_conv_block(inputs, block_args, activation, drop_rate=None, prefix='', ):\n",
    "    \"\"\"Mobile Inverted Residual Bottleneck.\"\"\"\n",
    "\n",
    "    has_se = (block_args.se_ratio is not None) and (0 < block_args.se_ratio <= 1)\n",
    "    bn_axis = 4 if backend.image_data_format() == 'channels_last' else 1\n",
    "\n",
    "    # workaround over non working dropout with None in noise_shape in tf.keras\n",
    "    Dropout = get_dropout(\n",
    "        backend=backend,\n",
    "        layers=layers,\n",
    "        models=models,\n",
    "        utils=keras_utils\n",
    "    )\n",
    "\n",
    "    # Expansion phase\n",
    "    filters = block_args.input_filters * block_args.expand_ratio\n",
    "    if block_args.expand_ratio != 1:\n",
    "        x = layers.Conv3D(filters, 1,\n",
    "                          padding='same',\n",
    "                          use_bias=False,\n",
    "                          kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "                          name=prefix + 'expand_conv')(inputs)\n",
    "        x = layers.BatchNormalization(axis=bn_axis, name=prefix + 'expand_bn')(x)\n",
    "        x = layers.Activation(activation, name=prefix + 'expand_activation')(x)\n",
    "    else:\n",
    "        x = inputs\n",
    "\n",
    "    # Depthwise Convolution\n",
    "    x = DepthwiseConv3D(block_args.kernel_size,\n",
    "                               strides=block_args.strides,\n",
    "                               padding='same',\n",
    "                               use_bias=False,\n",
    "                               depthwise_initializer=CONV_KERNEL_INITIALIZER,\n",
    "                               name=prefix + 'dwconv')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name=prefix + 'bn')(x)\n",
    "    x = layers.Activation(activation, name=prefix + 'activation')(x)\n",
    "\n",
    "    # Squeeze and Excitation phase\n",
    "    if has_se:\n",
    "        num_reduced_filters = max(1, int(\n",
    "            block_args.input_filters * block_args.se_ratio\n",
    "        ))\n",
    "        se_tensor = layers.GlobalAveragePooling3D(name=prefix + 'se_squeeze')(x)\n",
    "\n",
    "        target_shape = (1, 1, 1, filters) if backend.image_data_format() == 'channels_last' else (filters, 1, 1, 1)\n",
    "        se_tensor = layers.Reshape(target_shape, name=prefix + 'se_reshape')(se_tensor)\n",
    "        se_tensor = layers.Conv3D(num_reduced_filters, 1,\n",
    "                                  activation=activation,\n",
    "                                  padding='same',\n",
    "                                  use_bias=True,\n",
    "                                  kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "                                  name=prefix + 'se_reduce')(se_tensor)\n",
    "        se_tensor = layers.Conv3D(filters, 1,\n",
    "                                  activation='sigmoid',\n",
    "                                  padding='same',\n",
    "                                  use_bias=True,\n",
    "                                  kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "                                  name=prefix + 'se_expand')(se_tensor)\n",
    "        if backend.backend() == 'theano':\n",
    "            # For the Theano backend, we have to explicitly make\n",
    "            # the excitation weights broadcastable.\n",
    "            pattern = ([True, True, True, True, False] if backend.image_data_format() == 'channels_last'\n",
    "                       else [True, False, True, True, True])\n",
    "            se_tensor = layers.Lambda(\n",
    "                lambda x: backend.pattern_broadcast(x, pattern),\n",
    "                name=prefix + 'se_broadcast')(se_tensor)\n",
    "        x = layers.multiply([x, se_tensor], name=prefix + 'se_excite')\n",
    "\n",
    "    # Output phase\n",
    "    x = layers.Conv3D(block_args.output_filters, 1,\n",
    "                      padding='same',\n",
    "                      use_bias=False,\n",
    "                      kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "                      name=prefix + 'project_conv')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name=prefix + 'project_bn')(x)\n",
    "    if block_args.id_skip and all(\n",
    "            s == 1 for s in block_args.strides\n",
    "    ) and block_args.input_filters == block_args.output_filters:\n",
    "        if drop_rate and (drop_rate > 0):\n",
    "            x = Dropout(drop_rate,\n",
    "                        noise_shape=(None, 1, 1, 1, 1),\n",
    "                        name=prefix + 'drop')(x)\n",
    "        x = layers.add([x, inputs], name=prefix + 'add')\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def EfficientNet(width_coefficient,\n",
    "                 depth_coefficient,\n",
    "                 default_resolution,\n",
    "                 dropout_rate=0.2,\n",
    "                 drop_connect_rate=0.2,\n",
    "                 depth_divisor=8,\n",
    "                 blocks_args=DEFAULT_BLOCKS_ARGS,\n",
    "                 model_name='efficientnet',\n",
    "                 include_top=False,\n",
    "                 weights='imagenet',\n",
    "                 input_tensor=None,\n",
    "                 input_shape=None,\n",
    "                 pooling=None,\n",
    "                 classes=1000,\n",
    "                 **kwargs):\n",
    "    \"\"\"Instantiates the EfficientNet architecture using given scaling coefficients.\n",
    "    Optionally loads weights pre-trained on ImageNet.\n",
    "    Note that the data format convention used by the model is\n",
    "    the one specified in your Keras config at `~/.keras/keras.json`.\n",
    "    # Arguments\n",
    "        width_coefficient: float, scaling coefficient for network width.\n",
    "        depth_coefficient: float, scaling coefficient for network depth.\n",
    "        default_resolution: int, default input image size.\n",
    "        dropout_rate: float, dropout rate before final classifier layer.\n",
    "        drop_connect_rate: float, dropout rate at skip connections.\n",
    "        depth_divisor: int.\n",
    "        blocks_args: A list of BlockArgs to construct block modules.\n",
    "        model_name: string, model name.\n",
    "        include_top: whether to include the fully-connected\n",
    "            layer at the top of the network.\n",
    "        weights: one of `None` (random initialization),\n",
    "              'imagenet' (pre-training on ImageNet),\n",
    "              or the path to the weights file to be loaded.\n",
    "        input_tensor: optional Keras tensor\n",
    "            (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False.\n",
    "            It should have exactly 3 inputs channels.\n",
    "        pooling: optional pooling mode for feature extraction\n",
    "            when `include_top` is `False`.\n",
    "            - `None` means that the output of the model will be\n",
    "                the 4D tensor output of the\n",
    "                last convolutional layer.\n",
    "            - `avg` means that global average pooling\n",
    "                will be applied to the output of the\n",
    "                last convolutional layer, and thus\n",
    "                the output of the model will be a 2D tensor.\n",
    "            - `max` means that global max pooling will\n",
    "                be applied.\n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "            if no `weights` argument is specified.\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    # Raises\n",
    "        ValueError: in case of invalid argument for `weights`,\n",
    "            or invalid input shape.\n",
    "    \"\"\"\n",
    "    global backend, layers, models, keras_utils\n",
    "    backend, layers, models, keras_utils = get_submodules_from_kwargs(kwargs)\n",
    "\n",
    "    if not (weights in {'imagenet', 'noisy-student', None} or os.path.exists(weights)):\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization), `imagenet` '\n",
    "                         '(pre-training on ImageNet), '\n",
    "                         'or the path to the weights file to be loaded.')\n",
    "\n",
    "    if weights == 'imagenet' and include_top and classes != 1000:\n",
    "        raise ValueError('If using `weights` as `\"imagenet\"` with `include_top`'\n",
    "                         ' as true, `classes` should be 1000')\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = layers.Input(shape=input_shape)\n",
    "    else:\n",
    "        if backend.backend() == 'tensorflow':\n",
    "            from tensorflow.python.keras.backend import is_keras_tensor\n",
    "        else:\n",
    "            is_keras_tensor = backend.is_keras_tensor\n",
    "        if not is_keras_tensor(input_tensor):\n",
    "            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    bn_axis = 4 if backend.image_data_format() == 'channels_last' else 1\n",
    "    activation = get_swish(**kwargs)\n",
    "\n",
    "    # Build stem\n",
    "    x = img_input\n",
    "    x = layers.Conv3D(round_filters(32, width_coefficient, depth_divisor), 3,\n",
    "                      strides=(2, 2, 2),\n",
    "                      padding='same',\n",
    "                      use_bias=False,\n",
    "                      kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "                      name='stem_conv')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name='stem_bn')(x)\n",
    "    x = layers.Activation(activation, name='stem_activation')(x)\n",
    "\n",
    "    # Build blocks\n",
    "    num_blocks_total = sum(block_args.num_repeat for block_args in blocks_args)\n",
    "    block_num = 0\n",
    "    for idx, block_args in enumerate(blocks_args):\n",
    "        assert block_args.num_repeat > 0\n",
    "        # Update block input and output filters based on depth multiplier.\n",
    "        block_args = block_args._replace(\n",
    "            input_filters=round_filters(block_args.input_filters,\n",
    "                                        width_coefficient, depth_divisor),\n",
    "            output_filters=round_filters(block_args.output_filters,\n",
    "                                         width_coefficient, depth_divisor),\n",
    "            num_repeat=round_repeats(block_args.num_repeat, depth_coefficient))\n",
    "\n",
    "        # The first block needs to take care of stride and filter size increase.\n",
    "        drop_rate = drop_connect_rate * float(block_num) / num_blocks_total\n",
    "        x = mb_conv_block(x, block_args,\n",
    "                          activation=activation,\n",
    "                          drop_rate=drop_rate,\n",
    "                          prefix='block{}a_'.format(idx + 1))\n",
    "        block_num += 1\n",
    "        if block_args.num_repeat > 1:\n",
    "            # pylint: disable=protected-access\n",
    "            block_args = block_args._replace(\n",
    "                input_filters=block_args.output_filters, strides=[1, 1, 1])\n",
    "            # pylint: enable=protected-access\n",
    "            for bidx in xrange(block_args.num_repeat - 1):\n",
    "                drop_rate = drop_connect_rate * float(block_num) / num_blocks_total\n",
    "                block_prefix = 'block{}{}_'.format(\n",
    "                    idx + 1,\n",
    "                    string.ascii_lowercase[bidx + 1]\n",
    "                )\n",
    "                x = mb_conv_block(x, block_args,\n",
    "                                  activation=activation,\n",
    "                                  drop_rate=drop_rate,\n",
    "                                  prefix=block_prefix)\n",
    "                block_num += 1\n",
    "\n",
    "    # Build top\n",
    "    x = layers.Conv3D(round_filters(1280, width_coefficient, depth_divisor), 1,\n",
    "                      padding='same',\n",
    "                      use_bias=False,\n",
    "                      kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "                      name='top_conv')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name='top_bn')(x)\n",
    "    x = layers.Activation(activation, name='top_activation')(x)\n",
    "    if include_top:\n",
    "        x = layers.GlobalAveragePooling3D(name='avg_pool')(x)\n",
    "        if dropout_rate and dropout_rate > 0:\n",
    "            x = layers.Dropout(dropout_rate, name='top_dropout')(x)\n",
    "        x = layers.Dense(classes,\n",
    "                         activation='softmax',\n",
    "                         kernel_initializer=DENSE_KERNEL_INITIALIZER,\n",
    "                         name='probs')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = layers.GlobalAveragePooling3D(name='avg_pool')(x)\n",
    "        elif pooling == 'max':\n",
    "            x = layers.GlobalMaxPooling3D(name='max_pool')(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = keras_utils.get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "\n",
    "    # Create model.\n",
    "    model = models.Model(inputs, x, name=model_name)\n",
    "\n",
    "    # Load weights.\n",
    "    if weights == 'imagenet':\n",
    "\n",
    "        if include_top:\n",
    "            file_name = model_name + '_inp_channel_3_tch_0_top_False.h5'\n",
    "            file_hash = IMAGENET_WEIGHTS_HASHES[model_name][0]\n",
    "        else:\n",
    "            file_name = model_name + '_inp_channel_3_tch_0_top_False.h5'\n",
    "            file_hash = IMAGENET_WEIGHTS_HASHES[model_name][0]\n",
    "        weights_path = keras_utils.get_file(\n",
    "            file_name,\n",
    "            IMAGENET_WEIGHTS_PATH + file_name,\n",
    "            cache_subdir='models',\n",
    "            file_hash=file_hash,\n",
    "        )\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    elif weights is not None:\n",
    "        model.load_weights(weights)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def EfficientNetB0(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_tensor=None,\n",
    "        input_shape=None,\n",
    "        pooling=None,\n",
    "        classes=1000,\n",
    "        **kwargs\n",
    "):\n",
    "    return EfficientNet(\n",
    "        1.0, 1.0, 224, 0.2,\n",
    "        model_name='efficientnet-b0',\n",
    "        include_top=include_top, weights=weights,\n",
    "        input_tensor=input_tensor, input_shape=input_shape,\n",
    "        pooling=pooling, classes=classes,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "\n",
    "def EfficientNetB1(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_tensor=None,\n",
    "        input_shape=None,\n",
    "        pooling=None,\n",
    "        classes=1000,\n",
    "        **kwargs\n",
    "):\n",
    "    return EfficientNet(\n",
    "        1.0, 1.1, 240, 0.2,\n",
    "        model_name='efficientnet-b1',\n",
    "        include_top=include_top, weights=weights,\n",
    "        input_tensor=input_tensor, input_shape=input_shape,\n",
    "        pooling=pooling, classes=classes,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "\n",
    "def EfficientNetB2(include_top=False,\n",
    "                   weights='imagenet',\n",
    "                   input_tensor=None,\n",
    "                   input_shape=None,\n",
    "                   pooling=None,\n",
    "                   classes=1000,\n",
    "                   **kwargs):\n",
    "    return EfficientNet(\n",
    "        1.1, 1.2, 260, 0.3,\n",
    "        model_name='efficientnet-b2',\n",
    "        include_top=include_top, weights=weights,\n",
    "        input_tensor=input_tensor, input_shape=input_shape,\n",
    "        pooling=pooling, classes=classes,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "\n",
    "def EfficientNetB3(include_top=False,\n",
    "                   weights='imagenet',\n",
    "                   input_tensor=None,\n",
    "                   input_shape=None,\n",
    "                   pooling=None,\n",
    "                   classes=1000,\n",
    "                   **kwargs):\n",
    "    return EfficientNet(\n",
    "        1.2, 1.4, 300, 0.3,\n",
    "        model_name='efficientnet-b3',\n",
    "        include_top=include_top, weights=weights,\n",
    "        input_tensor=input_tensor, input_shape=input_shape,\n",
    "        pooling=pooling, classes=classes,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "\n",
    "def EfficientNetB4(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_tensor=None,\n",
    "        input_shape=None,\n",
    "        pooling=None,\n",
    "        classes=1000,\n",
    "        **kwargs\n",
    "):\n",
    "    return EfficientNet(\n",
    "        1.4, 1.8, 380, 0.4,\n",
    "        model_name='efficientnet-b4',\n",
    "        include_top=include_top, weights=weights,\n",
    "        input_tensor=input_tensor, input_shape=input_shape,\n",
    "        pooling=pooling, classes=classes,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "\n",
    "def EfficientNetB5(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_tensor=None,\n",
    "        input_shape=None,\n",
    "        pooling=None,\n",
    "        classes=1000,\n",
    "        **kwargs\n",
    "):\n",
    "    return EfficientNet(\n",
    "        1.6, 2.2, 456, 0.4,\n",
    "        model_name='efficientnet-b5',\n",
    "        include_top=include_top, weights=weights,\n",
    "        input_tensor=input_tensor, input_shape=input_shape,\n",
    "        pooling=pooling, classes=classes,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "\n",
    "def EfficientNetB6(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_tensor=None,\n",
    "        input_shape=None,\n",
    "        pooling=None,\n",
    "        classes=1000,\n",
    "        **kwargs\n",
    "):\n",
    "    return EfficientNet(\n",
    "        1.8, 2.6, 528, 0.5,\n",
    "        model_name='efficientnet-b6',\n",
    "        include_top=include_top, weights=weights,\n",
    "        input_tensor=input_tensor, input_shape=input_shape,\n",
    "        pooling=pooling, classes=classes,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "\n",
    "def EfficientNetB7(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_tensor=None,\n",
    "        input_shape=None,\n",
    "        pooling=None,\n",
    "        classes=1000,\n",
    "        **kwargs\n",
    "):\n",
    "    return EfficientNet(\n",
    "        2.0, 3.1, 600, 0.5,\n",
    "        model_name='efficientnet-b7',\n",
    "        include_top=include_top, weights=weights,\n",
    "        input_tensor=input_tensor, input_shape=input_shape,\n",
    "        pooling=pooling, classes=classes,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "\n",
    "def EfficientNetL2(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_tensor=None,\n",
    "        input_shape=None,\n",
    "        pooling=None,\n",
    "        classes=1000,\n",
    "        **kwargs\n",
    "):\n",
    "    return EfficientNet(\n",
    "        4.3, 5.3, 800, 0.5,\n",
    "        model_name='efficientnet-l2',\n",
    "        include_top=include_top, weights=weights,\n",
    "        input_tensor=input_tensor, input_shape=input_shape,\n",
    "        pooling=pooling, classes=classes,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "\n",
    "setattr(EfficientNetB0, '__doc__', EfficientNet.__doc__)\n",
    "setattr(EfficientNetB1, '__doc__', EfficientNet.__doc__)\n",
    "setattr(EfficientNetB2, '__doc__', EfficientNet.__doc__)\n",
    "setattr(EfficientNetB3, '__doc__', EfficientNet.__doc__)\n",
    "setattr(EfficientNetB4, '__doc__', EfficientNet.__doc__)\n",
    "setattr(EfficientNetB5, '__doc__', EfficientNet.__doc__)\n",
    "setattr(EfficientNetB6, '__doc__', EfficientNet.__doc__)\n",
    "setattr(EfficientNetB7, '__doc__', EfficientNet.__doc__)\n",
    "setattr(EfficientNetL2, '__doc__', EfficientNet.__doc__)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
