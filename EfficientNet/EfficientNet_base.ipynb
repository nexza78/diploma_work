{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/joaopauloschuler/k-neural-api/blob/master/cai/efficientnet.py \n",
    "\n",
    "\n",
    "\"\"\"EfficientNet models for Keras.\n",
    "# Reference paper\n",
    "- [EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks]\n",
    "  (https://arxiv.org/abs/1905.11946) (ICML 2019)\n",
    "# Reference implementation\n",
    "- [TensorFlow]\n",
    "  (https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet)\n",
    "  \n",
    "COPYRIGHT\n",
    "Copyright (c) 2016 - 2018, the respective contributors.\n",
    "All rights reserved.\n",
    "Each contributor holds copyright over their respective contributions.\n",
    "The project versioning (Git) records all such contribution source information.\n",
    "The initial code of this file came from \n",
    "https://github.com/keras-team/keras-applications/blob/master/keras_applications/efficientnet.py\n",
    "(the Keras repository), hence, for author information regarding commits\n",
    "that occured earlier than the first commit in the present repository,\n",
    "please see the original Keras repository.\n",
    "The original file from above link was modified. Modifications can be tracked via \n",
    "git commits at \n",
    "https://github.com/joaopauloschuler/k-neural-api/blob/master/cai/efficientnet.py.\n",
    "LICENSE\n",
    "The MIT License (MIT)\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import cai.util\n",
    "import cai.models\n",
    "import cai.layers\n",
    "\n",
    "import math\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "import tensorflow\n",
    "from copy import deepcopy\n",
    "\n",
    "def correct_pad(backend, inputs, kernel_size):\n",
    "    \"\"\"Returns a tuple for zero-padding for 2D convolution with downsampling.\n",
    "    # Arguments\n",
    "        input_size: An integer or tuple/list of 2 integers.\n",
    "        kernel_size: An integer or tuple/list of 2 integers.\n",
    "    # Returns\n",
    "        A tuple.\n",
    "    \"\"\"\n",
    "    img_dim = 1 # 2 if backend.image_data_format() == 'channels_first' else 1\n",
    "    input_size = backend.int_shape(inputs)[img_dim:(img_dim + 2)]\n",
    "\n",
    "    if isinstance(kernel_size, int):\n",
    "        kernel_size = (kernel_size, kernel_size)\n",
    "\n",
    "    if input_size[0] is None:\n",
    "        adjust = (1, 1)\n",
    "    else:\n",
    "        adjust = (1 - input_size[0] % 2, 1 - input_size[1] % 2)\n",
    "\n",
    "    correct = (kernel_size[0] // 2, kernel_size[1] // 2)\n",
    "\n",
    "    return ((correct[0] - adjust[0], correct[0]),\n",
    "            (correct[1] - adjust[1], correct[1]))\n",
    "\n",
    "DEFAULT_BLOCKS_ARGS = [\n",
    "    {'kernel_size': 3, 'repeats': 1, 'filters_in': 32, 'filters_out': 16,\n",
    "     'expand_ratio': 1, 'id_skip': True, 'strides': 1, 'se_ratio': 0.25},\n",
    "    {'kernel_size': 3, 'repeats': 2, 'filters_in': 16, 'filters_out': 24,\n",
    "     'expand_ratio': 6, 'id_skip': True, 'strides': 2, 'se_ratio': 0.25},\n",
    "    {'kernel_size': 5, 'repeats': 2, 'filters_in': 24, 'filters_out': 40,\n",
    "     'expand_ratio': 6, 'id_skip': True, 'strides': 2, 'se_ratio': 0.25},\n",
    "    {'kernel_size': 3, 'repeats': 3, 'filters_in': 40, 'filters_out': 80,\n",
    "     'expand_ratio': 6, 'id_skip': True, 'strides': 2, 'se_ratio': 0.25},\n",
    "    {'kernel_size': 5, 'repeats': 3, 'filters_in': 80, 'filters_out': 112,\n",
    "     'expand_ratio': 6, 'id_skip': True, 'strides': 1, 'se_ratio': 0.25},\n",
    "    {'kernel_size': 5, 'repeats': 4, 'filters_in': 112, 'filters_out': 192,\n",
    "     'expand_ratio': 6, 'id_skip': True, 'strides': 2, 'se_ratio': 0.25},\n",
    "    {'kernel_size': 3, 'repeats': 1, 'filters_in': 192, 'filters_out': 320,\n",
    "     'expand_ratio': 6, 'id_skip': True, 'strides': 1, 'se_ratio': 0.25}\n",
    "]\n",
    "\n",
    "SHALLOW_BLOCKS_ARGS = [\n",
    "    {'kernel_size': 3, 'repeats': 1, 'filters_in': 32, 'filters_out': 16,\n",
    "     'expand_ratio': 1, 'id_skip': True, 'strides': 1, 'se_ratio': 0.25},\n",
    "    {'kernel_size': 3, 'repeats': 1, 'filters_in': 16, 'filters_out': 24,\n",
    "     'expand_ratio': 6, 'id_skip': True, 'strides': 2, 'se_ratio': 0.25},\n",
    "    {'kernel_size': 5, 'repeats': 1, 'filters_in': 24, 'filters_out': 40,\n",
    "     'expand_ratio': 6, 'id_skip': True, 'strides': 2, 'se_ratio': 0.25},\n",
    "    {'kernel_size': 3, 'repeats': 1, 'filters_in': 40, 'filters_out': 80,\n",
    "     'expand_ratio': 6, 'id_skip': True, 'strides': 2, 'se_ratio': 0.25},\n",
    "    {'kernel_size': 5, 'repeats': 1, 'filters_in': 80, 'filters_out': 112,\n",
    "     'expand_ratio': 6, 'id_skip': True, 'strides': 1, 'se_ratio': 0.25},\n",
    "    {'kernel_size': 5, 'repeats': 1, 'filters_in': 112, 'filters_out': 192,\n",
    "     'expand_ratio': 6, 'id_skip': True, 'strides': 2, 'se_ratio': 0.25},\n",
    "    {'kernel_size': 3, 'repeats': 1, 'filters_in': 192, 'filters_out': 320,\n",
    "     'expand_ratio': 6, 'id_skip': True, 'strides': 1, 'se_ratio': 0.25}\n",
    "]\n",
    "\n",
    "TWO_BLOCKS_ARGS = [\n",
    "    {'kernel_size': 3, 'repeats': 2, 'filters_in': 32, 'filters_out': 16,\n",
    "     'expand_ratio': 1, 'id_skip': True, 'strides': 1, 'se_ratio': 0.25},\n",
    "    {'kernel_size': 3, 'repeats': 2, 'filters_in': 16, 'filters_out': 24,\n",
    "     'expand_ratio': 6, 'id_skip': True, 'strides': 2, 'se_ratio': 0.25},\n",
    "    {'kernel_size': 5, 'repeats': 2, 'filters_in': 24, 'filters_out': 40,\n",
    "     'expand_ratio': 6, 'id_skip': True, 'strides': 2, 'se_ratio': 0.25},\n",
    "    {'kernel_size': 3, 'repeats': 2, 'filters_in': 40, 'filters_out': 80,\n",
    "     'expand_ratio': 6, 'id_skip': True, 'strides': 2, 'se_ratio': 0.25},\n",
    "    {'kernel_size': 5, 'repeats': 2, 'filters_in': 80, 'filters_out': 112,\n",
    "     'expand_ratio': 6, 'id_skip': True, 'strides': 1, 'se_ratio': 0.25},\n",
    "    {'kernel_size': 5, 'repeats': 2, 'filters_in': 112, 'filters_out': 192,\n",
    "     'expand_ratio': 6, 'id_skip': True, 'strides': 2, 'se_ratio': 0.25},\n",
    "    {'kernel_size': 3, 'repeats': 2, 'filters_in': 192, 'filters_out': 320,\n",
    "     'expand_ratio': 6, 'id_skip': True, 'strides': 1, 'se_ratio': 0.25}\n",
    "]\n",
    "\n",
    "CONV_KERNEL_INITIALIZER = {\n",
    "    'class_name': 'VarianceScaling',\n",
    "    'config': {\n",
    "        'scale': 2.0,\n",
    "        'mode': 'fan_out',\n",
    "        # EfficientNet actually uses an untruncated normal distribution for\n",
    "        # initializing conv layers, but keras.initializers.VarianceScaling use\n",
    "        # a truncated distribution.\n",
    "        # We decided against a custom initializer for better serializability.\n",
    "        'distribution': 'normal'\n",
    "    }\n",
    "}\n",
    "\n",
    "DENSE_KERNEL_INITIALIZER = {\n",
    "    'class_name': 'VarianceScaling',\n",
    "    'config': {\n",
    "        'scale': 1. / 3.,\n",
    "        'mode': 'fan_out',\n",
    "        'distribution': 'uniform'\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def swish(x):\n",
    "    \"\"\"Swish activation function.\n",
    "    # Arguments\n",
    "        x: Input tensor.\n",
    "    # Returns\n",
    "        The Swish activation: `x * sigmoid(x)`.\n",
    "    # References\n",
    "        [Searching for Activation Functions](https://arxiv.org/abs/1710.05941)\n",
    "    \"\"\"\n",
    "    if backend.backend() == 'tensorflow':\n",
    "        try:\n",
    "            # The native TF implementation has a more\n",
    "            # memory-efficient gradient implementation\n",
    "            return backend.tf.nn.swish(x)\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "    return x * backend.sigmoid(x)\n",
    "\n",
    "\n",
    "def block(inputs, activation_fn=swish, drop_rate=0., name='',\n",
    "          filters_in=32, filters_out=16, kernel_size=3, strides=1,\n",
    "          expand_ratio=1, se_ratio=0., id_skip=True):\n",
    "    \"\"\"A mobile inverted residual block.\n",
    "    # Arguments\n",
    "        inputs: input tensor.\n",
    "        activation_fn: activation function.\n",
    "        drop_rate: float between 0 and 1, fraction of the input units to drop.\n",
    "        name: string, block label.\n",
    "        filters_in: integer, the number of input filters.\n",
    "        filters_out: integer, the number of output filters.\n",
    "        kernel_size: integer, the dimension of the convolution window.\n",
    "        strides: integer, the stride of the convolution.\n",
    "        expand_ratio: integer, scaling coefficient for the input filters.\n",
    "        se_ratio: float between 0 and 1, fraction to squeeze the input filters.\n",
    "        id_skip: boolean.\n",
    "    # Returns\n",
    "        output tensor for the block.\n",
    "    \"\"\"\n",
    "    bn_axis = 3\n",
    "\n",
    "    # Expansion phase\n",
    "    filters = filters_in * expand_ratio\n",
    "    if expand_ratio != 1:\n",
    "        x = layers.Conv2D(filters, 1,\n",
    "                          padding='same',\n",
    "                          use_bias=False,\n",
    "                          kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "                          name=name + 'expand_conv')(inputs)\n",
    "        x = layers.BatchNormalization(axis=bn_axis, name=name + 'expand_bn')(x)\n",
    "        x = layers.Activation(activation_fn, name=name + 'expand_activation')(x)\n",
    "    else:\n",
    "        x = inputs\n",
    "\n",
    "    # Depthwise Convolution\n",
    "    if strides == 2:\n",
    "        x = layers.ZeroPadding2D(padding=correct_pad(backend, x, kernel_size),\n",
    "                                 name=name + 'dwconv_pad')(x)\n",
    "        conv_pad = 'valid'\n",
    "    else:\n",
    "        conv_pad = 'same'\n",
    "    x = layers.DepthwiseConv2D(kernel_size,\n",
    "                               strides=strides,\n",
    "                               padding=conv_pad,\n",
    "                               use_bias=False,\n",
    "                               depthwise_initializer=CONV_KERNEL_INITIALIZER,\n",
    "                               name=name + 'dwconv')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name=name + 'bn')(x)\n",
    "    x = layers.Activation(activation_fn, name=name + 'activation')(x)\n",
    "\n",
    "    # Squeeze and Excitation phase\n",
    "    if 0 < se_ratio <= 1:\n",
    "        filters_se = max(1, int(filters_in * se_ratio))\n",
    "        se = layers.GlobalAveragePooling2D(name=name + 'se_squeeze')(x)\n",
    "        if bn_axis == 1:\n",
    "            se = layers.Reshape((filters, 1, 1), name=name + 'se_reshape')(se)\n",
    "        else:\n",
    "            se = layers.Reshape((1, 1, filters), name=name + 'se_reshape')(se)\n",
    "        se = layers.Conv2D(filters_se, 1,\n",
    "                           padding='same',\n",
    "                           activation=activation_fn,\n",
    "                           kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "                           name=name + 'se_reduce')(se)\n",
    "        se = layers.Conv2D(filters, 1,\n",
    "                           padding='same',\n",
    "                           activation='sigmoid',\n",
    "                           kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "                           name=name + 'se_expand')(se)\n",
    "        x = layers.multiply([x, se], name=name + 'se_excite')\n",
    "\n",
    "    # Output phase\n",
    "    x = layers.Conv2D(filters_out, 1,\n",
    "                      padding='same',\n",
    "                      use_bias=False,\n",
    "                      kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "                      name=name + 'project_conv')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name=name + 'project_bn')(x)\n",
    "    if (id_skip is True and strides == 1 and filters_in == filters_out):\n",
    "        if drop_rate > 0:\n",
    "            x = layers.Dropout(drop_rate,\n",
    "                               noise_shape=(None, 1, 1, 1),\n",
    "                               name=name + 'drop')(x)\n",
    "        x = layers.add([x, inputs], name=name + 'add')\n",
    "    return x\n",
    "\n",
    "def EfficientNet(width_coefficient,\n",
    "                 depth_coefficient,\n",
    "                 default_size,\n",
    "                 dropout_rate=0.2,\n",
    "                 drop_connect_rate=0.2,\n",
    "                 depth_divisor=8,\n",
    "                 activation_fn=swish,\n",
    "                 blocks_args=DEFAULT_BLOCKS_ARGS,\n",
    "                 model_name='efficientnet',\n",
    "                 include_top=True,\n",
    "                 input_tensor=None,\n",
    "                 input_shape=None,\n",
    "                 pooling=None,\n",
    "                 classes=1000,\n",
    "                 **kwargs):\n",
    "    \"\"\"Instantiates the EfficientNet architecture using given scaling coefficients.\n",
    "    Optionally loads weights pre-trained on ImageNet.\n",
    "    Note that the data format convention used by the model is\n",
    "    the one specified in your Keras config at `~/.keras/keras.json`.\n",
    "    # Arguments\n",
    "        width_coefficient: float, scaling coefficient for network width.\n",
    "        depth_coefficient: float, scaling coefficient for network depth.\n",
    "        default_size: integer, default input image size.\n",
    "        dropout_rate: float, dropout rate before final classifier layer.\n",
    "        drop_connect_rate: float, dropout rate at skip connections.\n",
    "        depth_divisor: integer, a unit of network width.\n",
    "        activation_fn: activation function.\n",
    "        blocks_args: list of dicts, parameters to construct block modules.\n",
    "        model_name: string, model name.\n",
    "        include_top: whether to include the fully-connected\n",
    "            layer at the top of the network.\n",
    "        input_tensor: optional Keras tensor\n",
    "            (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False.\n",
    "            It should have exactly 3 inputs channels.\n",
    "        pooling: optional pooling mode for feature extraction\n",
    "            when `include_top` is `False`.\n",
    "            - `None` means that the output of the model will be\n",
    "                the 4D tensor output of the\n",
    "                last convolutional layer.\n",
    "            - `avg` means that global average pooling\n",
    "                will be applied to the output of the\n",
    "                last convolutional layer, and thus\n",
    "                the output of the model will be a 2D tensor.\n",
    "            - `max` means that global max pooling will\n",
    "                be applied.\n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    # Raises\n",
    "        ValueError: in case of invalid input shape.\n",
    "    \"\"\"\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = layers.Input(shape=input_shape)\n",
    "    else:\n",
    "        if not backend.is_keras_tensor(input_tensor):\n",
    "            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    bn_axis = 3\n",
    "\n",
    "    def round_filters(filters, divisor=depth_divisor):\n",
    "        \"\"\"Round number of filters based on depth multiplier.\"\"\"\n",
    "        filters *= width_coefficient\n",
    "        new_filters = max(divisor, int(filters + divisor / 2) // divisor * divisor)\n",
    "        # Make sure that round down does not go down by more than 10%.\n",
    "        if new_filters < 0.9 * filters:\n",
    "            new_filters += divisor\n",
    "        return int(new_filters)\n",
    "\n",
    "    def round_repeats(repeats):\n",
    "        \"\"\"Round number of repeats based on depth multiplier.\"\"\"\n",
    "        return int(math.ceil(depth_coefficient * repeats))\n",
    "\n",
    "    # Build stem\n",
    "    x = img_input\n",
    "    x = layers.ZeroPadding2D(padding=correct_pad(backend, x, 3),\n",
    "                             name='stem_conv_pad')(x)\n",
    "    x = layers.Conv2D(round_filters(32), 3,\n",
    "                      strides=2,\n",
    "                      padding='valid',\n",
    "                      use_bias=False,\n",
    "                      kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "                      name='stem_conv')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name='stem_bn')(x)\n",
    "    x = layers.Activation(activation_fn, name='stem_activation')(x)\n",
    "\n",
    "    # Build blocks\n",
    "    from copy import deepcopy\n",
    "    blocks_args = deepcopy(blocks_args)\n",
    "\n",
    "    b = 0\n",
    "    blocks = float(sum(args['repeats'] for args in blocks_args))\n",
    "    for (i, args) in enumerate(blocks_args):\n",
    "        assert args['repeats'] > 0\n",
    "        # Update block input and output filters based on depth multiplier.\n",
    "        args['filters_in'] = round_filters(args['filters_in'])\n",
    "        args['filters_out'] = round_filters(args['filters_out'])\n",
    "\n",
    "        for j in range(round_repeats(args.pop('repeats'))):\n",
    "            # The first block needs to take care of stride and filter size increase.\n",
    "            if j > 0:\n",
    "                args['strides'] = 1\n",
    "                args['filters_in'] = args['filters_out']\n",
    "            x = block(x, activation_fn, drop_connect_rate * b / blocks,\n",
    "                      name='block{}{}_'.format(i + 1, chr(j + 97)), **args)\n",
    "            b += 1\n",
    "\n",
    "    # Build top\n",
    "    x = layers.Conv2D(round_filters(1280), 1,\n",
    "                      padding='same',\n",
    "                      use_bias=False,\n",
    "                      kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "                      name='top_conv')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name='top_bn')(x)\n",
    "    x = layers.Activation(activation_fn, name='top_activation')(x)\n",
    "    if include_top:\n",
    "        x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "        if dropout_rate > 0:\n",
    "            x = layers.Dropout(dropout_rate, name='top_dropout')(x)\n",
    "        x = layers.Dense(classes,\n",
    "                         activation='softmax',\n",
    "                         kernel_initializer=DENSE_KERNEL_INITIALIZER,\n",
    "                         name='probs')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "        elif pooling == 'max':\n",
    "            x = layers.GlobalMaxPooling2D(name='max_pool')(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = utils.get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "\n",
    "    # Create model.\n",
    "    model = models.Model(inputs, x, name=model_name)\n",
    "\n",
    "    return model\n",
    "\n",
    "def EfficientNetB0(include_top=True,\n",
    "                   input_tensor=None,\n",
    "                   input_shape=None,\n",
    "                   pooling=None,\n",
    "                   classes=1000,\n",
    "                   dropout_rate=0.2,\n",
    "                   drop_connect_rate=0.2,\n",
    "                   **kwargs):\n",
    "    return EfficientNet(1.0, 1.0, 224,\n",
    "                        model_name='efficientnet-b0',\n",
    "                        include_top=include_top,\n",
    "                        input_tensor=input_tensor, input_shape=input_shape,\n",
    "                        pooling=pooling, classes=classes,\n",
    "                        dropout_rate=dropout_rate,\n",
    "                        drop_connect_rate=drop_connect_rate,\n",
    "                        **kwargs)\n",
    "\n",
    "\n",
    "def EfficientNet_base():\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cai'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8292/362147585.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcai\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cai'"
     ]
    }
   ],
   "source": [
    "from cai import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
