{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "\n",
    "import math\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "import tensorflow\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cai.util\n",
    "import cai.models\n",
    "import cai.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_pad(backend, inputs, kernel_size):\n",
    "    \"\"\"Returns a tuple for zero-padding for 2D convolution with downsampling.\n",
    "    # Arguments\n",
    "        input_size: An integer or tuple/list of 2 integers.\n",
    "        kernel_size: An integer or tuple/list of 2 integers.\n",
    "    # Returns\n",
    "        A tuple.\n",
    "    \"\"\"\n",
    "    img_dim = 1 # 2 if backend.image_data_format() == 'channels_first' else 1\n",
    "    #извлечение чисел - первое равно h/w, второе - n_channels\n",
    "    input_size = backend.int_shape(inputs)[img_dim:(img_dim + 2)]\n",
    "    print(input_size, backend.image_data_format())\n",
    "\n",
    "    if isinstance(kernel_size, int):\n",
    "        print('is_inst', isinstance(kernel_size, int))\n",
    "        kernel_size = (kernel_size, kernel_size)\n",
    "\n",
    "    if input_size[0] is None:\n",
    "        adjust = (1, 1)\n",
    "    else:\n",
    "        adjust = (1 - input_size[0] % 2, 1 - input_size[1] % 2)\n",
    "\n",
    "    correct = (kernel_size[0] // 2, kernel_size[1] // 2)\n",
    "\n",
    "    return ((correct[0] - adjust[0], correct[0]),\n",
    "            (correct[1] - adjust[1], correct[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.random.rand(32, 32,32, 3)\n",
    "\n",
    "kernel_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32) channels_last\n",
      "is_inst True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0, 1), (0, 1))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_pad(backend,  inputs, kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swish(x):\n",
    "    \"\"\"Swish activation function.\n",
    "    # Arguments\n",
    "        x: Input tensor.\n",
    "    # Returns\n",
    "        The Swish activation: `x * sigmoid(x)`.\n",
    "    # References\n",
    "        [Searching for Activation Functions](https://arxiv.org/abs/1710.05941)\n",
    "    \"\"\"\n",
    "    if backend.backend() == 'tensorflow':\n",
    "        try:\n",
    "            # The native TF implementation has a more\n",
    "            # memory-efficient gradient implementation\n",
    "            return backend.tf.nn.swish(x)\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "    return x * backend.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_BLOCKS_ARGS = [\n",
    "    {'kernel_size': 3, 'repeats': 1, 'filters_in': 32, 'filters_out': 16,\n",
    "     'expand_ratio': 1, 'id_skip': True, 'strides': 1, 'se_ratio': 0.25},\n",
    "    {'kernel_size': 3, 'repeats': 2, 'filters_in': 16, 'filters_out': 24,\n",
    "     'expand_ratio': 6, 'id_skip': True, 'strides': 2, 'se_ratio': 0.25},\n",
    "    {'kernel_size': 5, 'repeats': 2, 'filters_in': 24, 'filters_out': 40,\n",
    "     'expand_ratio': 6, 'id_skip': True, 'strides': 2, 'se_ratio': 0.25},\n",
    "    {'kernel_size': 3, 'repeats': 3, 'filters_in': 40, 'filters_out': 80,\n",
    "     'expand_ratio': 6, 'id_skip': True, 'strides': 2, 'se_ratio': 0.25},\n",
    "    {'kernel_size': 5, 'repeats': 3, 'filters_in': 80, 'filters_out': 112,\n",
    "     'expand_ratio': 6, 'id_skip': True, 'strides': 1, 'se_ratio': 0.25},\n",
    "    {'kernel_size': 5, 'repeats': 4, 'filters_in': 112, 'filters_out': 192,\n",
    "     'expand_ratio': 6, 'id_skip': True, 'strides': 2, 'se_ratio': 0.25},\n",
    "    {'kernel_size': 3, 'repeats': 1, 'filters_in': 192, 'filters_out': 320,\n",
    "     'expand_ratio': 6, 'id_skip': True, 'strides': 1, 'se_ratio': 0.25}\n",
    "] \n",
    "\n",
    "CONV_KERNEL_INITIALIZER = {\n",
    "    'class_name': 'VarianceScaling',\n",
    "    'config': {\n",
    "        'scale': 2.0,\n",
    "        'mode': 'fan_out',\n",
    "        # EfficientNet actually uses an untruncated normal distribution for\n",
    "        # initializing conv layers, but keras.initializers.VarianceScaling use\n",
    "        # a truncated distribution.\n",
    "        # We decided against a custom initializer for better serializability.\n",
    "        'distribution': 'normal'\n",
    "    }\n",
    "}\n",
    "\n",
    "DENSE_KERNEL_INITIALIZER = {\n",
    "    'class_name': 'VarianceScaling',\n",
    "    'config': {\n",
    "        'scale': 1. / 3.,\n",
    "        'mode': 'fan_out',\n",
    "        'distribution': 'uniform'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def kConv2D(last_tensor, filters=32, channel_axis=3, name=None, activation=None, has_batch_norm=True, has_batch_scale=True, use_bias=True, kernel_size=1, stride_size=1, padding='same', kType=2):\n",
    "    print(\"last_tensor  \", last_tensor)\n",
    "    prev_layer_channel_count = tensorflow.keras.backend.int_shape(last_tensor)[channel_axis]\n",
    "    print(\"prev_layer_channel_count \", prev_layer_channel_count)\n",
    "\n",
    "    \n",
    "    if kType == 0:\n",
    "        return kConv2DType0(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding)\n",
    "    #elif kType == 1:\n",
    "    #    return kConv2DType1(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding)\n",
    "    #elif kType == D6_16ch():\n",
    "    #    return kConv2DType2(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=16)\n",
    "    #elif kType == kT3_16ch():\n",
    "    #    return kConv2DType3(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding)\n",
    "    #elif kType == 4:\n",
    "    #    return kConv2DType4(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding)\n",
    "    #elif kType == 5:\n",
    "    #    return kConv2DType5(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding)\n",
    "    #elif kType == 6:\n",
    "    #    return kConv2DType6(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding)\n",
    "    #elif kType == 7:\n",
    "    #    return kConv2DType7(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, bin_conv_count=0)\n",
    "    #elif kType == 8:\n",
    "    #    return kConv2DType7(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, bin_conv_count=1)\n",
    "    #elif kType == 9:\n",
    "    #    return kConv2DType7(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, bin_conv_count=2)\n",
    "    #elif kType == 10:\n",
    "    #    return kConv2DType7(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, bin_conv_count=4)\n",
    "    #elif kType == 11:\n",
    "    #    return kConv2DType7(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, bin_conv_count=5)\n",
    "    #elif kType == 12:\n",
    "    #    return kConv2DType7(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, bin_conv_count=6)\n",
    "    elif kType == cai.layers.D6_32ch():\n",
    "        return cai.layers.kConv2DType2(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=32)\n",
    "    #elif kType == D6_8ch():\n",
    "    #    return kConv2DType2(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=8)\n",
    "    #elif kType == D6_4ch():\n",
    "    #    return kConv2DType2(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=4)\n",
    "    #elif kType == 16:\n",
    "    #    if prev_layer_channel_count >= filters:\n",
    "    #        return kConv2DType2(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=32)\n",
    "    #    else:\n",
    "    #        return kConv2DType2(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=16)\n",
    "    #elif kType == 17:\n",
    "    #    if prev_layer_channel_count < filters:\n",
    "    #        return kConv2DType2(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=32)\n",
    "    #    else:\n",
    "    #        return kConv2DType2(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=16)\n",
    "    #elif kType == 18:\n",
    "    #    if prev_layer_channel_count >= filters:\n",
    "    #        return kConv2DType7(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, bin_conv_count=5)\n",
    "    #    else:\n",
    "    #        return kConv2DType2(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=16)\n",
    "    #elif kType == 19:\n",
    "    #    return kConv2DType8(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=16)\n",
    "    #elif kType == 20:\n",
    "    #    return kConv2DType8(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=32)\n",
    "    #elif kType == 21:\n",
    "    #    return kConv2DType8(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=16, always_intergroup=True)\n",
    "    #elif kType == 22:\n",
    "    #    return kConv2DType8(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=32, always_intergroup=True)\n",
    "    #elif kType == kT3_32ch():\n",
    "    #    return kConv2DType3(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=32)\n",
    "    #elif kType == D6_64ch():\n",
    "    #    return kConv2DType2(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=64)\n",
    "    #elif kType == kT3_64ch():\n",
    "    #    return kConv2DType3(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=64)\n",
    "    #elif kType == D6_128ch():\n",
    "    #    return kConv2DType2(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=128)\n",
    "    #elif kType == kT3_128ch():\n",
    "    #    return kConv2DType3(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=128)\n",
    "    #elif kType == 28:\n",
    "    #    return kConv2DType9(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=16, always_intergroup=True)\n",
    "    #elif kType == 29:\n",
    "    #    return kConv2DType9(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=32, always_intergroup=True)\n",
    "    #elif kType == 30:\n",
    "    #    return kConv2DType9(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=64, always_intergroup=True)\n",
    "    #elif kType == 31:\n",
    "    #    return kConv2DType9(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=128, always_intergroup=True)\n",
    "    elif kType == cai.layers.D6v3_16ch():\n",
    "       return cai.layers.kConv2DType10(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, min_channels_per_group=16, kernel_size=kernel_size, stride_size=stride_size, padding=padding)\n",
    "    elif kType == cai.layers.D6v3_32ch():\n",
    "       return cai.layers.kConv2DType10(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, min_channels_per_group=32, kernel_size=kernel_size, stride_size=stride_size, padding=padding)\n",
    "    #elif kType == D6v3_64ch():\n",
    "    #    return kConv2DType10(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, min_channels_per_group=64, kernel_size=kernel_size, stride_size=stride_size, padding=padding)\n",
    "    #elif kType == D6v3_128ch():\n",
    "    #    return kConv2DType10(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, min_channels_per_group=128, kernel_size=kernel_size, stride_size=stride_size, padding=padding)\n",
    "    #elif kType == kT3v3_16ch():\n",
    "    #    return kConv2DType10(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, min_channels_per_group=16, kernel_size=kernel_size, stride_size=stride_size, padding=padding, never_intergroup=True)\n",
    "    #elif kType == cai.layers.kT3v3_32ch():\n",
    "    #    return cai.layers.kConv2DType10(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, min_channels_per_group=32, kernel_size=kernel_size, stride_size=stride_size, padding=padding, never_intergroup=True)\n",
    "    #elif kType == cai.layers.kT3v3_64ch():\n",
    "    #    return cai.layers.kConv2DType10(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, min_channels_per_group=64, kernel_size=kernel_size, stride_size=stride_size, padding=padding, never_intergroup=True)\n",
    "    #elif kType == kT3v3_128ch():\n",
    "    #    return kConv2DType10(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, min_channels_per_group=128, kernel_size=kernel_size, stride_size=stride_size, padding=padding, never_intergroup=True)\n",
    "    #elif kType == D6_12ch():\n",
    "    #    return kConv2DType2(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=12)\n",
    "    #elif kType == D6_24ch():\n",
    "    #    return kConv2DType2(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=24)\n",
    "    #elif kType == D6v3_12ch():\n",
    "    #    return kConv2DType10(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, min_channels_per_group=12, kernel_size=kernel_size, stride_size=stride_size, padding=padding)\n",
    "    elif kType == cai.layers.D6v3_24ch():\n",
    "        return cai.layers.kConv2DType10(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, min_channels_per_group=24, kernel_size=kernel_size, stride_size=stride_size, padding=padding)\n",
    "    elif kType == cai.layers.D6v3_8ch():\n",
    "        return cai.layers.kConv2DType10(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, min_channels_per_group=8, kernel_size=kernel_size, stride_size=stride_size, padding=padding)\n",
    "    elif kType == cai.layers.D6v3_4ch():\n",
    "        return cai.layers.kConv2DType10(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, min_channels_per_group=4, kernel_size=kernel_size, stride_size=stride_size, padding=padding)\n",
    "    elif kType == cai.layers.D6v3_2ch():\n",
    "        return cai.layers.kConv2DType10(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, min_channels_per_group=2, kernel_size=kernel_size, stride_size=stride_size, padding=padding)\n",
    "    elif kType == cai.layers.kT3v3_4ch():\n",
    "        return cai.layers.kConv2DType10(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, min_channels_per_group=4, kernel_size=kernel_size, stride_size=stride_size, padding=padding, never_intergroup=True)\n",
    "    elif kType == cai.layers.kT3v3_8ch():\n",
    "        return cai.layers.kConv2DType10(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, min_channels_per_group=8, kernel_size=kernel_size, stride_size=stride_size, padding=padding, never_intergroup=True)\n",
    "\n",
    "def kPointwiseConv2D(last_tensor, filters=32, channel_axis=3, name=None, activation=None, has_batch_norm=True, has_batch_scale=True, use_bias=True, kType=2):\n",
    "    \"\"\"\n",
    "    Parameter efficient pointwise convolution as shown in these papers:\n",
    "    https://www.researchgate.net/publication/360226228_Grouped_Pointwise_Convolutions_Reduce_Parameters_in_Convolutional_Neural_Networks\n",
    "    https://www.researchgate.net/publication/363413038_An_Enhanced_Scheme_for_Reducing_the_Complexity_of_Pointwise_Convolutions_in_CNNs_for_Image_Classification_Based_on_Interleaved_Grouped_Filters_without_Divisibility_Constraints\n",
    "    \"\"\"\n",
    "    return kConv2D(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=1, stride_size=1, padding='same', kType=kType)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def kblock(inputs, activation_fn=swish, drop_rate=0., name='',\n",
    "          filters_in=32, filters_out=16, kernel_size=3, strides=1,\n",
    "          expand_ratio=1, se_ratio=0., id_skip=True, kType=1,\n",
    "          dropout_all_blocks=False):\n",
    "    \"\"\"A mobile inverted residual block.\n",
    "    # Arguments\n",
    "        inputs: input tensor.\n",
    "        activation_fn: activation function.\n",
    "        drop_rate: float between 0 and 1, fraction of the input units to drop.\n",
    "        name: string, block label.\n",
    "        filters_in: integer, the number of input filters.\n",
    "        filters_out: integer, the number of output filters.\n",
    "        kernel_size: integer, the dimension of the convolution window.\n",
    "        strides: integer, the stride of the convolution.\n",
    "        expand_ratio: integer, scaling coefficient for the input filters.\n",
    "        se_ratio: float between 0 and 1, fraction to squeeze the input filters.\n",
    "        id_skip: boolean.\n",
    "    # Returns\n",
    "        output tensor for the block.\n",
    "    \"\"\"\n",
    "    bn_axis = 3\n",
    "\n",
    "    # Expansion phase\n",
    "    filters = filters_in * expand_ratio\n",
    "    \n",
    "    if expand_ratio != 1:\n",
    "        #x = layers.Conv2D(filters, 1,\n",
    "        #                 padding='same',\n",
    "        #                  use_bias=False,\n",
    "        #                  kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "        #                  name=name + 'expand_conv')(inputs)\n",
    "        #x = layers.BatchNormalization(axis=bn_axis, name=name + 'expand_bn')(x)\n",
    "        #x = layers.Activation(activation_fn, name=name + 'expand_activation')(x)\n",
    "        x = cai.layers.kPointwiseConv2D(last_tensor=inputs, filters=filters, channel_axis=bn_axis, name=name+'expand', activation=activation_fn, has_batch_norm=True, use_bias=False, kType=kType)\n",
    "    else:\n",
    "        x = inputs\n",
    "\n",
    "    # Depthwise Convolution\n",
    "    if strides == 2:\n",
    "        x = layers.ZeroPadding2D(padding=correct_pad(backend, x, kernel_size),\n",
    "                                 name=name + 'dwconv_pad')(x)\n",
    "        conv_pad = 'valid'\n",
    "    else:\n",
    "        conv_pad = 'same'\n",
    "    x = layers.DepthwiseConv2D(kernel_size,\n",
    "                               strides=strides,\n",
    "                               padding=conv_pad,\n",
    "                               use_bias=False,\n",
    "                               depthwise_initializer=CONV_KERNEL_INITIALIZER,\n",
    "                               name=name + 'dwconv')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name=name + 'bn')(x)\n",
    "    x = layers.Activation(activation_fn, name=name + 'activation')(x)\n",
    "\n",
    "    # Squeeze and Excitation phase\n",
    "    if 0 < se_ratio <= 1:\n",
    "        filters_se = max(1, int(filters_in * se_ratio))\n",
    "        se = layers.GlobalAveragePooling2D(name=name + 'se_squeeze')(x)\n",
    "        if bn_axis == 1:\n",
    "            se = layers.Reshape((filters, 1, 1), name=name + 'se_reshape')(se)\n",
    "        else:\n",
    "            se = layers.Reshape((1, 1, filters), name=name + 'se_reshape')(se)\n",
    "        #se = layers.Conv2D(filters_se, 1,\n",
    "        #                   padding='same',\n",
    "        #                   activation=activation_fn,\n",
    "        #                   kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "        #                   name=name + 'se_reduce')(se)\n",
    "        print(\"kPointwiseConv2D 1v se = \", se)\n",
    "        se = kPointwiseConv2D(last_tensor=se, filters=filters_se, channel_axis=bn_axis, name=name+'se_reduce', activation=activation_fn, has_batch_norm=False, use_bias=True, kType=kType)\n",
    "        #se = layers.Conv2D(filters, 1,\n",
    "        #                   padding='same',\n",
    "        #                   activation='sigmoid',\n",
    "        #                   kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "        #                   name=name + 'se_expand')(se)\n",
    "        print(\"kPointwiseConv3D 2v se = \", se)\n",
    "        se = kPointwiseConv2D(last_tensor=se, filters=filters, channel_axis=bn_axis, name=name+'se_expand', activation='sigmoid', has_batch_norm=False, use_bias=True, kType=kType)\n",
    "        x = layers.multiply([x, se], name=name + 'se_excite')\n",
    "\n",
    "    # Output phase\n",
    "    #x = layers.Conv2D(filters_out, 1,\n",
    "    #                  padding='same',\n",
    "    #                  use_bias=False,\n",
    "    #                  kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "    #                  name=name + 'project_conv')(x)\n",
    "    # x = layers.BatchNormalization(axis=bn_axis, name=name + 'project_bn')(x)\n",
    "    x = cai.layers.kPointwiseConv2D(last_tensor=x, filters=filters_out, channel_axis=bn_axis, name=name+'project_conv', activation=None, has_batch_norm=True, use_bias=False, kType=kType)\n",
    "\n",
    "    if (drop_rate > 0)  and (dropout_all_blocks):\n",
    "        x = layers.Dropout(drop_rate,\n",
    "                noise_shape=(None, 1, 1, 1),\n",
    "                name=name + 'drop')(x)\n",
    "\n",
    "    if (id_skip is True and strides == 1 and filters_in == filters_out):\n",
    "        if (drop_rate > 0)  and (not dropout_all_blocks):\n",
    "            x = layers.Dropout(drop_rate,\n",
    "                               noise_shape=(None, 1, 1, 1),\n",
    "                               name=name + 'drop')(x)\n",
    "        x = layers.add([x, inputs], name=name + 'add')\n",
    "    return x\n",
    "\n",
    "def kblockLastName(drop_rate=0., name='',\n",
    "          filters_in=32, filters_out=16, strides=1,\n",
    "          id_skip=True,\n",
    "          dropout_all_blocks=False):\n",
    "    last_name = name + 'project_conv'\n",
    "\n",
    "    if (drop_rate > 0)  and (dropout_all_blocks):\n",
    "        last_name = name + 'drop'\n",
    "\n",
    "    if (id_skip is True and strides == 1 and filters_in == filters_out):\n",
    "        last_name = name + 'add'\n",
    "    return last_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/joaopauloschuler/k-neural-api/blob/master/cai/efficientnet.py\n",
    "\n",
    "def kEffNet2D(\n",
    "        width_coefficient,\n",
    "        depth_coefficient,\n",
    "        skip_stride_cnt=-1,\n",
    "        dropout_rate=0.2,\n",
    "        drop_connect_rate=0.2,\n",
    "        depth_divisor=8,\n",
    "        activation_fn=swish,\n",
    "        blocks_args=DEFAULT_BLOCKS_ARGS,\n",
    "        model_name='efficientnet',\n",
    "        include_top=True,\n",
    "        input_tensor=None,\n",
    "        input_shape=None,\n",
    "        pooling=None,\n",
    "        classes=1000,\n",
    "        kType=2,\n",
    "        concat_paths=True,\n",
    "        dropout_all_blocks=False,\n",
    "        name_prefix='k_',\n",
    "        **kwargs):\n",
    "    \"\"\"Instantiates the EfficientNet architecture using given scaling coefficients.\n",
    "    Optionally loads weights pre-trained on ImageNet.\n",
    "    Note that the data format convention used by the model is\n",
    "    the one specified in your Keras config at `~/.keras/keras.json`.\n",
    "    # Arguments\n",
    "        width_coefficient: float, scaling coefficient for network width.\n",
    "        depth_coefficient: float, scaling coefficient for network depth.\n",
    "        skip_stride_cnt: number of layers to skip stride. This parameter is used with smalll images such as CIFAR-10.\n",
    "        dropout_rate: float, dropout rate before final classifier layer.\n",
    "        drop_connect_rate: float, dropout rate at skip connections.\n",
    "        depth_divisor: integer, a unit of network width.\n",
    "        activation_fn: activation function.\n",
    "        blocks_args: list of dicts, parameters to construct block modules.\n",
    "        model_name: string, model name.\n",
    "        include_top: whether to include the fully-connected\n",
    "            layer at the top of the network.\n",
    "        input_tensor: optional Keras tensor\n",
    "            (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False.\n",
    "            It should have exactly 3 inputs channels.\n",
    "        pooling: optional pooling mode for feature extraction\n",
    "            when `include_top` is `False`.\n",
    "            - `None` means that the output of the model will be\n",
    "                the 4D tensor output of the\n",
    "                last convolutional layer.\n",
    "            - `avg` means that global average pooling\n",
    "                will be applied to the output of the\n",
    "                last convolutional layer, and thus\n",
    "                the output of the model will be a 2D tensor.\n",
    "            - `max` means that global max pooling will\n",
    "                be applied.\n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    # Raises\n",
    "        ValueError: in case of invalid input shape.\n",
    "    \"\"\"\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = layers.Input(shape=input_shape)\n",
    "    else:\n",
    "        if not backend.is_keras_tensor(input_tensor):\n",
    "            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    bn_axis = 3\n",
    "\n",
    "    def round_filters(filters, divisor=depth_divisor):\n",
    "        \"\"\"Round number of filters based on depth multiplier.\"\"\"\n",
    "        filters *= width_coefficient\n",
    "        new_filters = max(divisor, int(filters + divisor / 2) // divisor * divisor)\n",
    "        # Make sure that round down does not go down by more than 10%.\n",
    "        if new_filters < 0.9 * filters:\n",
    "            new_filters += divisor\n",
    "        return int(new_filters)\n",
    "\n",
    "    def round_repeats(repeats):\n",
    "        \"\"\"Round number of repeats based on depth multiplier.\"\"\"\n",
    "        return int(math.ceil(depth_coefficient * repeats))\n",
    "\n",
    "    if isinstance(kType, (int)):\n",
    "        kTypeList = [kType]\n",
    "    else:\n",
    "        kTypeList = kType\n",
    "    \n",
    "    # Build stem\n",
    "    x = img_input\n",
    "    print(\"213 \", img_input)\n",
    "    x = layers.ZeroPadding2D(padding=correct_pad(backend, x, 3),\n",
    "                             name=name_prefix+'stem_conv_pad')(x)\n",
    "    print(\"214 \", x)\n",
    "    first_stride = 1 if skip_stride_cnt >= 0 else 2\n",
    "    x = layers.Conv2D(round_filters(32), 3,\n",
    "                      strides=first_stride,\n",
    "                      padding='valid',\n",
    "                      use_bias=False,\n",
    "                      kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "                      name=name_prefix+'stem_conv')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name=name_prefix+'stem_bn')(x)\n",
    "    x = layers.Activation(activation_fn, name=name_prefix+'stem_activation')(x)\n",
    "\n",
    "    root_layer = x\n",
    "    output_layers = []\n",
    "    path_cnt = 0\n",
    "    for kType in kTypeList:\n",
    "        x = root_layer\n",
    "        blocks_args_cp = deepcopy(blocks_args)\n",
    "        b = 0\n",
    "        blocks = float(sum(args['repeats'] for args in blocks_args_cp))\n",
    "        #only the first branch can backpropagate to the input.\n",
    "        #if path_cnt>0:\n",
    "        #    x = keras.layers.Lambda(lambda x: tensorflow.stop_gradient(x))(x)\n",
    "        for (i, args) in enumerate(blocks_args_cp):\n",
    "            assert args['repeats'] > 0\n",
    "            # Update block input and output filters based on depth multiplier.\n",
    "            args['filters_in'] = round_filters(args['filters_in'])\n",
    "            args['filters_out'] = round_filters(args['filters_out'])\n",
    "\n",
    "            for j in range(round_repeats(args.pop('repeats'))):\n",
    "                #should skip the stride\n",
    "                if (skip_stride_cnt > i) and (j == 0) and (args['strides'] > 1):\n",
    "                    args['strides'] = 1\n",
    "                # The first block needs to take care of stride and filter size increase.\n",
    "                if (j > 0):\n",
    "                    args['strides'] = 1\n",
    "                    args['filters_in'] = args['filters_out']\n",
    "                print(\"x = kblock before    \", x)\n",
    "                x = kblock(x, activation_fn, drop_connect_rate * b / blocks,\n",
    "                          name=name_prefix+'block{}{}_'.format(i + 1, chr(j + 97))+'_'+str(path_cnt), **args,\n",
    "                          kType=kType, dropout_all_blocks=dropout_all_blocks)\n",
    "                print(\"x = kblock after \", x)\n",
    "                b += 1\n",
    "        if (len(kTypeList)>1):\n",
    "            x = layers.Activation('relu', name=name_prefix+'end_relu'+'_'+str(path_cnt))(x)\n",
    "        output_layers.append(x)\n",
    "        path_cnt = path_cnt +1\n",
    "        \n",
    "    if (len(output_layers)==1):\n",
    "        x = output_layers[0]\n",
    "    else:\n",
    "        if concat_paths:\n",
    "            x = keras.layers.Concatenate(axis=bn_axis, name=name_prefix+'global_concat')(output_layers)\n",
    "        else:\n",
    "            x = keras.layers.add(output_layers, name=name_prefix+'global_add')\n",
    "\n",
    "    # Build top\n",
    "    #x = layers.Conv2D(round_filters(1280), 1,\n",
    "    #                  padding='same',\n",
    "    #                  use_bias=False,\n",
    "    #                  kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "    #                  name='top_conv')(x)\n",
    "    #x = layers.BatchNormalization(axis=bn_axis, name='top_bn')(x)\n",
    "    #x = layers.Activation(activation_fn, name='top_activation')(x)\n",
    "    x = cai.layers.kPointwiseConv2D(last_tensor=x, filters=round_filters(1280), channel_axis=bn_axis, name=name_prefix+'top_conv', activation=None, has_batch_norm=True, use_bias=False, kType=kType)\n",
    "    print(\"x = cai.layers.kPointwiseConv2D  \", x)\n",
    "    if pooling == 'avg':\n",
    "        x = layers.GlobalAveragePooling2D(name=name_prefix+'avg_pool')(x)\n",
    "    elif pooling == 'max':\n",
    "        x = layers.GlobalMaxPooling2D(name=name_prefix+'max_pool')(x)\n",
    "    elif pooling == 'avgmax':\n",
    "        x = cai.layers.GlobalAverageMaxPooling2D(x, name=name_prefix+'avgmax_pool')\n",
    "\n",
    "    if include_top:\n",
    "        if (dropout_rate > 0):\n",
    "            x = layers.Dropout(dropout_rate, name=name_prefix+'top_dropout')(x)\n",
    "        x = layers.Dense(classes,\n",
    "            activation='softmax', # 'softmax'\n",
    "            kernel_initializer=DENSE_KERNEL_INITIALIZER,\n",
    "            name=name_prefix+'probs')(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = utils.get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "\n",
    "    # Create model.\n",
    "    model = models.Model(inputs, x, name=model_name)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kEfficientNetB0(include_top=True,\n",
    "                   input_tensor=None,\n",
    "                   input_shape=None,\n",
    "                   pooling='avg',\n",
    "                   classes=1000,\n",
    "                   kType=2,\n",
    "                   dropout_rate=0.2,\n",
    "                   drop_connect_rate=0.2,\n",
    "                   skip_stride_cnt=-1,\n",
    "                   activation_fn=swish,\n",
    "                   dropout_all_blocks=False,\n",
    "                   **kwargs):\n",
    "    return kEffNet2D(1.0, 1.0, skip_stride_cnt=skip_stride_cnt, # 224,\n",
    "                        model_name='kEffNet-b0',\n",
    "                        include_top=include_top,\n",
    "                        input_tensor=input_tensor, input_shape=input_shape,\n",
    "                        pooling=pooling, classes=classes,\n",
    "                        kType=kType,\n",
    "                        dropout_rate=dropout_rate,\n",
    "                        drop_connect_rate=drop_connect_rate,\n",
    "                        activation_fn=activation_fn,\n",
    "                        dropout_all_blocks=dropout_all_blocks,\n",
    "                        **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213  KerasTensor(type_spec=TensorSpec(shape=(None, 32, 32, 1), dtype=tf.float32, name='input_9'), name='input_9', description=\"created by layer 'input_9'\")\n",
      "(32, 32) channels_last\n",
      "is_inst True\n",
      "214  KerasTensor(type_spec=TensorSpec(shape=(None, 33, 33, 1), dtype=tf.float32, name=None), name='k_stem_conv_pad/Pad:0', description=\"created by layer 'k_stem_conv_pad'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 32), dtype=tf.float32, name=None), name='k_stem_activation/mul:0', description=\"created by layer 'k_stem_activation'\")\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 32), dtype=tf.float32, name=None), name='k_block1a__0se_reshape/Reshape:0', description=\"created by layer 'k_block1a__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 32), dtype=tf.float32, name=None), name='k_block1a__0se_reshape/Reshape:0', description=\"created by layer 'k_block1a__0se_reshape'\")\n",
      "prev_layer_channel_count  32\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 8), dtype=tf.float32, name=None), name='k_block1a__0se_reduce/mul:0', description=\"created by layer 'k_block1a__0se_reduce'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 8), dtype=tf.float32, name=None), name='k_block1a__0se_reduce/mul:0', description=\"created by layer 'k_block1a__0se_reduce'\")\n",
      "prev_layer_channel_count  8\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 32), dtype=tf.float32, name=None), name='k_block1a__0se_excite/mul:0', description=\"created by layer 'k_block1a__0se_excite'\")\n",
      "prev_layer_channel_count  32\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 16), dtype=tf.float32, name=None), name='k_block1a__0project_conv_bn/FusedBatchNormV3:0', description=\"created by layer 'k_block1a__0project_conv_bn'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 16), dtype=tf.float32, name=None), name='k_block1a__0project_conv_bn/FusedBatchNormV3:0', description=\"created by layer 'k_block1a__0project_conv_bn'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 16), dtype=tf.float32, name=None), name='k_block1a__0project_conv_bn/FusedBatchNormV3:0', description=\"created by layer 'k_block1a__0project_conv_bn'\")\n",
      "prev_layer_channel_count  16\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 96), dtype=tf.float32, name=None), name='k_block2a__0se_reshape/Reshape:0', description=\"created by layer 'k_block2a__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 96), dtype=tf.float32, name=None), name='k_block2a__0se_reshape/Reshape:0', description=\"created by layer 'k_block2a__0se_reshape'\")\n",
      "prev_layer_channel_count  96\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 4), dtype=tf.float32, name=None), name='k_block2a__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block2a__0se_reduce_inter_group_add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 4), dtype=tf.float32, name=None), name='k_block2a__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block2a__0se_reduce_inter_group_add'\")\n",
      "prev_layer_channel_count  4\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 96), dtype=tf.float32, name=None), name='k_block2a__0se_excite/mul:0', description=\"created by layer 'k_block2a__0se_excite'\")\n",
      "prev_layer_channel_count  96\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 24), dtype=tf.float32, name=None), name='k_block2a__0project_conv_inter_group_add/add:0', description=\"created by layer 'k_block2a__0project_conv_inter_group_add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 24), dtype=tf.float32, name=None), name='k_block2a__0project_conv_inter_group_add/add:0', description=\"created by layer 'k_block2a__0project_conv_inter_group_add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 24), dtype=tf.float32, name=None), name='k_block2a__0project_conv_inter_group_add/add:0', description=\"created by layer 'k_block2a__0project_conv_inter_group_add'\")\n",
      "prev_layer_channel_count  24\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 144), dtype=tf.float32, name=None), name='k_block2b__0se_reshape/Reshape:0', description=\"created by layer 'k_block2b__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 144), dtype=tf.float32, name=None), name='k_block2b__0se_reshape/Reshape:0', description=\"created by layer 'k_block2b__0se_reshape'\")\n",
      "prev_layer_channel_count  144\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 6), dtype=tf.float32, name=None), name='k_block2b__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block2b__0se_reduce_inter_group_add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 6), dtype=tf.float32, name=None), name='k_block2b__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block2b__0se_reduce_inter_group_add'\")\n",
      "prev_layer_channel_count  6\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 144), dtype=tf.float32, name=None), name='k_block2b__0se_excite/mul:0', description=\"created by layer 'k_block2b__0se_excite'\")\n",
      "prev_layer_channel_count  144\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 24), dtype=tf.float32, name=None), name='k_block2b__0add/add:0', description=\"created by layer 'k_block2b__0add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 24), dtype=tf.float32, name=None), name='k_block2b__0add/add:0', description=\"created by layer 'k_block2b__0add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 24), dtype=tf.float32, name=None), name='k_block2b__0add/add:0', description=\"created by layer 'k_block2b__0add'\")\n",
      "prev_layer_channel_count  24\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 144), dtype=tf.float32, name=None), name='k_block3a__0se_reshape/Reshape:0', description=\"created by layer 'k_block3a__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 144), dtype=tf.float32, name=None), name='k_block3a__0se_reshape/Reshape:0', description=\"created by layer 'k_block3a__0se_reshape'\")\n",
      "prev_layer_channel_count  144\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 6), dtype=tf.float32, name=None), name='k_block3a__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block3a__0se_reduce_inter_group_add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 6), dtype=tf.float32, name=None), name='k_block3a__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block3a__0se_reduce_inter_group_add'\")\n",
      "prev_layer_channel_count  6\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 144), dtype=tf.float32, name=None), name='k_block3a__0se_excite/mul:0', description=\"created by layer 'k_block3a__0se_excite'\")\n",
      "prev_layer_channel_count  144\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 40), dtype=tf.float32, name=None), name='k_block3a__0project_conv_inter_group_add/add:0', description=\"created by layer 'k_block3a__0project_conv_inter_group_add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 40), dtype=tf.float32, name=None), name='k_block3a__0project_conv_inter_group_add/add:0', description=\"created by layer 'k_block3a__0project_conv_inter_group_add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 40), dtype=tf.float32, name=None), name='k_block3a__0project_conv_inter_group_add/add:0', description=\"created by layer 'k_block3a__0project_conv_inter_group_add'\")\n",
      "prev_layer_channel_count  40\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 240), dtype=tf.float32, name=None), name='k_block3b__0se_reshape/Reshape:0', description=\"created by layer 'k_block3b__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 240), dtype=tf.float32, name=None), name='k_block3b__0se_reshape/Reshape:0', description=\"created by layer 'k_block3b__0se_reshape'\")\n",
      "prev_layer_channel_count  240\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 10), dtype=tf.float32, name=None), name='k_block3b__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block3b__0se_reduce_inter_group_add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 10), dtype=tf.float32, name=None), name='k_block3b__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block3b__0se_reduce_inter_group_add'\")\n",
      "prev_layer_channel_count  10\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 240), dtype=tf.float32, name=None), name='k_block3b__0se_excite/mul:0', description=\"created by layer 'k_block3b__0se_excite'\")\n",
      "prev_layer_channel_count  240\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 40), dtype=tf.float32, name=None), name='k_block3b__0add/add:0', description=\"created by layer 'k_block3b__0add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 40), dtype=tf.float32, name=None), name='k_block3b__0add/add:0', description=\"created by layer 'k_block3b__0add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 40), dtype=tf.float32, name=None), name='k_block3b__0add/add:0', description=\"created by layer 'k_block3b__0add'\")\n",
      "prev_layer_channel_count  40\n",
      "(31, 31) channels_last\n",
      "is_inst True\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 240), dtype=tf.float32, name=None), name='k_block4a__0se_reshape/Reshape:0', description=\"created by layer 'k_block4a__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 240), dtype=tf.float32, name=None), name='k_block4a__0se_reshape/Reshape:0', description=\"created by layer 'k_block4a__0se_reshape'\")\n",
      "prev_layer_channel_count  240\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 10), dtype=tf.float32, name=None), name='k_block4a__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block4a__0se_reduce_inter_group_add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 10), dtype=tf.float32, name=None), name='k_block4a__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block4a__0se_reduce_inter_group_add'\")\n",
      "prev_layer_channel_count  10\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 240), dtype=tf.float32, name=None), name='k_block4a__0se_excite/mul:0', description=\"created by layer 'k_block4a__0se_excite'\")\n",
      "prev_layer_channel_count  240\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 80), dtype=tf.float32, name=None), name='k_block4a__0project_conv_inter_group_add/add:0', description=\"created by layer 'k_block4a__0project_conv_inter_group_add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 80), dtype=tf.float32, name=None), name='k_block4a__0project_conv_inter_group_add/add:0', description=\"created by layer 'k_block4a__0project_conv_inter_group_add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 80), dtype=tf.float32, name=None), name='k_block4a__0project_conv_inter_group_add/add:0', description=\"created by layer 'k_block4a__0project_conv_inter_group_add'\")\n",
      "prev_layer_channel_count  80\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 480), dtype=tf.float32, name=None), name='k_block4b__0se_reshape/Reshape:0', description=\"created by layer 'k_block4b__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 480), dtype=tf.float32, name=None), name='k_block4b__0se_reshape/Reshape:0', description=\"created by layer 'k_block4b__0se_reshape'\")\n",
      "prev_layer_channel_count  480\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 20), dtype=tf.float32, name=None), name='k_block4b__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block4b__0se_reduce_inter_group_add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 20), dtype=tf.float32, name=None), name='k_block4b__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block4b__0se_reduce_inter_group_add'\")\n",
      "prev_layer_channel_count  20\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 480), dtype=tf.float32, name=None), name='k_block4b__0se_excite/mul:0', description=\"created by layer 'k_block4b__0se_excite'\")\n",
      "prev_layer_channel_count  480\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 80), dtype=tf.float32, name=None), name='k_block4b__0add/add:0', description=\"created by layer 'k_block4b__0add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 80), dtype=tf.float32, name=None), name='k_block4b__0add/add:0', description=\"created by layer 'k_block4b__0add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 80), dtype=tf.float32, name=None), name='k_block4b__0add/add:0', description=\"created by layer 'k_block4b__0add'\")\n",
      "prev_layer_channel_count  80\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 480), dtype=tf.float32, name=None), name='k_block4c__0se_reshape/Reshape:0', description=\"created by layer 'k_block4c__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 480), dtype=tf.float32, name=None), name='k_block4c__0se_reshape/Reshape:0', description=\"created by layer 'k_block4c__0se_reshape'\")\n",
      "prev_layer_channel_count  480\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 20), dtype=tf.float32, name=None), name='k_block4c__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block4c__0se_reduce_inter_group_add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 20), dtype=tf.float32, name=None), name='k_block4c__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block4c__0se_reduce_inter_group_add'\")\n",
      "prev_layer_channel_count  20\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 480), dtype=tf.float32, name=None), name='k_block4c__0se_excite/mul:0', description=\"created by layer 'k_block4c__0se_excite'\")\n",
      "prev_layer_channel_count  480\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 80), dtype=tf.float32, name=None), name='k_block4c__0add/add:0', description=\"created by layer 'k_block4c__0add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 80), dtype=tf.float32, name=None), name='k_block4c__0add/add:0', description=\"created by layer 'k_block4c__0add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 80), dtype=tf.float32, name=None), name='k_block4c__0add/add:0', description=\"created by layer 'k_block4c__0add'\")\n",
      "prev_layer_channel_count  80\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 480), dtype=tf.float32, name=None), name='k_block5a__0se_reshape/Reshape:0', description=\"created by layer 'k_block5a__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 480), dtype=tf.float32, name=None), name='k_block5a__0se_reshape/Reshape:0', description=\"created by layer 'k_block5a__0se_reshape'\")\n",
      "prev_layer_channel_count  480\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 20), dtype=tf.float32, name=None), name='k_block5a__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block5a__0se_reduce_inter_group_add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 20), dtype=tf.float32, name=None), name='k_block5a__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block5a__0se_reduce_inter_group_add'\")\n",
      "prev_layer_channel_count  20\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 480), dtype=tf.float32, name=None), name='k_block5a__0se_excite/mul:0', description=\"created by layer 'k_block5a__0se_excite'\")\n",
      "prev_layer_channel_count  480\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 112), dtype=tf.float32, name=None), name='k_block5a__0project_conv_inter_group_add/add:0', description=\"created by layer 'k_block5a__0project_conv_inter_group_add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 112), dtype=tf.float32, name=None), name='k_block5a__0project_conv_inter_group_add/add:0', description=\"created by layer 'k_block5a__0project_conv_inter_group_add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 112), dtype=tf.float32, name=None), name='k_block5a__0project_conv_inter_group_add/add:0', description=\"created by layer 'k_block5a__0project_conv_inter_group_add'\")\n",
      "prev_layer_channel_count  112\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 672), dtype=tf.float32, name=None), name='k_block5b__0se_reshape/Reshape:0', description=\"created by layer 'k_block5b__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 672), dtype=tf.float32, name=None), name='k_block5b__0se_reshape/Reshape:0', description=\"created by layer 'k_block5b__0se_reshape'\")\n",
      "prev_layer_channel_count  672\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 28), dtype=tf.float32, name=None), name='k_block5b__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block5b__0se_reduce_inter_group_add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 28), dtype=tf.float32, name=None), name='k_block5b__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block5b__0se_reduce_inter_group_add'\")\n",
      "prev_layer_channel_count  28\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 672), dtype=tf.float32, name=None), name='k_block5b__0se_excite/mul:0', description=\"created by layer 'k_block5b__0se_excite'\")\n",
      "prev_layer_channel_count  672\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 112), dtype=tf.float32, name=None), name='k_block5b__0add/add:0', description=\"created by layer 'k_block5b__0add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 112), dtype=tf.float32, name=None), name='k_block5b__0add/add:0', description=\"created by layer 'k_block5b__0add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 112), dtype=tf.float32, name=None), name='k_block5b__0add/add:0', description=\"created by layer 'k_block5b__0add'\")\n",
      "prev_layer_channel_count  112\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 672), dtype=tf.float32, name=None), name='k_block5c__0se_reshape/Reshape:0', description=\"created by layer 'k_block5c__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 672), dtype=tf.float32, name=None), name='k_block5c__0se_reshape/Reshape:0', description=\"created by layer 'k_block5c__0se_reshape'\")\n",
      "prev_layer_channel_count  672\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 28), dtype=tf.float32, name=None), name='k_block5c__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block5c__0se_reduce_inter_group_add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 28), dtype=tf.float32, name=None), name='k_block5c__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block5c__0se_reduce_inter_group_add'\")\n",
      "prev_layer_channel_count  28\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 672), dtype=tf.float32, name=None), name='k_block5c__0se_excite/mul:0', description=\"created by layer 'k_block5c__0se_excite'\")\n",
      "prev_layer_channel_count  672\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 112), dtype=tf.float32, name=None), name='k_block5c__0add/add:0', description=\"created by layer 'k_block5c__0add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 112), dtype=tf.float32, name=None), name='k_block5c__0add/add:0', description=\"created by layer 'k_block5c__0add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 112), dtype=tf.float32, name=None), name='k_block5c__0add/add:0', description=\"created by layer 'k_block5c__0add'\")\n",
      "prev_layer_channel_count  112\n",
      "(16, 16) channels_last\n",
      "is_inst True\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 672), dtype=tf.float32, name=None), name='k_block6a__0se_reshape/Reshape:0', description=\"created by layer 'k_block6a__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 672), dtype=tf.float32, name=None), name='k_block6a__0se_reshape/Reshape:0', description=\"created by layer 'k_block6a__0se_reshape'\")\n",
      "prev_layer_channel_count  672\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 28), dtype=tf.float32, name=None), name='k_block6a__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block6a__0se_reduce_inter_group_add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 28), dtype=tf.float32, name=None), name='k_block6a__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block6a__0se_reduce_inter_group_add'\")\n",
      "prev_layer_channel_count  28\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 672), dtype=tf.float32, name=None), name='k_block6a__0se_excite/mul:0', description=\"created by layer 'k_block6a__0se_excite'\")\n",
      "prev_layer_channel_count  672\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 192), dtype=tf.float32, name=None), name='k_block6a__0project_conv_inter_group_add/add:0', description=\"created by layer 'k_block6a__0project_conv_inter_group_add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 192), dtype=tf.float32, name=None), name='k_block6a__0project_conv_inter_group_add/add:0', description=\"created by layer 'k_block6a__0project_conv_inter_group_add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 192), dtype=tf.float32, name=None), name='k_block6a__0project_conv_inter_group_add/add:0', description=\"created by layer 'k_block6a__0project_conv_inter_group_add'\")\n",
      "prev_layer_channel_count  192\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 1152), dtype=tf.float32, name=None), name='k_block6b__0se_reshape/Reshape:0', description=\"created by layer 'k_block6b__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 1152), dtype=tf.float32, name=None), name='k_block6b__0se_reshape/Reshape:0', description=\"created by layer 'k_block6b__0se_reshape'\")\n",
      "prev_layer_channel_count  1152\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 48), dtype=tf.float32, name=None), name='k_block6b__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block6b__0se_reduce_inter_group_add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 48), dtype=tf.float32, name=None), name='k_block6b__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block6b__0se_reduce_inter_group_add'\")\n",
      "prev_layer_channel_count  48\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 1152), dtype=tf.float32, name=None), name='k_block6b__0se_excite/mul:0', description=\"created by layer 'k_block6b__0se_excite'\")\n",
      "prev_layer_channel_count  1152\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 192), dtype=tf.float32, name=None), name='k_block6b__0add/add:0', description=\"created by layer 'k_block6b__0add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 192), dtype=tf.float32, name=None), name='k_block6b__0add/add:0', description=\"created by layer 'k_block6b__0add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 192), dtype=tf.float32, name=None), name='k_block6b__0add/add:0', description=\"created by layer 'k_block6b__0add'\")\n",
      "prev_layer_channel_count  192\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 1152), dtype=tf.float32, name=None), name='k_block6c__0se_reshape/Reshape:0', description=\"created by layer 'k_block6c__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 1152), dtype=tf.float32, name=None), name='k_block6c__0se_reshape/Reshape:0', description=\"created by layer 'k_block6c__0se_reshape'\")\n",
      "prev_layer_channel_count  1152\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 48), dtype=tf.float32, name=None), name='k_block6c__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block6c__0se_reduce_inter_group_add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 48), dtype=tf.float32, name=None), name='k_block6c__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block6c__0se_reduce_inter_group_add'\")\n",
      "prev_layer_channel_count  48\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 1152), dtype=tf.float32, name=None), name='k_block6c__0se_excite/mul:0', description=\"created by layer 'k_block6c__0se_excite'\")\n",
      "prev_layer_channel_count  1152\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 192), dtype=tf.float32, name=None), name='k_block6c__0add/add:0', description=\"created by layer 'k_block6c__0add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 192), dtype=tf.float32, name=None), name='k_block6c__0add/add:0', description=\"created by layer 'k_block6c__0add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 192), dtype=tf.float32, name=None), name='k_block6c__0add/add:0', description=\"created by layer 'k_block6c__0add'\")\n",
      "prev_layer_channel_count  192\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 1152), dtype=tf.float32, name=None), name='k_block6d__0se_reshape/Reshape:0', description=\"created by layer 'k_block6d__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 1152), dtype=tf.float32, name=None), name='k_block6d__0se_reshape/Reshape:0', description=\"created by layer 'k_block6d__0se_reshape'\")\n",
      "prev_layer_channel_count  1152\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 48), dtype=tf.float32, name=None), name='k_block6d__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block6d__0se_reduce_inter_group_add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 48), dtype=tf.float32, name=None), name='k_block6d__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block6d__0se_reduce_inter_group_add'\")\n",
      "prev_layer_channel_count  48\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 1152), dtype=tf.float32, name=None), name='k_block6d__0se_excite/mul:0', description=\"created by layer 'k_block6d__0se_excite'\")\n",
      "prev_layer_channel_count  1152\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 192), dtype=tf.float32, name=None), name='k_block6d__0add/add:0', description=\"created by layer 'k_block6d__0add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 192), dtype=tf.float32, name=None), name='k_block6d__0add/add:0', description=\"created by layer 'k_block6d__0add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 192), dtype=tf.float32, name=None), name='k_block6d__0add/add:0', description=\"created by layer 'k_block6d__0add'\")\n",
      "prev_layer_channel_count  192\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 1152), dtype=tf.float32, name=None), name='k_block7a__0se_reshape/Reshape:0', description=\"created by layer 'k_block7a__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 1152), dtype=tf.float32, name=None), name='k_block7a__0se_reshape/Reshape:0', description=\"created by layer 'k_block7a__0se_reshape'\")\n",
      "prev_layer_channel_count  1152\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 48), dtype=tf.float32, name=None), name='k_block7a__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block7a__0se_reduce_inter_group_add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 48), dtype=tf.float32, name=None), name='k_block7a__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block7a__0se_reduce_inter_group_add'\")\n",
      "prev_layer_channel_count  48\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 1152), dtype=tf.float32, name=None), name='k_block7a__0se_excite/mul:0', description=\"created by layer 'k_block7a__0se_excite'\")\n",
      "prev_layer_channel_count  1152\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 320), dtype=tf.float32, name=None), name='k_block7a__0project_conv_inter_group_add/add:0', description=\"created by layer 'k_block7a__0project_conv_inter_group_add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 320), dtype=tf.float32, name=None), name='k_block7a__0project_conv_inter_group_add/add:0', description=\"created by layer 'k_block7a__0project_conv_inter_group_add'\")\n",
      "prev_layer_channel_count  320\n",
      "x = cai.layers.kPointwiseConv2D   KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 1280), dtype=tf.float32, name=None), name='k_top_conv_group_interleaved/concatenate/concat:0', description=\"created by layer 'k_top_conv_group_interleaved'\")\n"
     ]
    }
   ],
   "source": [
    "k = kEffNet2D(width_coefficient = 1.0, depth_coefficient = 1.0, input_shape=(32, 32, 1), skip_stride_cnt=3, kType = cai.layers.D6v3_32ch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n",
      "Processing c:\\users\\stan_\\lidc-idri-preproc\\diploma_work\\efficientnet\\k\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: pandas>=0.22.0 in c:\\users\\stan_\\lidc-idri-preproc\\diploma_work\\efficientnet\\.conda\\lib\\site-packages (from cai==0.1.7) (2.0.1)\n",
      "Requirement already satisfied: scikit-image>=0.15.0 in c:\\users\\stan_\\lidc-idri-preproc\\diploma_work\\efficientnet\\.conda\\lib\\site-packages (from cai==0.1.7) (0.20.0)\n",
      "Requirement already satisfied: opencv-python>=4.1.2.30 in c:\\users\\stan_\\lidc-idri-preproc\\diploma_work\\efficientnet\\.conda\\lib\\site-packages (from cai==0.1.7) (4.7.0.72)\n",
      "Requirement already satisfied: scikit-learn>=0.21.0numpy in c:\\users\\stan_\\lidc-idri-preproc\\diploma_work\\efficientnet\\.conda\\lib\\site-packages (from cai==0.1.7) (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\stan_\\lidc-idri-preproc\\diploma_work\\efficientnet\\.conda\\lib\\site-packages (from opencv-python>=4.1.2.30->cai==0.1.7) (1.24.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\stan_\\lidc-idri-preproc\\diploma_work\\efficientnet\\.conda\\lib\\site-packages (from pandas>=0.22.0->cai==0.1.7) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\stan_\\lidc-idri-preproc\\diploma_work\\efficientnet\\.conda\\lib\\site-packages (from pandas>=0.22.0->cai==0.1.7) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\stan_\\lidc-idri-preproc\\diploma_work\\efficientnet\\.conda\\lib\\site-packages (from pandas>=0.22.0->cai==0.1.7) (2.8.2)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\stan_\\lidc-idri-preproc\\diploma_work\\efficientnet\\.conda\\lib\\site-packages (from scikit-image>=0.15.0->cai==0.1.7) (0.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\stan_\\lidc-idri-preproc\\diploma_work\\efficientnet\\.conda\\lib\\site-packages (from scikit-image>=0.15.0->cai==0.1.7) (2021.7.2)\n",
      "Requirement already satisfied: imageio>=2.4.1 in c:\\users\\stan_\\lidc-idri-preproc\\diploma_work\\efficientnet\\.conda\\lib\\site-packages (from scikit-image>=0.15.0->cai==0.1.7) (2.26.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\stan_\\lidc-idri-preproc\\diploma_work\\efficientnet\\.conda\\lib\\site-packages (from scikit-image>=0.15.0->cai==0.1.7) (23.1)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\stan_\\lidc-idri-preproc\\diploma_work\\efficientnet\\.conda\\lib\\site-packages (from scikit-image>=0.15.0->cai==0.1.7) (3.1)\n",
      "Requirement already satisfied: pillow>=9.0.1 in c:\\users\\stan_\\lidc-idri-preproc\\diploma_work\\efficientnet\\.conda\\lib\\site-packages (from scikit-image>=0.15.0->cai==0.1.7) (9.5.0)\n",
      "Requirement already satisfied: scipy<1.9.2,>=1.8 in c:\\users\\stan_\\lidc-idri-preproc\\diploma_work\\efficientnet\\.conda\\lib\\site-packages (from scikit-image>=0.15.0->cai==0.1.7) (1.9.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\stan_\\lidc-idri-preproc\\diploma_work\\efficientnet\\.conda\\lib\\site-packages (from scikit-image>=0.15.0->cai==0.1.7) (1.4.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\stan_\\lidc-idri-preproc\\diploma_work\\efficientnet\\.conda\\lib\\site-packages (from scikit-learn>=0.21.0numpy->cai==0.1.7) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\stan_\\lidc-idri-preproc\\diploma_work\\efficientnet\\.conda\\lib\\site-packages (from scikit-learn>=0.21.0numpy->cai==0.1.7) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\stan_\\lidc-idri-preproc\\diploma_work\\efficientnet\\.conda\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=0.22.0->cai==0.1.7) (1.16.0)\n",
      "Building wheels for collected packages: cai\n",
      "  Building wheel for cai (setup.py): started\n",
      "  Building wheel for cai (setup.py): finished with status 'done'\n",
      "  Created wheel for cai: filename=cai-0.1.7-py3-none-any.whl size=61790 sha256=6eca24773254efc72b3d8fc26a59535a29a5584964f9efea0674ed3d6a9d92c4\n",
      "  Stored in directory: C:\\Users\\stan_\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-nd50gy68\\wheels\\7d\\bf\\8a\\a9657c0c9e5ef314407831cf13e1c2662ff36e8b5430a7e706\n",
      "Successfully built cai\n",
      "Installing collected packages: cai\n",
      "  Attempting uninstall: cai\n",
      "    Found existing installation: cai 0.1.7\n",
      "    Uninstalling cai-0.1.7:\n",
      "      Successfully uninstalled cai-0.1.7\n",
      "Successfully installed cai-0.1.7\n",
      "Tensorflow version: 2.12.0\n",
      "Keras version: 2.12.0\n",
      "CPU cores: 8\n",
      "RAM: 16.859602944 GB\n",
      "[]\n",
      "train shape (50000, 32, 32, 3)\n",
      "test shape (10000, 32, 32, 3)\n",
      "Original channel  0  min: 0.0  max: 255.0\n",
      "Original channel  1  min: 0.0  max: 255.0\n",
      "Original channel  2  min: 0.0  max: 255.0\n",
      "Loading RGB.\n",
      "Channel  0  min: -2.0  max: 1.984375\n",
      "Channel  1  min: -2.0  max: 1.984375\n",
      "Channel  2  min: -2.0  max: 1.984375\n",
      "Train shapes: (45000, 32, 32, 3) (45000, 10)\n",
      "Validation shapes: (10000, 32, 32, 3) (10000, 10)\n",
      "Test shapes: (10000, 32, 32, 3) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "#@title Global Settings\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.layers\n",
    "import tensorflow.keras.models\n",
    "import tensorflow.keras.datasets\n",
    "from tensorflow.keras import regularizers\n",
    "dataset=tensorflow.keras.datasets.cifar10 #@param [\"tensorflow.keras.datasets.cifar10\", \"tensorflow.keras.datasets.cifar100\", \"tensorflow.keras.datasets.mnist\", \"tensorflow.keras.datasets.fashion_mnist\"] {type:\"raw\"} \n",
    "batch_size=64 # @param [16, 32, 64, 128, 256, 512] {type:\"raw\"} \n",
    "channels_per_group=32 # @param [2, 4, 8, 12, 16, 32] {type:\"raw\"}\n",
    "epochs=50 # @param [2, 25, 50, 75, 100, 100, 200, 400] {type:\"raw\"}\n",
    "verbose=True #@param {type:\"boolean\"}\n",
    "bipolar_input=True #@param {type:\"boolean\"}\n",
    "seed=7\n",
    "\n",
    "if dataset is keras.datasets.cifar10 or dataset is keras.datasets.cifar100:\n",
    "  global_input_shape = (32, 32, 3)\n",
    "else:\n",
    "  global_input_shape = (28, 28, 1)\n",
    "\n",
    "if (dataset==keras.datasets.cifar100):\n",
    "  num_classes = 100\n",
    "else:\n",
    "  num_classes = 10\n",
    "import os\n",
    "if not os.path.isdir('k'):\n",
    "    !git clone -b development16 https://github.com/joaopauloschuler/k-neural-api.git k\n",
    "else:\n",
    "    !cd k && git pull\n",
    "!cd k && pip install .\n",
    "import cai.layers\n",
    "import cai.datasets\n",
    "import cai.efficientnet\n",
    "import cai.util\n",
    "import gc\n",
    "import multiprocessing\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "print(\"Tensorflow version:\", tf.version.VERSION)\n",
    "print(\"Keras version:\", keras.__version__)\n",
    "print(\"CPU cores:\", multiprocessing.cpu_count())\n",
    "import psutil\n",
    "print('RAM:', (psutil.virtual_memory().total / 1e9),'GB')\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "if channels_per_group==2:\n",
    "   kTypes = [cai.layers.D6v3_2ch()]\n",
    "elif channels_per_group==4:\n",
    "   kTypes = [cai.layers.D6v3_4ch()]\n",
    "elif channels_per_group==8:\n",
    "   kTypes = [cai.layers.D6v3_8ch()]\n",
    "elif channels_per_group==12:\n",
    "   kTypes = [cai.layers.D6v3_12ch()]\n",
    "elif channels_per_group==16:\n",
    "   kTypes = [cai.layers.D6v3_16ch()]\n",
    "else:\n",
    "   kTypes = [cai.layers.D6v3_32ch()]\n",
    "\n",
    "   \n",
    "base_model_name='kEffNetV2Example'\n",
    "x_train, y_train, x_val, y_val, x_test, y_test = cai.datasets.load_dataset_with_validation(dataset,\n",
    "  lab=False, verbose=verbose, bipolar=bipolar_input,\n",
    "  base_model_name=base_model_name,\n",
    "  validation_size=0.1, validation_flip_horizontal=True,\n",
    "  validation_flip_vertical=False)\n",
    "print(\"Train shapes:\", x_train.shape, y_train.shape)\n",
    "print(\"Validation shapes:\", x_val.shape, y_val.shape)\n",
    "print(\"Test shapes:\", x_test.shape, y_test.shape)\n",
    "train_datagen = cai.util.create_image_generator(rotation_range=20, \n",
    "  width_shift_range=0.3, height_shift_range=0.3, channel_shift_range=0.0)\n",
    "valid_datagen = cai.util.create_image_generator_no_augmentation()\n",
    "test_datagen = cai.util.create_image_generator_no_augmentation()\n",
    "cpus_num = max([multiprocessing.cpu_count(), 8])\n",
    "\n",
    "def cyclical_adv_lrscheduler25(epoch):\n",
    "    \"\"\"CAI Cyclical and Advanced Learning Rate Scheduler.\n",
    "    # Arguments\n",
    "        epoch: integer with current epoch count.\n",
    "    # Returns\n",
    "        float with desired learning rate.\n",
    "    \"\"\"\n",
    "    base_learning = 0.001\n",
    "    local_epoch = epoch % 25\n",
    "    if local_epoch < 7:\n",
    "       return base_learning * (1 + 0.5*local_epoch)\n",
    "    else:\n",
    "       return (base_learning * 4) * ( 0.85**(local_epoch-7) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45000, 32, 32, 3)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def work_on_efficientnet(show_model=False, run_fit=False, test_results=False, calc_f1=False, kTypes=[]):\n",
    "  monitor='val_loss'\n",
    "  if (show_model):\n",
    "    input_shape = global_input_shape\n",
    "  else:\n",
    "    input_shape = (None, None, global_input_shape[2])\n",
    "  for kType in kTypes:\n",
    "      basefilename = 'kEffNetV2-'+str(kType)\n",
    "      best_result_file_name = basefilename+'-best_result.hdf5'\n",
    "      print('Running: '+basefilename)\n",
    "      model = kEfficientNetB0(\n",
    "        include_top=True,\n",
    "        skip_stride_cnt=3,\n",
    "        input_shape=input_shape,\n",
    "        classes=num_classes,\n",
    "        kType=kType)\n",
    "      \n",
    "      optimizer = keras.optimizers.RMSprop()\n",
    "      model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "      if (show_model): \n",
    "        model.summary(line_length=180)\n",
    "\n",
    "      save_best = keras.callbacks.ModelCheckpoint(\n",
    "            filepath=best_result_file_name,\n",
    "            monitor=monitor,\n",
    "            verbose=1,\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False,\n",
    "            mode='min',\n",
    "            save_freq='epoch')\n",
    "\n",
    "      if (run_fit): \n",
    "            train_flow = train_datagen.flow(\n",
    "                x_train, y_train,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                seed=seed\n",
    "            )\n",
    "            validation_flow = valid_datagen.flow(\n",
    "                x_val, y_val,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False,\n",
    "                seed=seed\n",
    "            )\n",
    "            history = model.fit(\n",
    "              x = train_flow,\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=validation_flow,\n",
    "              callbacks=[save_best, tf.keras.callbacks.LearningRateScheduler(cyclical_adv_lrscheduler25)],\n",
    "              workers=cpus_num,\n",
    "              max_queue_size=128\n",
    "            )\n",
    "            plt.figure()\n",
    "            plt.ylabel(\"Accuracy (training and validation)\")\n",
    "            plt.xlabel(\"Epochs\")\n",
    "            plt.ylim([0,1])\n",
    "            plt.plot(history.history[\"accuracy\"])\n",
    "            plt.plot(history.history[\"val_accuracy\"])\n",
    "      if (test_results):\n",
    "        test_flow = test_datagen.flow(\n",
    "            x_test, y_test,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            seed=seed\n",
    "        )\n",
    "        print('Best Model Results: '+best_result_file_name)\n",
    "        model = cai.models.load_kereas_model(best_result_file_name)\n",
    "        evaluated = model.evaluate(\n",
    "            x=test_flow,\n",
    "            batch_size=batch_size,\n",
    "            use_multiprocessing=False,\n",
    "            workers=cpus_num\n",
    "        )\n",
    "        for metric, name in zip(evaluated,[\"loss\",\"acc\"]):\n",
    "              print(name,metric)\n",
    "      if (calc_f1):\n",
    "        cai.datasets.test_flips_on_saved_model(x_test, y_test, best_result_file_name, has_flip_x=True, has_flip_y=True, has_bw=False, center_crop=0.15)\n",
    "      print('Finished: '+basefilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: kEffNetV2-33\n",
      "213  KerasTensor(type_spec=TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32, name='input_11'), name='input_11', description=\"created by layer 'input_11'\")\n",
      "(32, 32) channels_last\n",
      "is_inst True\n",
      "214  KerasTensor(type_spec=TensorSpec(shape=(None, 33, 33, 3), dtype=tf.float32, name=None), name='k_stem_conv_pad/Pad:0', description=\"created by layer 'k_stem_conv_pad'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 32), dtype=tf.float32, name=None), name='k_stem_activation/mul:0', description=\"created by layer 'k_stem_activation'\")\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 32), dtype=tf.float32, name=None), name='k_block1a__0se_reshape/Reshape:0', description=\"created by layer 'k_block1a__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 32), dtype=tf.float32, name=None), name='k_block1a__0se_reshape/Reshape:0', description=\"created by layer 'k_block1a__0se_reshape'\")\n",
      "prev_layer_channel_count  32\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 8), dtype=tf.float32, name=None), name='k_block1a__0se_reduce_um/mul:0', description=\"created by layer 'k_block1a__0se_reduce_um'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 8), dtype=tf.float32, name=None), name='k_block1a__0se_reduce_um/mul:0', description=\"created by layer 'k_block1a__0se_reduce_um'\")\n",
      "prev_layer_channel_count  8\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 32), dtype=tf.float32, name=None), name='k_block1a__0se_excite/mul:0', description=\"created by layer 'k_block1a__0se_excite'\")\n",
      "prev_layer_channel_count  32\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 16), dtype=tf.float32, name=None), name='k_block1a__0project_conv_um_bn/FusedBatchNormV3:0', description=\"created by layer 'k_block1a__0project_conv_um_bn'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 16), dtype=tf.float32, name=None), name='k_block1a__0project_conv_um_bn/FusedBatchNormV3:0', description=\"created by layer 'k_block1a__0project_conv_um_bn'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 16), dtype=tf.float32, name=None), name='k_block1a__0project_conv_um_bn/FusedBatchNormV3:0', description=\"created by layer 'k_block1a__0project_conv_um_bn'\")\n",
      "prev_layer_channel_count  16\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 96), dtype=tf.float32, name=None), name='k_block2a__0se_reshape/Reshape:0', description=\"created by layer 'k_block2a__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 96), dtype=tf.float32, name=None), name='k_block2a__0se_reshape/Reshape:0', description=\"created by layer 'k_block2a__0se_reshape'\")\n",
      "prev_layer_channel_count  96\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 4), dtype=tf.float32, name=None), name='k_block2a__0se_reduce_iga/add:0', description=\"created by layer 'k_block2a__0se_reduce_iga'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 4), dtype=tf.float32, name=None), name='k_block2a__0se_reduce_iga/add:0', description=\"created by layer 'k_block2a__0se_reduce_iga'\")\n",
      "prev_layer_channel_count  4\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 96), dtype=tf.float32, name=None), name='k_block2a__0se_excite/mul:0', description=\"created by layer 'k_block2a__0se_excite'\")\n",
      "prev_layer_channel_count  96\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 24), dtype=tf.float32, name=None), name='k_block2a__0project_conv_iga/add:0', description=\"created by layer 'k_block2a__0project_conv_iga'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 24), dtype=tf.float32, name=None), name='k_block2a__0project_conv_iga/add:0', description=\"created by layer 'k_block2a__0project_conv_iga'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 24), dtype=tf.float32, name=None), name='k_block2a__0project_conv_iga/add:0', description=\"created by layer 'k_block2a__0project_conv_iga'\")\n",
      "prev_layer_channel_count  24\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 144), dtype=tf.float32, name=None), name='k_block2b__0se_reshape/Reshape:0', description=\"created by layer 'k_block2b__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 144), dtype=tf.float32, name=None), name='k_block2b__0se_reshape/Reshape:0', description=\"created by layer 'k_block2b__0se_reshape'\")\n",
      "prev_layer_channel_count  144\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 6), dtype=tf.float32, name=None), name='k_block2b__0se_reduce_iga/add:0', description=\"created by layer 'k_block2b__0se_reduce_iga'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 6), dtype=tf.float32, name=None), name='k_block2b__0se_reduce_iga/add:0', description=\"created by layer 'k_block2b__0se_reduce_iga'\")\n",
      "prev_layer_channel_count  6\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 144), dtype=tf.float32, name=None), name='k_block2b__0se_excite/mul:0', description=\"created by layer 'k_block2b__0se_excite'\")\n",
      "prev_layer_channel_count  144\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 24), dtype=tf.float32, name=None), name='k_block2b__0add/add:0', description=\"created by layer 'k_block2b__0add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 24), dtype=tf.float32, name=None), name='k_block2b__0add/add:0', description=\"created by layer 'k_block2b__0add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 24), dtype=tf.float32, name=None), name='k_block2b__0add/add:0', description=\"created by layer 'k_block2b__0add'\")\n",
      "prev_layer_channel_count  24\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 144), dtype=tf.float32, name=None), name='k_block3a__0se_reshape/Reshape:0', description=\"created by layer 'k_block3a__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 144), dtype=tf.float32, name=None), name='k_block3a__0se_reshape/Reshape:0', description=\"created by layer 'k_block3a__0se_reshape'\")\n",
      "prev_layer_channel_count  144\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 6), dtype=tf.float32, name=None), name='k_block3a__0se_reduce_iga/add:0', description=\"created by layer 'k_block3a__0se_reduce_iga'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 6), dtype=tf.float32, name=None), name='k_block3a__0se_reduce_iga/add:0', description=\"created by layer 'k_block3a__0se_reduce_iga'\")\n",
      "prev_layer_channel_count  6\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 144), dtype=tf.float32, name=None), name='k_block3a__0se_excite/mul:0', description=\"created by layer 'k_block3a__0se_excite'\")\n",
      "prev_layer_channel_count  144\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 40), dtype=tf.float32, name=None), name='k_block3a__0project_conv_iga/add:0', description=\"created by layer 'k_block3a__0project_conv_iga'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 40), dtype=tf.float32, name=None), name='k_block3a__0project_conv_iga/add:0', description=\"created by layer 'k_block3a__0project_conv_iga'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 40), dtype=tf.float32, name=None), name='k_block3a__0project_conv_iga/add:0', description=\"created by layer 'k_block3a__0project_conv_iga'\")\n",
      "prev_layer_channel_count  40\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 240), dtype=tf.float32, name=None), name='k_block3b__0se_reshape/Reshape:0', description=\"created by layer 'k_block3b__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 240), dtype=tf.float32, name=None), name='k_block3b__0se_reshape/Reshape:0', description=\"created by layer 'k_block3b__0se_reshape'\")\n",
      "prev_layer_channel_count  240\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 10), dtype=tf.float32, name=None), name='k_block3b__0se_reduce_iga/add:0', description=\"created by layer 'k_block3b__0se_reduce_iga'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 10), dtype=tf.float32, name=None), name='k_block3b__0se_reduce_iga/add:0', description=\"created by layer 'k_block3b__0se_reduce_iga'\")\n",
      "prev_layer_channel_count  10\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 240), dtype=tf.float32, name=None), name='k_block3b__0se_excite/mul:0', description=\"created by layer 'k_block3b__0se_excite'\")\n",
      "prev_layer_channel_count  240\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 40), dtype=tf.float32, name=None), name='k_block3b__0add/add:0', description=\"created by layer 'k_block3b__0add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 40), dtype=tf.float32, name=None), name='k_block3b__0add/add:0', description=\"created by layer 'k_block3b__0add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 40), dtype=tf.float32, name=None), name='k_block3b__0add/add:0', description=\"created by layer 'k_block3b__0add'\")\n",
      "prev_layer_channel_count  40\n",
      "(31, 31) channels_last\n",
      "is_inst True\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 240), dtype=tf.float32, name=None), name='k_block4a__0se_reshape/Reshape:0', description=\"created by layer 'k_block4a__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 240), dtype=tf.float32, name=None), name='k_block4a__0se_reshape/Reshape:0', description=\"created by layer 'k_block4a__0se_reshape'\")\n",
      "prev_layer_channel_count  240\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 10), dtype=tf.float32, name=None), name='k_block4a__0se_reduce_iga/add:0', description=\"created by layer 'k_block4a__0se_reduce_iga'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 10), dtype=tf.float32, name=None), name='k_block4a__0se_reduce_iga/add:0', description=\"created by layer 'k_block4a__0se_reduce_iga'\")\n",
      "prev_layer_channel_count  10\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 240), dtype=tf.float32, name=None), name='k_block4a__0se_excite/mul:0', description=\"created by layer 'k_block4a__0se_excite'\")\n",
      "prev_layer_channel_count  240\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 80), dtype=tf.float32, name=None), name='k_block4a__0project_conv_iga/add:0', description=\"created by layer 'k_block4a__0project_conv_iga'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 80), dtype=tf.float32, name=None), name='k_block4a__0project_conv_iga/add:0', description=\"created by layer 'k_block4a__0project_conv_iga'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 80), dtype=tf.float32, name=None), name='k_block4a__0project_conv_iga/add:0', description=\"created by layer 'k_block4a__0project_conv_iga'\")\n",
      "prev_layer_channel_count  80\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 480), dtype=tf.float32, name=None), name='k_block4b__0se_reshape/Reshape:0', description=\"created by layer 'k_block4b__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 480), dtype=tf.float32, name=None), name='k_block4b__0se_reshape/Reshape:0', description=\"created by layer 'k_block4b__0se_reshape'\")\n",
      "prev_layer_channel_count  480\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 20), dtype=tf.float32, name=None), name='k_block4b__0se_reduce_iga/add:0', description=\"created by layer 'k_block4b__0se_reduce_iga'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 20), dtype=tf.float32, name=None), name='k_block4b__0se_reduce_iga/add:0', description=\"created by layer 'k_block4b__0se_reduce_iga'\")\n",
      "prev_layer_channel_count  20\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 480), dtype=tf.float32, name=None), name='k_block4b__0se_excite/mul:0', description=\"created by layer 'k_block4b__0se_excite'\")\n",
      "prev_layer_channel_count  480\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 80), dtype=tf.float32, name=None), name='k_block4b__0add/add:0', description=\"created by layer 'k_block4b__0add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 80), dtype=tf.float32, name=None), name='k_block4b__0add/add:0', description=\"created by layer 'k_block4b__0add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 80), dtype=tf.float32, name=None), name='k_block4b__0add/add:0', description=\"created by layer 'k_block4b__0add'\")\n",
      "prev_layer_channel_count  80\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 480), dtype=tf.float32, name=None), name='k_block4c__0se_reshape/Reshape:0', description=\"created by layer 'k_block4c__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 480), dtype=tf.float32, name=None), name='k_block4c__0se_reshape/Reshape:0', description=\"created by layer 'k_block4c__0se_reshape'\")\n",
      "prev_layer_channel_count  480\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 20), dtype=tf.float32, name=None), name='k_block4c__0se_reduce_iga/add:0', description=\"created by layer 'k_block4c__0se_reduce_iga'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 20), dtype=tf.float32, name=None), name='k_block4c__0se_reduce_iga/add:0', description=\"created by layer 'k_block4c__0se_reduce_iga'\")\n",
      "prev_layer_channel_count  20\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 480), dtype=tf.float32, name=None), name='k_block4c__0se_excite/mul:0', description=\"created by layer 'k_block4c__0se_excite'\")\n",
      "prev_layer_channel_count  480\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 80), dtype=tf.float32, name=None), name='k_block4c__0add/add:0', description=\"created by layer 'k_block4c__0add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 80), dtype=tf.float32, name=None), name='k_block4c__0add/add:0', description=\"created by layer 'k_block4c__0add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 80), dtype=tf.float32, name=None), name='k_block4c__0add/add:0', description=\"created by layer 'k_block4c__0add'\")\n",
      "prev_layer_channel_count  80\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 480), dtype=tf.float32, name=None), name='k_block5a__0se_reshape/Reshape:0', description=\"created by layer 'k_block5a__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 480), dtype=tf.float32, name=None), name='k_block5a__0se_reshape/Reshape:0', description=\"created by layer 'k_block5a__0se_reshape'\")\n",
      "prev_layer_channel_count  480\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 20), dtype=tf.float32, name=None), name='k_block5a__0se_reduce_iga/add:0', description=\"created by layer 'k_block5a__0se_reduce_iga'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 20), dtype=tf.float32, name=None), name='k_block5a__0se_reduce_iga/add:0', description=\"created by layer 'k_block5a__0se_reduce_iga'\")\n",
      "prev_layer_channel_count  20\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 480), dtype=tf.float32, name=None), name='k_block5a__0se_excite/mul:0', description=\"created by layer 'k_block5a__0se_excite'\")\n",
      "prev_layer_channel_count  480\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 112), dtype=tf.float32, name=None), name='k_block5a__0project_conv_iga/add:0', description=\"created by layer 'k_block5a__0project_conv_iga'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 112), dtype=tf.float32, name=None), name='k_block5a__0project_conv_iga/add:0', description=\"created by layer 'k_block5a__0project_conv_iga'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 112), dtype=tf.float32, name=None), name='k_block5a__0project_conv_iga/add:0', description=\"created by layer 'k_block5a__0project_conv_iga'\")\n",
      "prev_layer_channel_count  112\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 672), dtype=tf.float32, name=None), name='k_block5b__0se_reshape/Reshape:0', description=\"created by layer 'k_block5b__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 672), dtype=tf.float32, name=None), name='k_block5b__0se_reshape/Reshape:0', description=\"created by layer 'k_block5b__0se_reshape'\")\n",
      "prev_layer_channel_count  672\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 28), dtype=tf.float32, name=None), name='k_block5b__0se_reduce_iga/add:0', description=\"created by layer 'k_block5b__0se_reduce_iga'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 28), dtype=tf.float32, name=None), name='k_block5b__0se_reduce_iga/add:0', description=\"created by layer 'k_block5b__0se_reduce_iga'\")\n",
      "prev_layer_channel_count  28\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 672), dtype=tf.float32, name=None), name='k_block5b__0se_excite/mul:0', description=\"created by layer 'k_block5b__0se_excite'\")\n",
      "prev_layer_channel_count  672\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 112), dtype=tf.float32, name=None), name='k_block5b__0add/add:0', description=\"created by layer 'k_block5b__0add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 112), dtype=tf.float32, name=None), name='k_block5b__0add/add:0', description=\"created by layer 'k_block5b__0add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 112), dtype=tf.float32, name=None), name='k_block5b__0add/add:0', description=\"created by layer 'k_block5b__0add'\")\n",
      "prev_layer_channel_count  112\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 672), dtype=tf.float32, name=None), name='k_block5c__0se_reshape/Reshape:0', description=\"created by layer 'k_block5c__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 672), dtype=tf.float32, name=None), name='k_block5c__0se_reshape/Reshape:0', description=\"created by layer 'k_block5c__0se_reshape'\")\n",
      "prev_layer_channel_count  672\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 28), dtype=tf.float32, name=None), name='k_block5c__0se_reduce_iga/add:0', description=\"created by layer 'k_block5c__0se_reduce_iga'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 28), dtype=tf.float32, name=None), name='k_block5c__0se_reduce_iga/add:0', description=\"created by layer 'k_block5c__0se_reduce_iga'\")\n",
      "prev_layer_channel_count  28\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 672), dtype=tf.float32, name=None), name='k_block5c__0se_excite/mul:0', description=\"created by layer 'k_block5c__0se_excite'\")\n",
      "prev_layer_channel_count  672\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 112), dtype=tf.float32, name=None), name='k_block5c__0add/add:0', description=\"created by layer 'k_block5c__0add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 112), dtype=tf.float32, name=None), name='k_block5c__0add/add:0', description=\"created by layer 'k_block5c__0add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 112), dtype=tf.float32, name=None), name='k_block5c__0add/add:0', description=\"created by layer 'k_block5c__0add'\")\n",
      "prev_layer_channel_count  112\n",
      "(16, 16) channels_last\n",
      "is_inst True\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 672), dtype=tf.float32, name=None), name='k_block6a__0se_reshape/Reshape:0', description=\"created by layer 'k_block6a__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 672), dtype=tf.float32, name=None), name='k_block6a__0se_reshape/Reshape:0', description=\"created by layer 'k_block6a__0se_reshape'\")\n",
      "prev_layer_channel_count  672\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 28), dtype=tf.float32, name=None), name='k_block6a__0se_reduce_iga/add:0', description=\"created by layer 'k_block6a__0se_reduce_iga'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 28), dtype=tf.float32, name=None), name='k_block6a__0se_reduce_iga/add:0', description=\"created by layer 'k_block6a__0se_reduce_iga'\")\n",
      "prev_layer_channel_count  28\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 672), dtype=tf.float32, name=None), name='k_block6a__0se_excite/mul:0', description=\"created by layer 'k_block6a__0se_excite'\")\n",
      "prev_layer_channel_count  672\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 192), dtype=tf.float32, name=None), name='k_block6a__0project_conv_iga/add:0', description=\"created by layer 'k_block6a__0project_conv_iga'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 192), dtype=tf.float32, name=None), name='k_block6a__0project_conv_iga/add:0', description=\"created by layer 'k_block6a__0project_conv_iga'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 192), dtype=tf.float32, name=None), name='k_block6a__0project_conv_iga/add:0', description=\"created by layer 'k_block6a__0project_conv_iga'\")\n",
      "prev_layer_channel_count  192\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 1152), dtype=tf.float32, name=None), name='k_block6b__0se_reshape/Reshape:0', description=\"created by layer 'k_block6b__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 1152), dtype=tf.float32, name=None), name='k_block6b__0se_reshape/Reshape:0', description=\"created by layer 'k_block6b__0se_reshape'\")\n",
      "prev_layer_channel_count  1152\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 48), dtype=tf.float32, name=None), name='k_block6b__0se_reduce_iga/add:0', description=\"created by layer 'k_block6b__0se_reduce_iga'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 48), dtype=tf.float32, name=None), name='k_block6b__0se_reduce_iga/add:0', description=\"created by layer 'k_block6b__0se_reduce_iga'\")\n",
      "prev_layer_channel_count  48\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 1152), dtype=tf.float32, name=None), name='k_block6b__0se_excite/mul:0', description=\"created by layer 'k_block6b__0se_excite'\")\n",
      "prev_layer_channel_count  1152\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 192), dtype=tf.float32, name=None), name='k_block6b__0add/add:0', description=\"created by layer 'k_block6b__0add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 192), dtype=tf.float32, name=None), name='k_block6b__0add/add:0', description=\"created by layer 'k_block6b__0add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 192), dtype=tf.float32, name=None), name='k_block6b__0add/add:0', description=\"created by layer 'k_block6b__0add'\")\n",
      "prev_layer_channel_count  192\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 1152), dtype=tf.float32, name=None), name='k_block6c__0se_reshape/Reshape:0', description=\"created by layer 'k_block6c__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 1152), dtype=tf.float32, name=None), name='k_block6c__0se_reshape/Reshape:0', description=\"created by layer 'k_block6c__0se_reshape'\")\n",
      "prev_layer_channel_count  1152\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 48), dtype=tf.float32, name=None), name='k_block6c__0se_reduce_iga/add:0', description=\"created by layer 'k_block6c__0se_reduce_iga'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 48), dtype=tf.float32, name=None), name='k_block6c__0se_reduce_iga/add:0', description=\"created by layer 'k_block6c__0se_reduce_iga'\")\n",
      "prev_layer_channel_count  48\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 1152), dtype=tf.float32, name=None), name='k_block6c__0se_excite/mul:0', description=\"created by layer 'k_block6c__0se_excite'\")\n",
      "prev_layer_channel_count  1152\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 192), dtype=tf.float32, name=None), name='k_block6c__0add/add:0', description=\"created by layer 'k_block6c__0add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 192), dtype=tf.float32, name=None), name='k_block6c__0add/add:0', description=\"created by layer 'k_block6c__0add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 192), dtype=tf.float32, name=None), name='k_block6c__0add/add:0', description=\"created by layer 'k_block6c__0add'\")\n",
      "prev_layer_channel_count  192\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 1152), dtype=tf.float32, name=None), name='k_block6d__0se_reshape/Reshape:0', description=\"created by layer 'k_block6d__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 1152), dtype=tf.float32, name=None), name='k_block6d__0se_reshape/Reshape:0', description=\"created by layer 'k_block6d__0se_reshape'\")\n",
      "prev_layer_channel_count  1152\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 48), dtype=tf.float32, name=None), name='k_block6d__0se_reduce_iga/add:0', description=\"created by layer 'k_block6d__0se_reduce_iga'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 48), dtype=tf.float32, name=None), name='k_block6d__0se_reduce_iga/add:0', description=\"created by layer 'k_block6d__0se_reduce_iga'\")\n",
      "prev_layer_channel_count  48\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 1152), dtype=tf.float32, name=None), name='k_block6d__0se_excite/mul:0', description=\"created by layer 'k_block6d__0se_excite'\")\n",
      "prev_layer_channel_count  1152\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 192), dtype=tf.float32, name=None), name='k_block6d__0add/add:0', description=\"created by layer 'k_block6d__0add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 192), dtype=tf.float32, name=None), name='k_block6d__0add/add:0', description=\"created by layer 'k_block6d__0add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 192), dtype=tf.float32, name=None), name='k_block6d__0add/add:0', description=\"created by layer 'k_block6d__0add'\")\n",
      "prev_layer_channel_count  192\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 1152), dtype=tf.float32, name=None), name='k_block7a__0se_reshape/Reshape:0', description=\"created by layer 'k_block7a__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 1152), dtype=tf.float32, name=None), name='k_block7a__0se_reshape/Reshape:0', description=\"created by layer 'k_block7a__0se_reshape'\")\n",
      "prev_layer_channel_count  1152\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 48), dtype=tf.float32, name=None), name='k_block7a__0se_reduce_iga/add:0', description=\"created by layer 'k_block7a__0se_reduce_iga'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 48), dtype=tf.float32, name=None), name='k_block7a__0se_reduce_iga/add:0', description=\"created by layer 'k_block7a__0se_reduce_iga'\")\n",
      "prev_layer_channel_count  48\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 1152), dtype=tf.float32, name=None), name='k_block7a__0se_excite/mul:0', description=\"created by layer 'k_block7a__0se_excite'\")\n",
      "prev_layer_channel_count  1152\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 320), dtype=tf.float32, name=None), name='k_block7a__0project_conv_iga/add:0', description=\"created by layer 'k_block7a__0project_conv_iga'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 320), dtype=tf.float32, name=None), name='k_block7a__0project_conv_iga/add:0', description=\"created by layer 'k_block7a__0project_conv_iga'\")\n",
      "prev_layer_channel_count  320\n",
      "x = cai.layers.kPointwiseConv2D   KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 1280), dtype=tf.float32, name=None), name='k_top_conv_c1_m10_bn/FusedBatchNormV3:0', description=\"created by layer 'k_top_conv_c1_m10_bn'\")\n",
      "Model: \"kEffNet-b0\"\n",
      "____________________________________________________________________________________________________________________________________________________________________________________\n",
      " Layer (type)                                              Output Shape                            Param #              Connected to                                                \n",
      "====================================================================================================================================================================================\n",
      " input_11 (InputLayer)                                     [(None, 32, 32, 3)]                     0                    []                                                          \n",
      "                                                                                                                                                                                    \n",
      " k_stem_conv_pad (ZeroPadding2D)                           (None, 33, 33, 3)                       0                    ['input_11[0][0]']                                          \n",
      "                                                                                                                                                                                    \n",
      " k_stem_conv (Conv2D)                                      (None, 31, 31, 32)                      864                  ['k_stem_conv_pad[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_stem_bn (BatchNormalization)                            (None, 31, 31, 32)                      128                  ['k_stem_conv[0][0]']                                       \n",
      "                                                                                                                                                                                    \n",
      " k_stem_activation (Activation)                            (None, 31, 31, 32)                      0                    ['k_stem_bn[0][0]']                                         \n",
      "                                                                                                                                                                                    \n",
      " k_block1a__0dwconv (DepthwiseConv2D)                      (None, 31, 31, 32)                      288                  ['k_stem_activation[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block1a__0bn (BatchNormalization)                       (None, 31, 31, 32)                      128                  ['k_block1a__0dwconv[0][0]']                                \n",
      "                                                                                                                                                                                    \n",
      " k_block1a__0activation (Activation)                       (None, 31, 31, 32)                      0                    ['k_block1a__0bn[0][0]']                                    \n",
      "                                                                                                                                                                                    \n",
      " k_block1a__0se_squeeze (GlobalAveragePooling2D)           (None, 32)                              0                    ['k_block1a__0activation[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_block1a__0se_reshape (Reshape)                          (None, 1, 1, 32)                        0                    ['k_block1a__0se_squeeze[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_block1a__0se_reduce_um_conv (Conv2D)                    (None, 1, 1, 8)                         264                  ['k_block1a__0se_reshape[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_block1a__0se_reduce_um (Activation)                     (None, 1, 1, 8)                         0                    ['k_block1a__0se_reduce_um_conv[0][0]']                     \n",
      "                                                                                                                                                                                    \n",
      " k_block1a__0se_expand_um_conv (Conv2D)                    (None, 1, 1, 32)                        288                  ['k_block1a__0se_reduce_um[0][0]']                          \n",
      "                                                                                                                                                                                    \n",
      " k_block1a__0se_expand_um (Activation)                     (None, 1, 1, 32)                        0                    ['k_block1a__0se_expand_um_conv[0][0]']                     \n",
      "                                                                                                                                                                                    \n",
      " k_block1a__0se_excite (Multiply)                          (None, 31, 31, 32)                      0                    ['k_block1a__0activation[0][0]',                            \n",
      "                                                                                                                         'k_block1a__0se_expand_um[0][0]']                          \n",
      "                                                                                                                                                                                    \n",
      " k_block1a__0project_conv_um_conv (Conv2D)                 (None, 31, 31, 16)                      512                  ['k_block1a__0se_excite[0][0]']                             \n",
      "                                                                                                                                                                                    \n",
      " k_block1a__0project_conv_um_bn (BatchNormalization)       (None, 31, 31, 16)                      64                   ['k_block1a__0project_conv_um_conv[0][0]']                  \n",
      "                                                                                                                                                                                    \n",
      " k_block2a__0expand_um_conv (Conv2D)                       (None, 31, 31, 96)                      1536                 ['k_block1a__0project_conv_um_bn[0][0]']                    \n",
      "                                                                                                                                                                                    \n",
      " k_block2a__0expand_um_bn (BatchNormalization)             (None, 31, 31, 96)                      384                  ['k_block2a__0expand_um_conv[0][0]']                        \n",
      "                                                                                                                                                                                    \n",
      " k_block2a__0expand_um (Activation)                        (None, 31, 31, 96)                      0                    ['k_block2a__0expand_um_bn[0][0]']                          \n",
      "                                                                                                                                                                                    \n",
      " k_block2a__0dwconv (DepthwiseConv2D)                      (None, 31, 31, 96)                      864                  ['k_block2a__0expand_um[0][0]']                             \n",
      "                                                                                                                                                                                    \n",
      " k_block2a__0bn (BatchNormalization)                       (None, 31, 31, 96)                      384                  ['k_block2a__0dwconv[0][0]']                                \n",
      "                                                                                                                                                                                    \n",
      " k_block2a__0activation (Activation)                       (None, 31, 31, 96)                      0                    ['k_block2a__0bn[0][0]']                                    \n",
      "                                                                                                                                                                                    \n",
      " k_block2a__0se_squeeze (GlobalAveragePooling2D)           (None, 96)                              0                    ['k_block2a__0activation[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_block2a__0se_reshape (Reshape)                          (None, 1, 1, 96)                        0                    ['k_block2a__0se_squeeze[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_386 (CopyChannels)                          (None, 1, 1, 32)                        0                    ['k_block2a__0se_reshape[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_block2a__0se_reduce_c1_p1_3_conv (Conv2D)               (None, 1, 1, 3)                         99                   ['k_block2a__0se_reshape[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_block2a__0se_reduce_c1_p2_conv (Conv2D)                 (None, 1, 1, 1)                         33                   ['copy_channels_386[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block2a__0se_reduce_c1_p1_3 (Activation)                (None, 1, 1, 3)                         0                    ['k_block2a__0se_reduce_c1_p1_3_conv[0][0]']                \n",
      "                                                                                                                                                                                    \n",
      " k_block2a__0se_reduce_c1_p2 (Activation)                  (None, 1, 1, 1)                         0                    ['k_block2a__0se_reduce_c1_p2_conv[0][0]']                  \n",
      "                                                                                                                                                                                    \n",
      " k_block2a__0se_reduce_c1_dc (Concatenate)                 (None, 1, 1, 4)                         0                    ['k_block2a__0se_reduce_c1_p1_3[0][0]',                     \n",
      "                                                                                                                         'k_block2a__0se_reduce_c1_p2[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block2a__0se_reduce_c2_dum_conv (Conv2D)                (None, 1, 1, 4)                         20                   ['k_block2a__0se_reduce_c1_dc[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block2a__0se_reduce_c2_dum (Activation)                 (None, 1, 1, 4)                         0                    ['k_block2a__0se_reduce_c2_dum_conv[0][0]']                 \n",
      "                                                                                                                                                                                    \n",
      " k_block2a__0se_reduce_iga (Add)                           (None, 1, 1, 4)                         0                    ['k_block2a__0se_reduce_c2_dum[0][0]',                      \n",
      "                                                                                                                         'k_block2a__0se_reduce_c1_dc[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block2a__0se_expand_um_conv (Conv2D)                    (None, 1, 1, 96)                        480                  ['k_block2a__0se_reduce_iga[0][0]']                         \n",
      "                                                                                                                                                                                    \n",
      " k_block2a__0se_expand_um (Activation)                     (None, 1, 1, 96)                        0                    ['k_block2a__0se_expand_um_conv[0][0]']                     \n",
      "                                                                                                                                                                                    \n",
      " k_block2a__0se_excite (Multiply)                          (None, 31, 31, 96)                      0                    ['k_block2a__0activation[0][0]',                            \n",
      "                                                                                                                         'k_block2a__0se_expand_um[0][0]']                          \n",
      "                                                                                                                                                                                    \n",
      " k_block2a__0project_conv_c1_m3_conv (Conv2D)              (None, 31, 31, 24)                      768                  ['k_block2a__0se_excite[0][0]']                             \n",
      "                                                                                                                                                                                    \n",
      " k_block2a__0project_conv_c1_m3_bn (BatchNormalization)    (None, 31, 31, 24)                      96                   ['k_block2a__0project_conv_c1_m3_conv[0][0]']               \n",
      "                                                                                                                                                                                    \n",
      " k_block2a__0project_conv_c2_dum_conv (Conv2D)             (None, 31, 31, 24)                      576                  ['k_block2a__0project_conv_c1_m3_bn[0][0]']                 \n",
      "                                                                                                                                                                                    \n",
      " k_block2a__0project_conv_c2_dum_bn (BatchNormalization)   (None, 31, 31, 24)                      96                   ['k_block2a__0project_conv_c2_dum_conv[0][0]']              \n",
      "                                                                                                                                                                                    \n",
      " k_block2a__0project_conv_iga (Add)                        (None, 31, 31, 24)                      0                    ['k_block2a__0project_conv_c2_dum_bn[0][0]',                \n",
      "                                                                                                                         'k_block2a__0project_conv_c1_m3_bn[0][0]']                 \n",
      "                                                                                                                                                                                    \n",
      " k_block2b__0expand_um_conv (Conv2D)                       (None, 31, 31, 144)                     3456                 ['k_block2a__0project_conv_iga[0][0]']                      \n",
      "                                                                                                                                                                                    \n",
      " k_block2b__0expand_um_bn (BatchNormalization)             (None, 31, 31, 144)                     576                  ['k_block2b__0expand_um_conv[0][0]']                        \n",
      "                                                                                                                                                                                    \n",
      " k_block2b__0expand_um (Activation)                        (None, 31, 31, 144)                     0                    ['k_block2b__0expand_um_bn[0][0]']                          \n",
      "                                                                                                                                                                                    \n",
      " k_block2b__0dwconv (DepthwiseConv2D)                      (None, 31, 31, 144)                     1296                 ['k_block2b__0expand_um[0][0]']                             \n",
      "                                                                                                                                                                                    \n",
      " k_block2b__0bn (BatchNormalization)                       (None, 31, 31, 144)                     576                  ['k_block2b__0dwconv[0][0]']                                \n",
      "                                                                                                                                                                                    \n",
      " k_block2b__0activation (Activation)                       (None, 31, 31, 144)                     0                    ['k_block2b__0bn[0][0]']                                    \n",
      "                                                                                                                                                                                    \n",
      " k_block2b__0se_squeeze (GlobalAveragePooling2D)           (None, 144)                             0                    ['k_block2b__0activation[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_block2b__0se_reshape (Reshape)                          (None, 1, 1, 144)                       0                    ['k_block2b__0se_squeeze[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_387 (CopyChannels)                          (None, 1, 1, 16)                        0                    ['k_block2b__0se_reshape[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " concatenate_204 (Concatenate)                             (None, 1, 1, 160)                       0                    ['k_block2b__0se_reshape[0][0]',                            \n",
      "                                                                                                                         'copy_channels_387[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_388 (CopyChannels)                          (None, 1, 1, 32)                        0                    ['concatenate_204[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block2b__0se_reduce_c1_p1_5_conv (Conv2D)               (None, 1, 1, 5)                         165                  ['concatenate_204[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block2b__0se_reduce_c1_p2_conv (Conv2D)                 (None, 1, 1, 1)                         33                   ['copy_channels_388[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block2b__0se_reduce_c1_p1_5 (Activation)                (None, 1, 1, 5)                         0                    ['k_block2b__0se_reduce_c1_p1_5_conv[0][0]']                \n",
      "                                                                                                                                                                                    \n",
      " k_block2b__0se_reduce_c1_p2 (Activation)                  (None, 1, 1, 1)                         0                    ['k_block2b__0se_reduce_c1_p2_conv[0][0]']                  \n",
      "                                                                                                                                                                                    \n",
      " k_block2b__0se_reduce_c1_dc (Concatenate)                 (None, 1, 1, 6)                         0                    ['k_block2b__0se_reduce_c1_p1_5[0][0]',                     \n",
      "                                                                                                                         'k_block2b__0se_reduce_c1_p2[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block2b__0se_reduce_c2_dum_conv (Conv2D)                (None, 1, 1, 6)                         42                   ['k_block2b__0se_reduce_c1_dc[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block2b__0se_reduce_c2_dum (Activation)                 (None, 1, 1, 6)                         0                    ['k_block2b__0se_reduce_c2_dum_conv[0][0]']                 \n",
      "                                                                                                                                                                                    \n",
      " k_block2b__0se_reduce_iga (Add)                           (None, 1, 1, 6)                         0                    ['k_block2b__0se_reduce_c2_dum[0][0]',                      \n",
      "                                                                                                                         'k_block2b__0se_reduce_c1_dc[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block2b__0se_expand_um_conv (Conv2D)                    (None, 1, 1, 144)                       1008                 ['k_block2b__0se_reduce_iga[0][0]']                         \n",
      "                                                                                                                                                                                    \n",
      " k_block2b__0se_expand_um (Activation)                     (None, 1, 1, 144)                       0                    ['k_block2b__0se_expand_um_conv[0][0]']                     \n",
      "                                                                                                                                                                                    \n",
      " k_block2b__0se_excite (Multiply)                          (None, 31, 31, 144)                     0                    ['k_block2b__0activation[0][0]',                            \n",
      "                                                                                                                         'k_block2b__0se_expand_um[0][0]']                          \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_389 (CopyChannels)                          (None, 31, 31, 16)                      0                    ['k_block2b__0se_excite[0][0]']                             \n",
      "                                                                                                                                                                                    \n",
      " concatenate_205 (Concatenate)                             (None, 31, 31, 160)                     0                    ['k_block2b__0se_excite[0][0]',                             \n",
      "                                                                                                                         'copy_channels_389[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_390 (CopyChannels)                          (None, 31, 31, 128)                     0                    ['concatenate_205[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block2b__0project_conv_c1_p1_5_conv (Conv2D)            (None, 31, 31, 20)                      640                  ['concatenate_205[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block2b__0project_conv_c1_p2_conv (Conv2D)              (None, 31, 31, 4)                       128                  ['copy_channels_390[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block2b__0project_conv_c1_p1_5_bn (BatchNormalization)  (None, 31, 31, 20)                      80                   ['k_block2b__0project_conv_c1_p1_5_conv[0][0]']             \n",
      "                                                                                                                                                                                    \n",
      " k_block2b__0project_conv_c1_p2_bn (BatchNormalization)    (None, 31, 31, 4)                       16                   ['k_block2b__0project_conv_c1_p2_conv[0][0]']               \n",
      "                                                                                                                                                                                    \n",
      " k_block2b__0project_conv_c1_dc (Concatenate)              (None, 31, 31, 24)                      0                    ['k_block2b__0project_conv_c1_p1_5_bn[0][0]',               \n",
      "                                                                                                                         'k_block2b__0project_conv_c1_p2_bn[0][0]']                 \n",
      "                                                                                                                                                                                    \n",
      " k_block2b__0project_conv_c2_dum_conv (Conv2D)             (None, 31, 31, 24)                      576                  ['k_block2b__0project_conv_c1_dc[0][0]']                    \n",
      "                                                                                                                                                                                    \n",
      " k_block2b__0project_conv_c2_dum_bn (BatchNormalization)   (None, 31, 31, 24)                      96                   ['k_block2b__0project_conv_c2_dum_conv[0][0]']              \n",
      "                                                                                                                                                                                    \n",
      " k_block2b__0project_conv_iga (Add)                        (None, 31, 31, 24)                      0                    ['k_block2b__0project_conv_c2_dum_bn[0][0]',                \n",
      "                                                                                                                         'k_block2b__0project_conv_c1_dc[0][0]']                    \n",
      "                                                                                                                                                                                    \n",
      " k_block2b__0drop (Dropout)                                (None, 31, 31, 24)                      0                    ['k_block2b__0project_conv_iga[0][0]']                      \n",
      "                                                                                                                                                                                    \n",
      " k_block2b__0add (Add)                                     (None, 31, 31, 24)                      0                    ['k_block2b__0drop[0][0]',                                  \n",
      "                                                                                                                         'k_block2a__0project_conv_iga[0][0]']                      \n",
      "                                                                                                                                                                                    \n",
      " k_block3a__0expand_um_conv (Conv2D)                       (None, 31, 31, 144)                     3456                 ['k_block2b__0add[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block3a__0expand_um_bn (BatchNormalization)             (None, 31, 31, 144)                     576                  ['k_block3a__0expand_um_conv[0][0]']                        \n",
      "                                                                                                                                                                                    \n",
      " k_block3a__0expand_um (Activation)                        (None, 31, 31, 144)                     0                    ['k_block3a__0expand_um_bn[0][0]']                          \n",
      "                                                                                                                                                                                    \n",
      " k_block3a__0dwconv (DepthwiseConv2D)                      (None, 31, 31, 144)                     3600                 ['k_block3a__0expand_um[0][0]']                             \n",
      "                                                                                                                                                                                    \n",
      " k_block3a__0bn (BatchNormalization)                       (None, 31, 31, 144)                     576                  ['k_block3a__0dwconv[0][0]']                                \n",
      "                                                                                                                                                                                    \n",
      " k_block3a__0activation (Activation)                       (None, 31, 31, 144)                     0                    ['k_block3a__0bn[0][0]']                                    \n",
      "                                                                                                                                                                                    \n",
      " k_block3a__0se_squeeze (GlobalAveragePooling2D)           (None, 144)                             0                    ['k_block3a__0activation[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_block3a__0se_reshape (Reshape)                          (None, 1, 1, 144)                       0                    ['k_block3a__0se_squeeze[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_391 (CopyChannels)                          (None, 1, 1, 16)                        0                    ['k_block3a__0se_reshape[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " concatenate_206 (Concatenate)                             (None, 1, 1, 160)                       0                    ['k_block3a__0se_reshape[0][0]',                            \n",
      "                                                                                                                         'copy_channels_391[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_392 (CopyChannels)                          (None, 1, 1, 32)                        0                    ['concatenate_206[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block3a__0se_reduce_c1_p1_5_conv (Conv2D)               (None, 1, 1, 5)                         165                  ['concatenate_206[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block3a__0se_reduce_c1_p2_conv (Conv2D)                 (None, 1, 1, 1)                         33                   ['copy_channels_392[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block3a__0se_reduce_c1_p1_5 (Activation)                (None, 1, 1, 5)                         0                    ['k_block3a__0se_reduce_c1_p1_5_conv[0][0]']                \n",
      "                                                                                                                                                                                    \n",
      " k_block3a__0se_reduce_c1_p2 (Activation)                  (None, 1, 1, 1)                         0                    ['k_block3a__0se_reduce_c1_p2_conv[0][0]']                  \n",
      "                                                                                                                                                                                    \n",
      " k_block3a__0se_reduce_c1_dc (Concatenate)                 (None, 1, 1, 6)                         0                    ['k_block3a__0se_reduce_c1_p1_5[0][0]',                     \n",
      "                                                                                                                         'k_block3a__0se_reduce_c1_p2[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block3a__0se_reduce_c2_dum_conv (Conv2D)                (None, 1, 1, 6)                         42                   ['k_block3a__0se_reduce_c1_dc[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block3a__0se_reduce_c2_dum (Activation)                 (None, 1, 1, 6)                         0                    ['k_block3a__0se_reduce_c2_dum_conv[0][0]']                 \n",
      "                                                                                                                                                                                    \n",
      " k_block3a__0se_reduce_iga (Add)                           (None, 1, 1, 6)                         0                    ['k_block3a__0se_reduce_c2_dum[0][0]',                      \n",
      "                                                                                                                         'k_block3a__0se_reduce_c1_dc[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block3a__0se_expand_um_conv (Conv2D)                    (None, 1, 1, 144)                       1008                 ['k_block3a__0se_reduce_iga[0][0]']                         \n",
      "                                                                                                                                                                                    \n",
      " k_block3a__0se_expand_um (Activation)                     (None, 1, 1, 144)                       0                    ['k_block3a__0se_expand_um_conv[0][0]']                     \n",
      "                                                                                                                                                                                    \n",
      " k_block3a__0se_excite (Multiply)                          (None, 31, 31, 144)                     0                    ['k_block3a__0activation[0][0]',                            \n",
      "                                                                                                                         'k_block3a__0se_expand_um[0][0]']                          \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_393 (CopyChannels)                          (None, 31, 31, 16)                      0                    ['k_block3a__0se_excite[0][0]']                             \n",
      "                                                                                                                                                                                    \n",
      " concatenate_207 (Concatenate)                             (None, 31, 31, 160)                     0                    ['k_block3a__0se_excite[0][0]',                             \n",
      "                                                                                                                         'copy_channels_393[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block3a__0project_conv_c1_m5_conv (Conv2D)              (None, 31, 31, 40)                      1280                 ['concatenate_207[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block3a__0project_conv_c1_m5_bn (BatchNormalization)    (None, 31, 31, 40)                      160                  ['k_block3a__0project_conv_c1_m5_conv[0][0]']               \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_394 (CopyChannels)                          (None, 31, 31, 24)                      0                    ['k_block3a__0project_conv_c1_m5_bn[0][0]']                 \n",
      "                                                                                                                                                                                    \n",
      " concatenate_208 (Concatenate)                             (None, 31, 31, 64)                      0                    ['k_block3a__0project_conv_c1_m5_bn[0][0]',                 \n",
      "                                                                                                                         'copy_channels_394[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block3a__0project_conv_c2_m2_conv (Conv2D)              (None, 31, 31, 40)                      1280                 ['concatenate_208[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block3a__0project_conv_c2_m2_bn (BatchNormalization)    (None, 31, 31, 40)                      160                  ['k_block3a__0project_conv_c2_m2_conv[0][0]']               \n",
      "                                                                                                                                                                                    \n",
      " k_block3a__0project_conv_iga (Add)                        (None, 31, 31, 40)                      0                    ['k_block3a__0project_conv_c2_m2_bn[0][0]',                 \n",
      "                                                                                                                         'k_block3a__0project_conv_c1_m5_bn[0][0]']                 \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_395 (CopyChannels)                          (None, 31, 31, 24)                      0                    ['k_block3a__0project_conv_iga[0][0]']                      \n",
      "                                                                                                                                                                                    \n",
      " concatenate_209 (Concatenate)                             (None, 31, 31, 64)                      0                    ['k_block3a__0project_conv_iga[0][0]',                      \n",
      "                                                                                                                         'copy_channels_395[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block3b__0expand_c1_m2_conv (Conv2D)                    (None, 31, 31, 240)                     7680                 ['concatenate_209[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block3b__0expand_c1_m2_bn (BatchNormalization)          (None, 31, 31, 240)                     960                  ['k_block3b__0expand_c1_m2_conv[0][0]']                     \n",
      "                                                                                                                                                                                    \n",
      " k_block3b__0expand_c1_m2 (Activation)                     (None, 31, 31, 240)                     0                    ['k_block3b__0expand_c1_m2_bn[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block3b__0dwconv (DepthwiseConv2D)                      (None, 31, 31, 240)                     6000                 ['k_block3b__0expand_c1_m2[0][0]']                          \n",
      "                                                                                                                                                                                    \n",
      " k_block3b__0bn (BatchNormalization)                       (None, 31, 31, 240)                     960                  ['k_block3b__0dwconv[0][0]']                                \n",
      "                                                                                                                                                                                    \n",
      " k_block3b__0activation (Activation)                       (None, 31, 31, 240)                     0                    ['k_block3b__0bn[0][0]']                                    \n",
      "                                                                                                                                                                                    \n",
      " k_block3b__0se_squeeze (GlobalAveragePooling2D)           (None, 240)                             0                    ['k_block3b__0activation[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_block3b__0se_reshape (Reshape)                          (None, 1, 1, 240)                       0                    ['k_block3b__0se_squeeze[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_396 (CopyChannels)                          (None, 1, 1, 16)                        0                    ['k_block3b__0se_reshape[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " concatenate_210 (Concatenate)                             (None, 1, 1, 256)                       0                    ['k_block3b__0se_reshape[0][0]',                            \n",
      "                                                                                                                         'copy_channels_396[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_397 (CopyChannels)                          (None, 1, 1, 64)                        0                    ['concatenate_210[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block3b__0se_reduce_c1_p1_8_conv (Conv2D)               (None, 1, 1, 8)                         264                  ['concatenate_210[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block3b__0se_reduce_c1_p2_conv (Conv2D)                 (None, 1, 1, 2)                         66                   ['copy_channels_397[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block3b__0se_reduce_c1_p1_8 (Activation)                (None, 1, 1, 8)                         0                    ['k_block3b__0se_reduce_c1_p1_8_conv[0][0]']                \n",
      "                                                                                                                                                                                    \n",
      " k_block3b__0se_reduce_c1_p2 (Activation)                  (None, 1, 1, 2)                         0                    ['k_block3b__0se_reduce_c1_p2_conv[0][0]']                  \n",
      "                                                                                                                                                                                    \n",
      " k_block3b__0se_reduce_c1_dc (Concatenate)                 (None, 1, 1, 10)                        0                    ['k_block3b__0se_reduce_c1_p1_8[0][0]',                     \n",
      "                                                                                                                         'k_block3b__0se_reduce_c1_p2[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block3b__0se_reduce_c2_dum_conv (Conv2D)                (None, 1, 1, 10)                        110                  ['k_block3b__0se_reduce_c1_dc[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block3b__0se_reduce_c2_dum (Activation)                 (None, 1, 1, 10)                        0                    ['k_block3b__0se_reduce_c2_dum_conv[0][0]']                 \n",
      "                                                                                                                                                                                    \n",
      " k_block3b__0se_reduce_iga (Add)                           (None, 1, 1, 10)                        0                    ['k_block3b__0se_reduce_c2_dum[0][0]',                      \n",
      "                                                                                                                         'k_block3b__0se_reduce_c1_dc[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block3b__0se_expand_um_conv (Conv2D)                    (None, 1, 1, 240)                       2640                 ['k_block3b__0se_reduce_iga[0][0]']                         \n",
      "                                                                                                                                                                                    \n",
      " k_block3b__0se_expand_um (Activation)                     (None, 1, 1, 240)                       0                    ['k_block3b__0se_expand_um_conv[0][0]']                     \n",
      "                                                                                                                                                                                    \n",
      " k_block3b__0se_excite (Multiply)                          (None, 31, 31, 240)                     0                    ['k_block3b__0activation[0][0]',                            \n",
      "                                                                                                                         'k_block3b__0se_expand_um[0][0]']                          \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_398 (CopyChannels)                          (None, 31, 31, 16)                      0                    ['k_block3b__0se_excite[0][0]']                             \n",
      "                                                                                                                                                                                    \n",
      " concatenate_211 (Concatenate)                             (None, 31, 31, 256)                     0                    ['k_block3b__0se_excite[0][0]',                             \n",
      "                                                                                                                         'copy_channels_398[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block3b__0project_conv_c1_m8_conv (Conv2D)              (None, 31, 31, 40)                      1280                 ['concatenate_211[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block3b__0project_conv_c1_m8_bn (BatchNormalization)    (None, 31, 31, 40)                      160                  ['k_block3b__0project_conv_c1_m8_conv[0][0]']               \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_399 (CopyChannels)                          (None, 31, 31, 24)                      0                    ['k_block3b__0project_conv_c1_m8_bn[0][0]']                 \n",
      "                                                                                                                                                                                    \n",
      " concatenate_212 (Concatenate)                             (None, 31, 31, 64)                      0                    ['k_block3b__0project_conv_c1_m8_bn[0][0]',                 \n",
      "                                                                                                                         'copy_channels_399[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block3b__0project_conv_c2_m2_conv (Conv2D)              (None, 31, 31, 40)                      1280                 ['concatenate_212[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block3b__0project_conv_c2_m2_bn (BatchNormalization)    (None, 31, 31, 40)                      160                  ['k_block3b__0project_conv_c2_m2_conv[0][0]']               \n",
      "                                                                                                                                                                                    \n",
      " k_block3b__0project_conv_iga (Add)                        (None, 31, 31, 40)                      0                    ['k_block3b__0project_conv_c2_m2_bn[0][0]',                 \n",
      "                                                                                                                         'k_block3b__0project_conv_c1_m8_bn[0][0]']                 \n",
      "                                                                                                                                                                                    \n",
      " k_block3b__0drop (Dropout)                                (None, 31, 31, 40)                      0                    ['k_block3b__0project_conv_iga[0][0]']                      \n",
      "                                                                                                                                                                                    \n",
      " k_block3b__0add (Add)                                     (None, 31, 31, 40)                      0                    ['k_block3b__0drop[0][0]',                                  \n",
      "                                                                                                                         'k_block3a__0project_conv_iga[0][0]']                      \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_400 (CopyChannels)                          (None, 31, 31, 24)                      0                    ['k_block3b__0add[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " concatenate_213 (Concatenate)                             (None, 31, 31, 64)                      0                    ['k_block3b__0add[0][0]',                                   \n",
      "                                                                                                                         'copy_channels_400[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block4a__0expand_c1_m2_conv (Conv2D)                    (None, 31, 31, 240)                     7680                 ['concatenate_213[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block4a__0expand_c1_m2_bn (BatchNormalization)          (None, 31, 31, 240)                     960                  ['k_block4a__0expand_c1_m2_conv[0][0]']                     \n",
      "                                                                                                                                                                                    \n",
      " k_block4a__0expand_c1_m2 (Activation)                     (None, 31, 31, 240)                     0                    ['k_block4a__0expand_c1_m2_bn[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block4a__0dwconv_pad (ZeroPadding2D)                    (None, 33, 33, 240)                     0                    ['k_block4a__0expand_c1_m2[0][0]']                          \n",
      "                                                                                                                                                                                    \n",
      " k_block4a__0dwconv (DepthwiseConv2D)                      (None, 16, 16, 240)                     2160                 ['k_block4a__0dwconv_pad[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_block4a__0bn (BatchNormalization)                       (None, 16, 16, 240)                     960                  ['k_block4a__0dwconv[0][0]']                                \n",
      "                                                                                                                                                                                    \n",
      " k_block4a__0activation (Activation)                       (None, 16, 16, 240)                     0                    ['k_block4a__0bn[0][0]']                                    \n",
      "                                                                                                                                                                                    \n",
      " k_block4a__0se_squeeze (GlobalAveragePooling2D)           (None, 240)                             0                    ['k_block4a__0activation[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_block4a__0se_reshape (Reshape)                          (None, 1, 1, 240)                       0                    ['k_block4a__0se_squeeze[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_401 (CopyChannels)                          (None, 1, 1, 16)                        0                    ['k_block4a__0se_reshape[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " concatenate_214 (Concatenate)                             (None, 1, 1, 256)                       0                    ['k_block4a__0se_reshape[0][0]',                            \n",
      "                                                                                                                         'copy_channels_401[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_402 (CopyChannels)                          (None, 1, 1, 64)                        0                    ['concatenate_214[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block4a__0se_reduce_c1_p1_8_conv (Conv2D)               (None, 1, 1, 8)                         264                  ['concatenate_214[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block4a__0se_reduce_c1_p2_conv (Conv2D)                 (None, 1, 1, 2)                         66                   ['copy_channels_402[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block4a__0se_reduce_c1_p1_8 (Activation)                (None, 1, 1, 8)                         0                    ['k_block4a__0se_reduce_c1_p1_8_conv[0][0]']                \n",
      "                                                                                                                                                                                    \n",
      " k_block4a__0se_reduce_c1_p2 (Activation)                  (None, 1, 1, 2)                         0                    ['k_block4a__0se_reduce_c1_p2_conv[0][0]']                  \n",
      "                                                                                                                                                                                    \n",
      " k_block4a__0se_reduce_c1_dc (Concatenate)                 (None, 1, 1, 10)                        0                    ['k_block4a__0se_reduce_c1_p1_8[0][0]',                     \n",
      "                                                                                                                         'k_block4a__0se_reduce_c1_p2[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block4a__0se_reduce_c2_dum_conv (Conv2D)                (None, 1, 1, 10)                        110                  ['k_block4a__0se_reduce_c1_dc[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block4a__0se_reduce_c2_dum (Activation)                 (None, 1, 1, 10)                        0                    ['k_block4a__0se_reduce_c2_dum_conv[0][0]']                 \n",
      "                                                                                                                                                                                    \n",
      " k_block4a__0se_reduce_iga (Add)                           (None, 1, 1, 10)                        0                    ['k_block4a__0se_reduce_c2_dum[0][0]',                      \n",
      "                                                                                                                         'k_block4a__0se_reduce_c1_dc[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block4a__0se_expand_um_conv (Conv2D)                    (None, 1, 1, 240)                       2640                 ['k_block4a__0se_reduce_iga[0][0]']                         \n",
      "                                                                                                                                                                                    \n",
      " k_block4a__0se_expand_um (Activation)                     (None, 1, 1, 240)                       0                    ['k_block4a__0se_expand_um_conv[0][0]']                     \n",
      "                                                                                                                                                                                    \n",
      " k_block4a__0se_excite (Multiply)                          (None, 16, 16, 240)                     0                    ['k_block4a__0activation[0][0]',                            \n",
      "                                                                                                                         'k_block4a__0se_expand_um[0][0]']                          \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_403 (CopyChannels)                          (None, 16, 16, 16)                      0                    ['k_block4a__0se_excite[0][0]']                             \n",
      "                                                                                                                                                                                    \n",
      " concatenate_215 (Concatenate)                             (None, 16, 16, 256)                     0                    ['k_block4a__0se_excite[0][0]',                             \n",
      "                                                                                                                         'copy_channels_403[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block4a__0project_conv_c1_m8_conv (Conv2D)              (None, 16, 16, 80)                      2560                 ['concatenate_215[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block4a__0project_conv_c1_m8_bn (BatchNormalization)    (None, 16, 16, 80)                      320                  ['k_block4a__0project_conv_c1_m8_conv[0][0]']               \n",
      "                                                                                                                                                                                    \n",
      " k_block4a__0project_conv_i2 (InterleaveChannels)          (None, 16, 16, 80)                      0                    ['k_block4a__0project_conv_c1_m8_bn[0][0]']                 \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_404 (CopyChannels)                          (None, 16, 16, 16)                      0                    ['k_block4a__0project_conv_i2[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " concatenate_216 (Concatenate)                             (None, 16, 16, 96)                      0                    ['k_block4a__0project_conv_i2[0][0]',                       \n",
      "                                                                                                                         'copy_channels_404[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_405 (CopyChannels)                          (None, 16, 16, 64)                      0                    ['concatenate_216[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block4a__0project_conv_c2_p1_3_conv (Conv2D)            (None, 16, 16, 78)                      2496                 ['concatenate_216[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block4a__0project_conv_c2_p2_conv (Conv2D)              (None, 16, 16, 2)                       64                   ['copy_channels_405[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block4a__0project_conv_c2_p1_3_bn (BatchNormalization)  (None, 16, 16, 78)                      312                  ['k_block4a__0project_conv_c2_p1_3_conv[0][0]']             \n",
      "                                                                                                                                                                                    \n",
      " k_block4a__0project_conv_c2_p2_bn (BatchNormalization)    (None, 16, 16, 2)                       8                    ['k_block4a__0project_conv_c2_p2_conv[0][0]']               \n",
      "                                                                                                                                                                                    \n",
      " k_block4a__0project_conv_c2_dc (Concatenate)              (None, 16, 16, 80)                      0                    ['k_block4a__0project_conv_c2_p1_3_bn[0][0]',               \n",
      "                                                                                                                         'k_block4a__0project_conv_c2_p2_bn[0][0]']                 \n",
      "                                                                                                                                                                                    \n",
      " k_block4a__0project_conv_iga (Add)                        (None, 16, 16, 80)                      0                    ['k_block4a__0project_conv_c2_dc[0][0]',                    \n",
      "                                                                                                                         'k_block4a__0project_conv_c1_m8_bn[0][0]']                 \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_406 (CopyChannels)                          (None, 16, 16, 16)                      0                    ['k_block4a__0project_conv_iga[0][0]']                      \n",
      "                                                                                                                                                                                    \n",
      " concatenate_217 (Concatenate)                             (None, 16, 16, 96)                      0                    ['k_block4a__0project_conv_iga[0][0]',                      \n",
      "                                                                                                                         'copy_channels_406[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block4b__0expand_c1_m3_conv (Conv2D)                    (None, 16, 16, 480)                     15360                ['concatenate_217[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block4b__0expand_c1_m3_bn (BatchNormalization)          (None, 16, 16, 480)                     1920                 ['k_block4b__0expand_c1_m3_conv[0][0]']                     \n",
      "                                                                                                                                                                                    \n",
      " k_block4b__0expand_c1_m3 (Activation)                     (None, 16, 16, 480)                     0                    ['k_block4b__0expand_c1_m3_bn[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block4b__0dwconv (DepthwiseConv2D)                      (None, 16, 16, 480)                     4320                 ['k_block4b__0expand_c1_m3[0][0]']                          \n",
      "                                                                                                                                                                                    \n",
      " k_block4b__0bn (BatchNormalization)                       (None, 16, 16, 480)                     1920                 ['k_block4b__0dwconv[0][0]']                                \n",
      "                                                                                                                                                                                    \n",
      " k_block4b__0activation (Activation)                       (None, 16, 16, 480)                     0                    ['k_block4b__0bn[0][0]']                                    \n",
      "                                                                                                                                                                                    \n",
      " k_block4b__0se_squeeze (GlobalAveragePooling2D)           (None, 480)                             0                    ['k_block4b__0activation[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_block4b__0se_reshape (Reshape)                          (None, 1, 1, 480)                       0                    ['k_block4b__0se_squeeze[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_407 (CopyChannels)                          (None, 1, 1, 160)                       0                    ['k_block4b__0se_reshape[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_block4b__0se_reduce_c1_p1_15_conv (Conv2D)              (None, 1, 1, 15)                        495                  ['k_block4b__0se_reshape[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_block4b__0se_reduce_c1_p2_conv (Conv2D)                 (None, 1, 1, 5)                         165                  ['copy_channels_407[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block4b__0se_reduce_c1_p1_15 (Activation)               (None, 1, 1, 15)                        0                    ['k_block4b__0se_reduce_c1_p1_15_conv[0][0]']               \n",
      "                                                                                                                                                                                    \n",
      " k_block4b__0se_reduce_c1_p2 (Activation)                  (None, 1, 1, 5)                         0                    ['k_block4b__0se_reduce_c1_p2_conv[0][0]']                  \n",
      "                                                                                                                                                                                    \n",
      " k_block4b__0se_reduce_c1_dc (Concatenate)                 (None, 1, 1, 20)                        0                    ['k_block4b__0se_reduce_c1_p1_15[0][0]',                    \n",
      "                                                                                                                         'k_block4b__0se_reduce_c1_p2[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block4b__0se_reduce_c2_dum_conv (Conv2D)                (None, 1, 1, 20)                        420                  ['k_block4b__0se_reduce_c1_dc[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block4b__0se_reduce_c2_dum (Activation)                 (None, 1, 1, 20)                        0                    ['k_block4b__0se_reduce_c2_dum_conv[0][0]']                 \n",
      "                                                                                                                                                                                    \n",
      " k_block4b__0se_reduce_iga (Add)                           (None, 1, 1, 20)                        0                    ['k_block4b__0se_reduce_c2_dum[0][0]',                      \n",
      "                                                                                                                         'k_block4b__0se_reduce_c1_dc[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block4b__0se_expand_um_conv (Conv2D)                    (None, 1, 1, 480)                       10080                ['k_block4b__0se_reduce_iga[0][0]']                         \n",
      "                                                                                                                                                                                    \n",
      " k_block4b__0se_expand_um (Activation)                     (None, 1, 1, 480)                       0                    ['k_block4b__0se_expand_um_conv[0][0]']                     \n",
      "                                                                                                                                                                                    \n",
      " k_block4b__0se_excite (Multiply)                          (None, 16, 16, 480)                     0                    ['k_block4b__0activation[0][0]',                            \n",
      "                                                                                                                         'k_block4b__0se_expand_um[0][0]']                          \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_408 (CopyChannels)                          (None, 16, 16, 160)                     0                    ['k_block4b__0se_excite[0][0]']                             \n",
      "                                                                                                                                                                                    \n",
      " k_block4b__0project_conv_c1_p1_15_conv (Conv2D)           (None, 16, 16, 75)                      2400                 ['k_block4b__0se_excite[0][0]']                             \n",
      "                                                                                                                                                                                    \n",
      " k_block4b__0project_conv_c1_p2_conv (Conv2D)              (None, 16, 16, 5)                       160                  ['copy_channels_408[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block4b__0project_conv_c1_p1_15_bn (BatchNormalization)  (None, 16, 16, 75)                     300                  ['k_block4b__0project_conv_c1_p1_15_conv[0][0]']            \n",
      "                                                                                                                                                                                    \n",
      " k_block4b__0project_conv_c1_p2_bn (BatchNormalization)    (None, 16, 16, 5)                       20                   ['k_block4b__0project_conv_c1_p2_conv[0][0]']               \n",
      "                                                                                                                                                                                    \n",
      " k_block4b__0project_conv_c1_dc (Concatenate)              (None, 16, 16, 80)                      0                    ['k_block4b__0project_conv_c1_p1_15_bn[0][0]',              \n",
      "                                                                                                                         'k_block4b__0project_conv_c1_p2_bn[0][0]']                 \n",
      "                                                                                                                                                                                    \n",
      " k_block4b__0project_conv_i2 (InterleaveChannels)          (None, 16, 16, 80)                      0                    ['k_block4b__0project_conv_c1_dc[0][0]']                    \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_409 (CopyChannels)                          (None, 16, 16, 16)                      0                    ['k_block4b__0project_conv_i2[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " concatenate_218 (Concatenate)                             (None, 16, 16, 96)                      0                    ['k_block4b__0project_conv_i2[0][0]',                       \n",
      "                                                                                                                         'copy_channels_409[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_410 (CopyChannels)                          (None, 16, 16, 64)                      0                    ['concatenate_218[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block4b__0project_conv_c2_p1_3_conv (Conv2D)            (None, 16, 16, 78)                      2496                 ['concatenate_218[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block4b__0project_conv_c2_p2_conv (Conv2D)              (None, 16, 16, 2)                       64                   ['copy_channels_410[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block4b__0project_conv_c2_p1_3_bn (BatchNormalization)  (None, 16, 16, 78)                      312                  ['k_block4b__0project_conv_c2_p1_3_conv[0][0]']             \n",
      "                                                                                                                                                                                    \n",
      " k_block4b__0project_conv_c2_p2_bn (BatchNormalization)    (None, 16, 16, 2)                       8                    ['k_block4b__0project_conv_c2_p2_conv[0][0]']               \n",
      "                                                                                                                                                                                    \n",
      " k_block4b__0project_conv_c2_dc (Concatenate)              (None, 16, 16, 80)                      0                    ['k_block4b__0project_conv_c2_p1_3_bn[0][0]',               \n",
      "                                                                                                                         'k_block4b__0project_conv_c2_p2_bn[0][0]']                 \n",
      "                                                                                                                                                                                    \n",
      " k_block4b__0project_conv_iga (Add)                        (None, 16, 16, 80)                      0                    ['k_block4b__0project_conv_c2_dc[0][0]',                    \n",
      "                                                                                                                         'k_block4b__0project_conv_c1_dc[0][0]']                    \n",
      "                                                                                                                                                                                    \n",
      " k_block4b__0drop (Dropout)                                (None, 16, 16, 80)                      0                    ['k_block4b__0project_conv_iga[0][0]']                      \n",
      "                                                                                                                                                                                    \n",
      " k_block4b__0add (Add)                                     (None, 16, 16, 80)                      0                    ['k_block4b__0drop[0][0]',                                  \n",
      "                                                                                                                         'k_block4a__0project_conv_iga[0][0]']                      \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_411 (CopyChannels)                          (None, 16, 16, 16)                      0                    ['k_block4b__0add[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " concatenate_219 (Concatenate)                             (None, 16, 16, 96)                      0                    ['k_block4b__0add[0][0]',                                   \n",
      "                                                                                                                         'copy_channels_411[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block4c__0expand_c1_m3_conv (Conv2D)                    (None, 16, 16, 480)                     15360                ['concatenate_219[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block4c__0expand_c1_m3_bn (BatchNormalization)          (None, 16, 16, 480)                     1920                 ['k_block4c__0expand_c1_m3_conv[0][0]']                     \n",
      "                                                                                                                                                                                    \n",
      " k_block4c__0expand_c1_m3 (Activation)                     (None, 16, 16, 480)                     0                    ['k_block4c__0expand_c1_m3_bn[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block4c__0dwconv (DepthwiseConv2D)                      (None, 16, 16, 480)                     4320                 ['k_block4c__0expand_c1_m3[0][0]']                          \n",
      "                                                                                                                                                                                    \n",
      " k_block4c__0bn (BatchNormalization)                       (None, 16, 16, 480)                     1920                 ['k_block4c__0dwconv[0][0]']                                \n",
      "                                                                                                                                                                                    \n",
      " k_block4c__0activation (Activation)                       (None, 16, 16, 480)                     0                    ['k_block4c__0bn[0][0]']                                    \n",
      "                                                                                                                                                                                    \n",
      " k_block4c__0se_squeeze (GlobalAveragePooling2D)           (None, 480)                             0                    ['k_block4c__0activation[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_block4c__0se_reshape (Reshape)                          (None, 1, 1, 480)                       0                    ['k_block4c__0se_squeeze[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_412 (CopyChannels)                          (None, 1, 1, 160)                       0                    ['k_block4c__0se_reshape[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_block4c__0se_reduce_c1_p1_15_conv (Conv2D)              (None, 1, 1, 15)                        495                  ['k_block4c__0se_reshape[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_block4c__0se_reduce_c1_p2_conv (Conv2D)                 (None, 1, 1, 5)                         165                  ['copy_channels_412[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block4c__0se_reduce_c1_p1_15 (Activation)               (None, 1, 1, 15)                        0                    ['k_block4c__0se_reduce_c1_p1_15_conv[0][0]']               \n",
      "                                                                                                                                                                                    \n",
      " k_block4c__0se_reduce_c1_p2 (Activation)                  (None, 1, 1, 5)                         0                    ['k_block4c__0se_reduce_c1_p2_conv[0][0]']                  \n",
      "                                                                                                                                                                                    \n",
      " k_block4c__0se_reduce_c1_dc (Concatenate)                 (None, 1, 1, 20)                        0                    ['k_block4c__0se_reduce_c1_p1_15[0][0]',                    \n",
      "                                                                                                                         'k_block4c__0se_reduce_c1_p2[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block4c__0se_reduce_c2_dum_conv (Conv2D)                (None, 1, 1, 20)                        420                  ['k_block4c__0se_reduce_c1_dc[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block4c__0se_reduce_c2_dum (Activation)                 (None, 1, 1, 20)                        0                    ['k_block4c__0se_reduce_c2_dum_conv[0][0]']                 \n",
      "                                                                                                                                                                                    \n",
      " k_block4c__0se_reduce_iga (Add)                           (None, 1, 1, 20)                        0                    ['k_block4c__0se_reduce_c2_dum[0][0]',                      \n",
      "                                                                                                                         'k_block4c__0se_reduce_c1_dc[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block4c__0se_expand_um_conv (Conv2D)                    (None, 1, 1, 480)                       10080                ['k_block4c__0se_reduce_iga[0][0]']                         \n",
      "                                                                                                                                                                                    \n",
      " k_block4c__0se_expand_um (Activation)                     (None, 1, 1, 480)                       0                    ['k_block4c__0se_expand_um_conv[0][0]']                     \n",
      "                                                                                                                                                                                    \n",
      " k_block4c__0se_excite (Multiply)                          (None, 16, 16, 480)                     0                    ['k_block4c__0activation[0][0]',                            \n",
      "                                                                                                                         'k_block4c__0se_expand_um[0][0]']                          \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_413 (CopyChannels)                          (None, 16, 16, 160)                     0                    ['k_block4c__0se_excite[0][0]']                             \n",
      "                                                                                                                                                                                    \n",
      " k_block4c__0project_conv_c1_p1_15_conv (Conv2D)           (None, 16, 16, 75)                      2400                 ['k_block4c__0se_excite[0][0]']                             \n",
      "                                                                                                                                                                                    \n",
      " k_block4c__0project_conv_c1_p2_conv (Conv2D)              (None, 16, 16, 5)                       160                  ['copy_channels_413[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block4c__0project_conv_c1_p1_15_bn (BatchNormalization)  (None, 16, 16, 75)                     300                  ['k_block4c__0project_conv_c1_p1_15_conv[0][0]']            \n",
      "                                                                                                                                                                                    \n",
      " k_block4c__0project_conv_c1_p2_bn (BatchNormalization)    (None, 16, 16, 5)                       20                   ['k_block4c__0project_conv_c1_p2_conv[0][0]']               \n",
      "                                                                                                                                                                                    \n",
      " k_block4c__0project_conv_c1_dc (Concatenate)              (None, 16, 16, 80)                      0                    ['k_block4c__0project_conv_c1_p1_15_bn[0][0]',              \n",
      "                                                                                                                         'k_block4c__0project_conv_c1_p2_bn[0][0]']                 \n",
      "                                                                                                                                                                                    \n",
      " k_block4c__0project_conv_i2 (InterleaveChannels)          (None, 16, 16, 80)                      0                    ['k_block4c__0project_conv_c1_dc[0][0]']                    \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_414 (CopyChannels)                          (None, 16, 16, 16)                      0                    ['k_block4c__0project_conv_i2[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " concatenate_220 (Concatenate)                             (None, 16, 16, 96)                      0                    ['k_block4c__0project_conv_i2[0][0]',                       \n",
      "                                                                                                                         'copy_channels_414[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_415 (CopyChannels)                          (None, 16, 16, 64)                      0                    ['concatenate_220[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block4c__0project_conv_c2_p1_3_conv (Conv2D)            (None, 16, 16, 78)                      2496                 ['concatenate_220[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block4c__0project_conv_c2_p2_conv (Conv2D)              (None, 16, 16, 2)                       64                   ['copy_channels_415[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block4c__0project_conv_c2_p1_3_bn (BatchNormalization)  (None, 16, 16, 78)                      312                  ['k_block4c__0project_conv_c2_p1_3_conv[0][0]']             \n",
      "                                                                                                                                                                                    \n",
      " k_block4c__0project_conv_c2_p2_bn (BatchNormalization)    (None, 16, 16, 2)                       8                    ['k_block4c__0project_conv_c2_p2_conv[0][0]']               \n",
      "                                                                                                                                                                                    \n",
      " k_block4c__0project_conv_c2_dc (Concatenate)              (None, 16, 16, 80)                      0                    ['k_block4c__0project_conv_c2_p1_3_bn[0][0]',               \n",
      "                                                                                                                         'k_block4c__0project_conv_c2_p2_bn[0][0]']                 \n",
      "                                                                                                                                                                                    \n",
      " k_block4c__0project_conv_iga (Add)                        (None, 16, 16, 80)                      0                    ['k_block4c__0project_conv_c2_dc[0][0]',                    \n",
      "                                                                                                                         'k_block4c__0project_conv_c1_dc[0][0]']                    \n",
      "                                                                                                                                                                                    \n",
      " k_block4c__0drop (Dropout)                                (None, 16, 16, 80)                      0                    ['k_block4c__0project_conv_iga[0][0]']                      \n",
      "                                                                                                                                                                                    \n",
      " k_block4c__0add (Add)                                     (None, 16, 16, 80)                      0                    ['k_block4c__0drop[0][0]',                                  \n",
      "                                                                                                                         'k_block4b__0add[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_416 (CopyChannels)                          (None, 16, 16, 16)                      0                    ['k_block4c__0add[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " concatenate_221 (Concatenate)                             (None, 16, 16, 96)                      0                    ['k_block4c__0add[0][0]',                                   \n",
      "                                                                                                                         'copy_channels_416[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block5a__0expand_c1_m3_conv (Conv2D)                    (None, 16, 16, 480)                     15360                ['concatenate_221[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block5a__0expand_c1_m3_bn (BatchNormalization)          (None, 16, 16, 480)                     1920                 ['k_block5a__0expand_c1_m3_conv[0][0]']                     \n",
      "                                                                                                                                                                                    \n",
      " k_block5a__0expand_c1_m3 (Activation)                     (None, 16, 16, 480)                     0                    ['k_block5a__0expand_c1_m3_bn[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block5a__0dwconv (DepthwiseConv2D)                      (None, 16, 16, 480)                     12000                ['k_block5a__0expand_c1_m3[0][0]']                          \n",
      "                                                                                                                                                                                    \n",
      " k_block5a__0bn (BatchNormalization)                       (None, 16, 16, 480)                     1920                 ['k_block5a__0dwconv[0][0]']                                \n",
      "                                                                                                                                                                                    \n",
      " k_block5a__0activation (Activation)                       (None, 16, 16, 480)                     0                    ['k_block5a__0bn[0][0]']                                    \n",
      "                                                                                                                                                                                    \n",
      " k_block5a__0se_squeeze (GlobalAveragePooling2D)           (None, 480)                             0                    ['k_block5a__0activation[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_block5a__0se_reshape (Reshape)                          (None, 1, 1, 480)                       0                    ['k_block5a__0se_squeeze[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_417 (CopyChannels)                          (None, 1, 1, 160)                       0                    ['k_block5a__0se_reshape[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_block5a__0se_reduce_c1_p1_15_conv (Conv2D)              (None, 1, 1, 15)                        495                  ['k_block5a__0se_reshape[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_block5a__0se_reduce_c1_p2_conv (Conv2D)                 (None, 1, 1, 5)                         165                  ['copy_channels_417[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block5a__0se_reduce_c1_p1_15 (Activation)               (None, 1, 1, 15)                        0                    ['k_block5a__0se_reduce_c1_p1_15_conv[0][0]']               \n",
      "                                                                                                                                                                                    \n",
      " k_block5a__0se_reduce_c1_p2 (Activation)                  (None, 1, 1, 5)                         0                    ['k_block5a__0se_reduce_c1_p2_conv[0][0]']                  \n",
      "                                                                                                                                                                                    \n",
      " k_block5a__0se_reduce_c1_dc (Concatenate)                 (None, 1, 1, 20)                        0                    ['k_block5a__0se_reduce_c1_p1_15[0][0]',                    \n",
      "                                                                                                                         'k_block5a__0se_reduce_c1_p2[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block5a__0se_reduce_c2_dum_conv (Conv2D)                (None, 1, 1, 20)                        420                  ['k_block5a__0se_reduce_c1_dc[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block5a__0se_reduce_c2_dum (Activation)                 (None, 1, 1, 20)                        0                    ['k_block5a__0se_reduce_c2_dum_conv[0][0]']                 \n",
      "                                                                                                                                                                                    \n",
      " k_block5a__0se_reduce_iga (Add)                           (None, 1, 1, 20)                        0                    ['k_block5a__0se_reduce_c2_dum[0][0]',                      \n",
      "                                                                                                                         'k_block5a__0se_reduce_c1_dc[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block5a__0se_expand_um_conv (Conv2D)                    (None, 1, 1, 480)                       10080                ['k_block5a__0se_reduce_iga[0][0]']                         \n",
      "                                                                                                                                                                                    \n",
      " k_block5a__0se_expand_um (Activation)                     (None, 1, 1, 480)                       0                    ['k_block5a__0se_expand_um_conv[0][0]']                     \n",
      "                                                                                                                                                                                    \n",
      " k_block5a__0se_excite (Multiply)                          (None, 16, 16, 480)                     0                    ['k_block5a__0activation[0][0]',                            \n",
      "                                                                                                                         'k_block5a__0se_expand_um[0][0]']                          \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_418 (CopyChannels)                          (None, 16, 16, 224)                     0                    ['k_block5a__0se_excite[0][0]']                             \n",
      "                                                                                                                                                                                    \n",
      " k_block5a__0project_conv_c1_p1_15_conv (Conv2D)           (None, 16, 16, 105)                     3360                 ['k_block5a__0se_excite[0][0]']                             \n",
      "                                                                                                                                                                                    \n",
      " k_block5a__0project_conv_c1_p2_conv (Conv2D)              (None, 16, 16, 7)                       224                  ['copy_channels_418[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block5a__0project_conv_c1_p1_15_bn (BatchNormalization)  (None, 16, 16, 105)                    420                  ['k_block5a__0project_conv_c1_p1_15_conv[0][0]']            \n",
      "                                                                                                                                                                                    \n",
      " k_block5a__0project_conv_c1_p2_bn (BatchNormalization)    (None, 16, 16, 7)                       28                   ['k_block5a__0project_conv_c1_p2_conv[0][0]']               \n",
      "                                                                                                                                                                                    \n",
      " k_block5a__0project_conv_c1_dc (Concatenate)              (None, 16, 16, 112)                     0                    ['k_block5a__0project_conv_c1_p1_15_bn[0][0]',              \n",
      "                                                                                                                         'k_block5a__0project_conv_c1_p2_bn[0][0]']                 \n",
      "                                                                                                                                                                                    \n",
      " k_block5a__0project_conv_i3 (InterleaveChannels)          (None, 16, 16, 112)                     0                    ['k_block5a__0project_conv_c1_dc[0][0]']                    \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_419 (CopyChannels)                          (None, 16, 16, 16)                      0                    ['k_block5a__0project_conv_i3[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " concatenate_222 (Concatenate)                             (None, 16, 16, 128)                     0                    ['k_block5a__0project_conv_i3[0][0]',                       \n",
      "                                                                                                                         'copy_channels_419[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block5a__0project_conv_c2_m4_conv (Conv2D)              (None, 16, 16, 112)                     3584                 ['concatenate_222[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block5a__0project_conv_c2_m4_bn (BatchNormalization)    (None, 16, 16, 112)                     448                  ['k_block5a__0project_conv_c2_m4_conv[0][0]']               \n",
      "                                                                                                                                                                                    \n",
      " k_block5a__0project_conv_iga (Add)                        (None, 16, 16, 112)                     0                    ['k_block5a__0project_conv_c2_m4_bn[0][0]',                 \n",
      "                                                                                                                         'k_block5a__0project_conv_c1_dc[0][0]']                    \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_420 (CopyChannels)                          (None, 16, 16, 16)                      0                    ['k_block5a__0project_conv_iga[0][0]']                      \n",
      "                                                                                                                                                                                    \n",
      " concatenate_223 (Concatenate)                             (None, 16, 16, 128)                     0                    ['k_block5a__0project_conv_iga[0][0]',                      \n",
      "                                                                                                                         'copy_channels_420[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block5b__0expand_c1_m4_conv (Conv2D)                    (None, 16, 16, 672)                     21504                ['concatenate_223[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block5b__0expand_c1_m4_bn (BatchNormalization)          (None, 16, 16, 672)                     2688                 ['k_block5b__0expand_c1_m4_conv[0][0]']                     \n",
      "                                                                                                                                                                                    \n",
      " k_block5b__0expand_c1_m4 (Activation)                     (None, 16, 16, 672)                     0                    ['k_block5b__0expand_c1_m4_bn[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block5b__0dwconv (DepthwiseConv2D)                      (None, 16, 16, 672)                     16800                ['k_block5b__0expand_c1_m4[0][0]']                          \n",
      "                                                                                                                                                                                    \n",
      " k_block5b__0bn (BatchNormalization)                       (None, 16, 16, 672)                     2688                 ['k_block5b__0dwconv[0][0]']                                \n",
      "                                                                                                                                                                                    \n",
      " k_block5b__0activation (Activation)                       (None, 16, 16, 672)                     0                    ['k_block5b__0bn[0][0]']                                    \n",
      "                                                                                                                                                                                    \n",
      " k_block5b__0se_squeeze (GlobalAveragePooling2D)           (None, 672)                             0                    ['k_block5b__0activation[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_block5b__0se_reshape (Reshape)                          (None, 1, 1, 672)                       0                    ['k_block5b__0se_squeeze[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_421 (CopyChannels)                          (None, 1, 1, 224)                       0                    ['k_block5b__0se_reshape[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_block5b__0se_reduce_c1_p1_21_conv (Conv2D)              (None, 1, 1, 21)                        693                  ['k_block5b__0se_reshape[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_block5b__0se_reduce_c1_p2_conv (Conv2D)                 (None, 1, 1, 7)                         231                  ['copy_channels_421[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block5b__0se_reduce_c1_p1_21 (Activation)               (None, 1, 1, 21)                        0                    ['k_block5b__0se_reduce_c1_p1_21_conv[0][0]']               \n",
      "                                                                                                                                                                                    \n",
      " k_block5b__0se_reduce_c1_p2 (Activation)                  (None, 1, 1, 7)                         0                    ['k_block5b__0se_reduce_c1_p2_conv[0][0]']                  \n",
      "                                                                                                                                                                                    \n",
      " k_block5b__0se_reduce_c1_dc (Concatenate)                 (None, 1, 1, 28)                        0                    ['k_block5b__0se_reduce_c1_p1_21[0][0]',                    \n",
      "                                                                                                                         'k_block5b__0se_reduce_c1_p2[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block5b__0se_reduce_c2_dum_conv (Conv2D)                (None, 1, 1, 28)                        812                  ['k_block5b__0se_reduce_c1_dc[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block5b__0se_reduce_c2_dum (Activation)                 (None, 1, 1, 28)                        0                    ['k_block5b__0se_reduce_c2_dum_conv[0][0]']                 \n",
      "                                                                                                                                                                                    \n",
      " k_block5b__0se_reduce_iga (Add)                           (None, 1, 1, 28)                        0                    ['k_block5b__0se_reduce_c2_dum[0][0]',                      \n",
      "                                                                                                                         'k_block5b__0se_reduce_c1_dc[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block5b__0se_expand_um_conv (Conv2D)                    (None, 1, 1, 672)                       19488                ['k_block5b__0se_reduce_iga[0][0]']                         \n",
      "                                                                                                                                                                                    \n",
      " k_block5b__0se_expand_um (Activation)                     (None, 1, 1, 672)                       0                    ['k_block5b__0se_expand_um_conv[0][0]']                     \n",
      "                                                                                                                                                                                    \n",
      " k_block5b__0se_excite (Multiply)                          (None, 16, 16, 672)                     0                    ['k_block5b__0activation[0][0]',                            \n",
      "                                                                                                                         'k_block5b__0se_expand_um[0][0]']                          \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_422 (CopyChannels)                          (None, 16, 16, 224)                     0                    ['k_block5b__0se_excite[0][0]']                             \n",
      "                                                                                                                                                                                    \n",
      " k_block5b__0project_conv_c1_p1_21_conv (Conv2D)           (None, 16, 16, 105)                     3360                 ['k_block5b__0se_excite[0][0]']                             \n",
      "                                                                                                                                                                                    \n",
      " k_block5b__0project_conv_c1_p2_conv (Conv2D)              (None, 16, 16, 7)                       224                  ['copy_channels_422[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block5b__0project_conv_c1_p1_21_bn (BatchNormalization)  (None, 16, 16, 105)                    420                  ['k_block5b__0project_conv_c1_p1_21_conv[0][0]']            \n",
      "                                                                                                                                                                                    \n",
      " k_block5b__0project_conv_c1_p2_bn (BatchNormalization)    (None, 16, 16, 7)                       28                   ['k_block5b__0project_conv_c1_p2_conv[0][0]']               \n",
      "                                                                                                                                                                                    \n",
      " k_block5b__0project_conv_c1_dc (Concatenate)              (None, 16, 16, 112)                     0                    ['k_block5b__0project_conv_c1_p1_21_bn[0][0]',              \n",
      "                                                                                                                         'k_block5b__0project_conv_c1_p2_bn[0][0]']                 \n",
      "                                                                                                                                                                                    \n",
      " k_block5b__0project_conv_i3 (InterleaveChannels)          (None, 16, 16, 112)                     0                    ['k_block5b__0project_conv_c1_dc[0][0]']                    \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_423 (CopyChannels)                          (None, 16, 16, 16)                      0                    ['k_block5b__0project_conv_i3[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " concatenate_224 (Concatenate)                             (None, 16, 16, 128)                     0                    ['k_block5b__0project_conv_i3[0][0]',                       \n",
      "                                                                                                                         'copy_channels_423[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block5b__0project_conv_c2_m4_conv (Conv2D)              (None, 16, 16, 112)                     3584                 ['concatenate_224[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block5b__0project_conv_c2_m4_bn (BatchNormalization)    (None, 16, 16, 112)                     448                  ['k_block5b__0project_conv_c2_m4_conv[0][0]']               \n",
      "                                                                                                                                                                                    \n",
      " k_block5b__0project_conv_iga (Add)                        (None, 16, 16, 112)                     0                    ['k_block5b__0project_conv_c2_m4_bn[0][0]',                 \n",
      "                                                                                                                         'k_block5b__0project_conv_c1_dc[0][0]']                    \n",
      "                                                                                                                                                                                    \n",
      " k_block5b__0drop (Dropout)                                (None, 16, 16, 112)                     0                    ['k_block5b__0project_conv_iga[0][0]']                      \n",
      "                                                                                                                                                                                    \n",
      " k_block5b__0add (Add)                                     (None, 16, 16, 112)                     0                    ['k_block5b__0drop[0][0]',                                  \n",
      "                                                                                                                         'k_block5a__0project_conv_iga[0][0]']                      \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_424 (CopyChannels)                          (None, 16, 16, 16)                      0                    ['k_block5b__0add[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " concatenate_225 (Concatenate)                             (None, 16, 16, 128)                     0                    ['k_block5b__0add[0][0]',                                   \n",
      "                                                                                                                         'copy_channels_424[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block5c__0expand_c1_m4_conv (Conv2D)                    (None, 16, 16, 672)                     21504                ['concatenate_225[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block5c__0expand_c1_m4_bn (BatchNormalization)          (None, 16, 16, 672)                     2688                 ['k_block5c__0expand_c1_m4_conv[0][0]']                     \n",
      "                                                                                                                                                                                    \n",
      " k_block5c__0expand_c1_m4 (Activation)                     (None, 16, 16, 672)                     0                    ['k_block5c__0expand_c1_m4_bn[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block5c__0dwconv (DepthwiseConv2D)                      (None, 16, 16, 672)                     16800                ['k_block5c__0expand_c1_m4[0][0]']                          \n",
      "                                                                                                                                                                                    \n",
      " k_block5c__0bn (BatchNormalization)                       (None, 16, 16, 672)                     2688                 ['k_block5c__0dwconv[0][0]']                                \n",
      "                                                                                                                                                                                    \n",
      " k_block5c__0activation (Activation)                       (None, 16, 16, 672)                     0                    ['k_block5c__0bn[0][0]']                                    \n",
      "                                                                                                                                                                                    \n",
      " k_block5c__0se_squeeze (GlobalAveragePooling2D)           (None, 672)                             0                    ['k_block5c__0activation[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_block5c__0se_reshape (Reshape)                          (None, 1, 1, 672)                       0                    ['k_block5c__0se_squeeze[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_425 (CopyChannels)                          (None, 1, 1, 224)                       0                    ['k_block5c__0se_reshape[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_block5c__0se_reduce_c1_p1_21_conv (Conv2D)              (None, 1, 1, 21)                        693                  ['k_block5c__0se_reshape[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_block5c__0se_reduce_c1_p2_conv (Conv2D)                 (None, 1, 1, 7)                         231                  ['copy_channels_425[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block5c__0se_reduce_c1_p1_21 (Activation)               (None, 1, 1, 21)                        0                    ['k_block5c__0se_reduce_c1_p1_21_conv[0][0]']               \n",
      "                                                                                                                                                                                    \n",
      " k_block5c__0se_reduce_c1_p2 (Activation)                  (None, 1, 1, 7)                         0                    ['k_block5c__0se_reduce_c1_p2_conv[0][0]']                  \n",
      "                                                                                                                                                                                    \n",
      " k_block5c__0se_reduce_c1_dc (Concatenate)                 (None, 1, 1, 28)                        0                    ['k_block5c__0se_reduce_c1_p1_21[0][0]',                    \n",
      "                                                                                                                         'k_block5c__0se_reduce_c1_p2[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block5c__0se_reduce_c2_dum_conv (Conv2D)                (None, 1, 1, 28)                        812                  ['k_block5c__0se_reduce_c1_dc[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block5c__0se_reduce_c2_dum (Activation)                 (None, 1, 1, 28)                        0                    ['k_block5c__0se_reduce_c2_dum_conv[0][0]']                 \n",
      "                                                                                                                                                                                    \n",
      " k_block5c__0se_reduce_iga (Add)                           (None, 1, 1, 28)                        0                    ['k_block5c__0se_reduce_c2_dum[0][0]',                      \n",
      "                                                                                                                         'k_block5c__0se_reduce_c1_dc[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block5c__0se_expand_um_conv (Conv2D)                    (None, 1, 1, 672)                       19488                ['k_block5c__0se_reduce_iga[0][0]']                         \n",
      "                                                                                                                                                                                    \n",
      " k_block5c__0se_expand_um (Activation)                     (None, 1, 1, 672)                       0                    ['k_block5c__0se_expand_um_conv[0][0]']                     \n",
      "                                                                                                                                                                                    \n",
      " k_block5c__0se_excite (Multiply)                          (None, 16, 16, 672)                     0                    ['k_block5c__0activation[0][0]',                            \n",
      "                                                                                                                         'k_block5c__0se_expand_um[0][0]']                          \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_426 (CopyChannels)                          (None, 16, 16, 224)                     0                    ['k_block5c__0se_excite[0][0]']                             \n",
      "                                                                                                                                                                                    \n",
      " k_block5c__0project_conv_c1_p1_21_conv (Conv2D)           (None, 16, 16, 105)                     3360                 ['k_block5c__0se_excite[0][0]']                             \n",
      "                                                                                                                                                                                    \n",
      " k_block5c__0project_conv_c1_p2_conv (Conv2D)              (None, 16, 16, 7)                       224                  ['copy_channels_426[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block5c__0project_conv_c1_p1_21_bn (BatchNormalization)  (None, 16, 16, 105)                    420                  ['k_block5c__0project_conv_c1_p1_21_conv[0][0]']            \n",
      "                                                                                                                                                                                    \n",
      " k_block5c__0project_conv_c1_p2_bn (BatchNormalization)    (None, 16, 16, 7)                       28                   ['k_block5c__0project_conv_c1_p2_conv[0][0]']               \n",
      "                                                                                                                                                                                    \n",
      " k_block5c__0project_conv_c1_dc (Concatenate)              (None, 16, 16, 112)                     0                    ['k_block5c__0project_conv_c1_p1_21_bn[0][0]',              \n",
      "                                                                                                                         'k_block5c__0project_conv_c1_p2_bn[0][0]']                 \n",
      "                                                                                                                                                                                    \n",
      " k_block5c__0project_conv_i3 (InterleaveChannels)          (None, 16, 16, 112)                     0                    ['k_block5c__0project_conv_c1_dc[0][0]']                    \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_427 (CopyChannels)                          (None, 16, 16, 16)                      0                    ['k_block5c__0project_conv_i3[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " concatenate_226 (Concatenate)                             (None, 16, 16, 128)                     0                    ['k_block5c__0project_conv_i3[0][0]',                       \n",
      "                                                                                                                         'copy_channels_427[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block5c__0project_conv_c2_m4_conv (Conv2D)              (None, 16, 16, 112)                     3584                 ['concatenate_226[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block5c__0project_conv_c2_m4_bn (BatchNormalization)    (None, 16, 16, 112)                     448                  ['k_block5c__0project_conv_c2_m4_conv[0][0]']               \n",
      "                                                                                                                                                                                    \n",
      " k_block5c__0project_conv_iga (Add)                        (None, 16, 16, 112)                     0                    ['k_block5c__0project_conv_c2_m4_bn[0][0]',                 \n",
      "                                                                                                                         'k_block5c__0project_conv_c1_dc[0][0]']                    \n",
      "                                                                                                                                                                                    \n",
      " k_block5c__0drop (Dropout)                                (None, 16, 16, 112)                     0                    ['k_block5c__0project_conv_iga[0][0]']                      \n",
      "                                                                                                                                                                                    \n",
      " k_block5c__0add (Add)                                     (None, 16, 16, 112)                     0                    ['k_block5c__0drop[0][0]',                                  \n",
      "                                                                                                                         'k_block5b__0add[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_428 (CopyChannels)                          (None, 16, 16, 16)                      0                    ['k_block5c__0add[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " concatenate_227 (Concatenate)                             (None, 16, 16, 128)                     0                    ['k_block5c__0add[0][0]',                                   \n",
      "                                                                                                                         'copy_channels_428[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block6a__0expand_c1_m4_conv (Conv2D)                    (None, 16, 16, 672)                     21504                ['concatenate_227[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block6a__0expand_c1_m4_bn (BatchNormalization)          (None, 16, 16, 672)                     2688                 ['k_block6a__0expand_c1_m4_conv[0][0]']                     \n",
      "                                                                                                                                                                                    \n",
      " k_block6a__0expand_c1_m4 (Activation)                     (None, 16, 16, 672)                     0                    ['k_block6a__0expand_c1_m4_bn[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block6a__0dwconv_pad (ZeroPadding2D)                    (None, 19, 19, 672)                     0                    ['k_block6a__0expand_c1_m4[0][0]']                          \n",
      "                                                                                                                                                                                    \n",
      " k_block6a__0dwconv (DepthwiseConv2D)                      (None, 8, 8, 672)                       16800                ['k_block6a__0dwconv_pad[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_block6a__0bn (BatchNormalization)                       (None, 8, 8, 672)                       2688                 ['k_block6a__0dwconv[0][0]']                                \n",
      "                                                                                                                                                                                    \n",
      " k_block6a__0activation (Activation)                       (None, 8, 8, 672)                       0                    ['k_block6a__0bn[0][0]']                                    \n",
      "                                                                                                                                                                                    \n",
      " k_block6a__0se_squeeze (GlobalAveragePooling2D)           (None, 672)                             0                    ['k_block6a__0activation[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_block6a__0se_reshape (Reshape)                          (None, 1, 1, 672)                       0                    ['k_block6a__0se_squeeze[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_429 (CopyChannels)                          (None, 1, 1, 224)                       0                    ['k_block6a__0se_reshape[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_block6a__0se_reduce_c1_p1_21_conv (Conv2D)              (None, 1, 1, 21)                        693                  ['k_block6a__0se_reshape[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_block6a__0se_reduce_c1_p2_conv (Conv2D)                 (None, 1, 1, 7)                         231                  ['copy_channels_429[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block6a__0se_reduce_c1_p1_21 (Activation)               (None, 1, 1, 21)                        0                    ['k_block6a__0se_reduce_c1_p1_21_conv[0][0]']               \n",
      "                                                                                                                                                                                    \n",
      " k_block6a__0se_reduce_c1_p2 (Activation)                  (None, 1, 1, 7)                         0                    ['k_block6a__0se_reduce_c1_p2_conv[0][0]']                  \n",
      "                                                                                                                                                                                    \n",
      " k_block6a__0se_reduce_c1_dc (Concatenate)                 (None, 1, 1, 28)                        0                    ['k_block6a__0se_reduce_c1_p1_21[0][0]',                    \n",
      "                                                                                                                         'k_block6a__0se_reduce_c1_p2[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block6a__0se_reduce_c2_dum_conv (Conv2D)                (None, 1, 1, 28)                        812                  ['k_block6a__0se_reduce_c1_dc[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block6a__0se_reduce_c2_dum (Activation)                 (None, 1, 1, 28)                        0                    ['k_block6a__0se_reduce_c2_dum_conv[0][0]']                 \n",
      "                                                                                                                                                                                    \n",
      " k_block6a__0se_reduce_iga (Add)                           (None, 1, 1, 28)                        0                    ['k_block6a__0se_reduce_c2_dum[0][0]',                      \n",
      "                                                                                                                         'k_block6a__0se_reduce_c1_dc[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block6a__0se_expand_um_conv (Conv2D)                    (None, 1, 1, 672)                       19488                ['k_block6a__0se_reduce_iga[0][0]']                         \n",
      "                                                                                                                                                                                    \n",
      " k_block6a__0se_expand_um (Activation)                     (None, 1, 1, 672)                       0                    ['k_block6a__0se_expand_um_conv[0][0]']                     \n",
      "                                                                                                                                                                                    \n",
      " k_block6a__0se_excite (Multiply)                          (None, 8, 8, 672)                       0                    ['k_block6a__0activation[0][0]',                            \n",
      "                                                                                                                         'k_block6a__0se_expand_um[0][0]']                          \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_430 (CopyChannels)                          (None, 8, 8, 96)                        0                    ['k_block6a__0se_excite[0][0]']                             \n",
      "                                                                                                                                                                                    \n",
      " k_block6a__0project_conv_c1_p1_21_conv (Conv2D)           (None, 8, 8, 189)                       6048                 ['k_block6a__0se_excite[0][0]']                             \n",
      "                                                                                                                                                                                    \n",
      " k_block6a__0project_conv_c1_p2_conv (Conv2D)              (None, 8, 8, 3)                         96                   ['copy_channels_430[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block6a__0project_conv_c1_p1_21_bn (BatchNormalization)  (None, 8, 8, 189)                      756                  ['k_block6a__0project_conv_c1_p1_21_conv[0][0]']            \n",
      "                                                                                                                                                                                    \n",
      " k_block6a__0project_conv_c1_p2_bn (BatchNormalization)    (None, 8, 8, 3)                         12                   ['k_block6a__0project_conv_c1_p2_conv[0][0]']               \n",
      "                                                                                                                                                                                    \n",
      " k_block6a__0project_conv_c1_dc (Concatenate)              (None, 8, 8, 192)                       0                    ['k_block6a__0project_conv_c1_p1_21_bn[0][0]',              \n",
      "                                                                                                                         'k_block6a__0project_conv_c1_p2_bn[0][0]']                 \n",
      "                                                                                                                                                                                    \n",
      " k_block6a__0project_conv_i6 (InterleaveChannels)          (None, 8, 8, 192)                       0                    ['k_block6a__0project_conv_c1_dc[0][0]']                    \n",
      "                                                                                                                                                                                    \n",
      " k_block6a__0project_conv_c2_m6_conv (Conv2D)              (None, 8, 8, 192)                       6144                 ['k_block6a__0project_conv_i6[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block6a__0project_conv_c2_m6_bn (BatchNormalization)    (None, 8, 8, 192)                       768                  ['k_block6a__0project_conv_c2_m6_conv[0][0]']               \n",
      "                                                                                                                                                                                    \n",
      " k_block6a__0project_conv_iga (Add)                        (None, 8, 8, 192)                       0                    ['k_block6a__0project_conv_c2_m6_bn[0][0]',                 \n",
      "                                                                                                                         'k_block6a__0project_conv_c1_dc[0][0]']                    \n",
      "                                                                                                                                                                                    \n",
      " k_block6b__0expand_c1_m6_conv (Conv2D)                    (None, 8, 8, 1152)                      36864                ['k_block6a__0project_conv_iga[0][0]']                      \n",
      "                                                                                                                                                                                    \n",
      " k_block6b__0expand_c1_m6_bn (BatchNormalization)          (None, 8, 8, 1152)                      4608                 ['k_block6b__0expand_c1_m6_conv[0][0]']                     \n",
      "                                                                                                                                                                                    \n",
      " k_block6b__0expand_c1_m6 (Activation)                     (None, 8, 8, 1152)                      0                    ['k_block6b__0expand_c1_m6_bn[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block6b__0dwconv (DepthwiseConv2D)                      (None, 8, 8, 1152)                      28800                ['k_block6b__0expand_c1_m6[0][0]']                          \n",
      "                                                                                                                                                                                    \n",
      " k_block6b__0bn (BatchNormalization)                       (None, 8, 8, 1152)                      4608                 ['k_block6b__0dwconv[0][0]']                                \n",
      "                                                                                                                                                                                    \n",
      " k_block6b__0activation (Activation)                       (None, 8, 8, 1152)                      0                    ['k_block6b__0bn[0][0]']                                    \n",
      "                                                                                                                                                                                    \n",
      " k_block6b__0se_squeeze (GlobalAveragePooling2D)           (None, 1152)                            0                    ['k_block6b__0activation[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_block6b__0se_reshape (Reshape)                          (None, 1, 1, 1152)                      0                    ['k_block6b__0se_squeeze[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_431 (CopyChannels)                          (None, 1, 1, 384)                       0                    ['k_block6b__0se_reshape[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_block6b__0se_reduce_c1_p1_36_conv (Conv2D)              (None, 1, 1, 36)                        1188                 ['k_block6b__0se_reshape[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_block6b__0se_reduce_c1_p2_conv (Conv2D)                 (None, 1, 1, 12)                        396                  ['copy_channels_431[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block6b__0se_reduce_c1_p1_36 (Activation)               (None, 1, 1, 36)                        0                    ['k_block6b__0se_reduce_c1_p1_36_conv[0][0]']               \n",
      "                                                                                                                                                                                    \n",
      " k_block6b__0se_reduce_c1_p2 (Activation)                  (None, 1, 1, 12)                        0                    ['k_block6b__0se_reduce_c1_p2_conv[0][0]']                  \n",
      "                                                                                                                                                                                    \n",
      " k_block6b__0se_reduce_c1_dc (Concatenate)                 (None, 1, 1, 48)                        0                    ['k_block6b__0se_reduce_c1_p1_36[0][0]',                    \n",
      "                                                                                                                         'k_block6b__0se_reduce_c1_p2[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_432 (CopyChannels)                          (None, 1, 1, 16)                        0                    ['k_block6b__0se_reduce_c1_dc[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " concatenate_228 (Concatenate)                             (None, 1, 1, 64)                        0                    ['k_block6b__0se_reduce_c1_dc[0][0]',                       \n",
      "                                                                                                                         'copy_channels_432[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block6b__0se_reduce_c2_m2_conv (Conv2D)                 (None, 1, 1, 48)                        1584                 ['concatenate_228[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block6b__0se_reduce_c2_m2 (Activation)                  (None, 1, 1, 48)                        0                    ['k_block6b__0se_reduce_c2_m2_conv[0][0]']                  \n",
      "                                                                                                                                                                                    \n",
      " k_block6b__0se_reduce_iga (Add)                           (None, 1, 1, 48)                        0                    ['k_block6b__0se_reduce_c2_m2[0][0]',                       \n",
      "                                                                                                                         'k_block6b__0se_reduce_c1_dc[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_433 (CopyChannels)                          (None, 1, 1, 16)                        0                    ['k_block6b__0se_reduce_iga[0][0]']                         \n",
      "                                                                                                                                                                                    \n",
      " concatenate_229 (Concatenate)                             (None, 1, 1, 64)                        0                    ['k_block6b__0se_reduce_iga[0][0]',                         \n",
      "                                                                                                                         'copy_channels_433[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block6b__0se_expand_c1_m2_conv (Conv2D)                 (None, 1, 1, 1152)                      38016                ['concatenate_229[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block6b__0se_expand_c1_m2 (Activation)                  (None, 1, 1, 1152)                      0                    ['k_block6b__0se_expand_c1_m2_conv[0][0]']                  \n",
      "                                                                                                                                                                                    \n",
      " k_block6b__0se_excite (Multiply)                          (None, 8, 8, 1152)                      0                    ['k_block6b__0activation[0][0]',                            \n",
      "                                                                                                                         'k_block6b__0se_expand_c1_m2[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_434 (CopyChannels)                          (None, 8, 8, 384)                       0                    ['k_block6b__0se_excite[0][0]']                             \n",
      "                                                                                                                                                                                    \n",
      " k_block6b__0project_conv_c1_p1_36_conv (Conv2D)           (None, 8, 8, 180)                       5760                 ['k_block6b__0se_excite[0][0]']                             \n",
      "                                                                                                                                                                                    \n",
      " k_block6b__0project_conv_c1_p2_conv (Conv2D)              (None, 8, 8, 12)                        384                  ['copy_channels_434[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block6b__0project_conv_c1_p1_36_bn (BatchNormalization)  (None, 8, 8, 180)                      720                  ['k_block6b__0project_conv_c1_p1_36_conv[0][0]']            \n",
      "                                                                                                                                                                                    \n",
      " k_block6b__0project_conv_c1_p2_bn (BatchNormalization)    (None, 8, 8, 12)                        48                   ['k_block6b__0project_conv_c1_p2_conv[0][0]']               \n",
      "                                                                                                                                                                                    \n",
      " k_block6b__0project_conv_c1_dc (Concatenate)              (None, 8, 8, 192)                       0                    ['k_block6b__0project_conv_c1_p1_36_bn[0][0]',              \n",
      "                                                                                                                         'k_block6b__0project_conv_c1_p2_bn[0][0]']                 \n",
      "                                                                                                                                                                                    \n",
      " k_block6b__0project_conv_i6 (InterleaveChannels)          (None, 8, 8, 192)                       0                    ['k_block6b__0project_conv_c1_dc[0][0]']                    \n",
      "                                                                                                                                                                                    \n",
      " k_block6b__0project_conv_c2_m6_conv (Conv2D)              (None, 8, 8, 192)                       6144                 ['k_block6b__0project_conv_i6[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block6b__0project_conv_c2_m6_bn (BatchNormalization)    (None, 8, 8, 192)                       768                  ['k_block6b__0project_conv_c2_m6_conv[0][0]']               \n",
      "                                                                                                                                                                                    \n",
      " k_block6b__0project_conv_iga (Add)                        (None, 8, 8, 192)                       0                    ['k_block6b__0project_conv_c2_m6_bn[0][0]',                 \n",
      "                                                                                                                         'k_block6b__0project_conv_c1_dc[0][0]']                    \n",
      "                                                                                                                                                                                    \n",
      " k_block6b__0drop (Dropout)                                (None, 8, 8, 192)                       0                    ['k_block6b__0project_conv_iga[0][0]']                      \n",
      "                                                                                                                                                                                    \n",
      " k_block6b__0add (Add)                                     (None, 8, 8, 192)                       0                    ['k_block6b__0drop[0][0]',                                  \n",
      "                                                                                                                         'k_block6a__0project_conv_iga[0][0]']                      \n",
      "                                                                                                                                                                                    \n",
      " k_block6c__0expand_c1_m6_conv (Conv2D)                    (None, 8, 8, 1152)                      36864                ['k_block6b__0add[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block6c__0expand_c1_m6_bn (BatchNormalization)          (None, 8, 8, 1152)                      4608                 ['k_block6c__0expand_c1_m6_conv[0][0]']                     \n",
      "                                                                                                                                                                                    \n",
      " k_block6c__0expand_c1_m6 (Activation)                     (None, 8, 8, 1152)                      0                    ['k_block6c__0expand_c1_m6_bn[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block6c__0dwconv (DepthwiseConv2D)                      (None, 8, 8, 1152)                      28800                ['k_block6c__0expand_c1_m6[0][0]']                          \n",
      "                                                                                                                                                                                    \n",
      " k_block6c__0bn (BatchNormalization)                       (None, 8, 8, 1152)                      4608                 ['k_block6c__0dwconv[0][0]']                                \n",
      "                                                                                                                                                                                    \n",
      " k_block6c__0activation (Activation)                       (None, 8, 8, 1152)                      0                    ['k_block6c__0bn[0][0]']                                    \n",
      "                                                                                                                                                                                    \n",
      " k_block6c__0se_squeeze (GlobalAveragePooling2D)           (None, 1152)                            0                    ['k_block6c__0activation[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_block6c__0se_reshape (Reshape)                          (None, 1, 1, 1152)                      0                    ['k_block6c__0se_squeeze[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_435 (CopyChannels)                          (None, 1, 1, 384)                       0                    ['k_block6c__0se_reshape[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_block6c__0se_reduce_c1_p1_36_conv (Conv2D)              (None, 1, 1, 36)                        1188                 ['k_block6c__0se_reshape[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_block6c__0se_reduce_c1_p2_conv (Conv2D)                 (None, 1, 1, 12)                        396                  ['copy_channels_435[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block6c__0se_reduce_c1_p1_36 (Activation)               (None, 1, 1, 36)                        0                    ['k_block6c__0se_reduce_c1_p1_36_conv[0][0]']               \n",
      "                                                                                                                                                                                    \n",
      " k_block6c__0se_reduce_c1_p2 (Activation)                  (None, 1, 1, 12)                        0                    ['k_block6c__0se_reduce_c1_p2_conv[0][0]']                  \n",
      "                                                                                                                                                                                    \n",
      " k_block6c__0se_reduce_c1_dc (Concatenate)                 (None, 1, 1, 48)                        0                    ['k_block6c__0se_reduce_c1_p1_36[0][0]',                    \n",
      "                                                                                                                         'k_block6c__0se_reduce_c1_p2[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_436 (CopyChannels)                          (None, 1, 1, 16)                        0                    ['k_block6c__0se_reduce_c1_dc[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " concatenate_230 (Concatenate)                             (None, 1, 1, 64)                        0                    ['k_block6c__0se_reduce_c1_dc[0][0]',                       \n",
      "                                                                                                                         'copy_channels_436[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block6c__0se_reduce_c2_m2_conv (Conv2D)                 (None, 1, 1, 48)                        1584                 ['concatenate_230[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block6c__0se_reduce_c2_m2 (Activation)                  (None, 1, 1, 48)                        0                    ['k_block6c__0se_reduce_c2_m2_conv[0][0]']                  \n",
      "                                                                                                                                                                                    \n",
      " k_block6c__0se_reduce_iga (Add)                           (None, 1, 1, 48)                        0                    ['k_block6c__0se_reduce_c2_m2[0][0]',                       \n",
      "                                                                                                                         'k_block6c__0se_reduce_c1_dc[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_437 (CopyChannels)                          (None, 1, 1, 16)                        0                    ['k_block6c__0se_reduce_iga[0][0]']                         \n",
      "                                                                                                                                                                                    \n",
      " concatenate_231 (Concatenate)                             (None, 1, 1, 64)                        0                    ['k_block6c__0se_reduce_iga[0][0]',                         \n",
      "                                                                                                                         'copy_channels_437[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block6c__0se_expand_c1_m2_conv (Conv2D)                 (None, 1, 1, 1152)                      38016                ['concatenate_231[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block6c__0se_expand_c1_m2 (Activation)                  (None, 1, 1, 1152)                      0                    ['k_block6c__0se_expand_c1_m2_conv[0][0]']                  \n",
      "                                                                                                                                                                                    \n",
      " k_block6c__0se_excite (Multiply)                          (None, 8, 8, 1152)                      0                    ['k_block6c__0activation[0][0]',                            \n",
      "                                                                                                                         'k_block6c__0se_expand_c1_m2[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_438 (CopyChannels)                          (None, 8, 8, 384)                       0                    ['k_block6c__0se_excite[0][0]']                             \n",
      "                                                                                                                                                                                    \n",
      " k_block6c__0project_conv_c1_p1_36_conv (Conv2D)           (None, 8, 8, 180)                       5760                 ['k_block6c__0se_excite[0][0]']                             \n",
      "                                                                                                                                                                                    \n",
      " k_block6c__0project_conv_c1_p2_conv (Conv2D)              (None, 8, 8, 12)                        384                  ['copy_channels_438[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block6c__0project_conv_c1_p1_36_bn (BatchNormalization)  (None, 8, 8, 180)                      720                  ['k_block6c__0project_conv_c1_p1_36_conv[0][0]']            \n",
      "                                                                                                                                                                                    \n",
      " k_block6c__0project_conv_c1_p2_bn (BatchNormalization)    (None, 8, 8, 12)                        48                   ['k_block6c__0project_conv_c1_p2_conv[0][0]']               \n",
      "                                                                                                                                                                                    \n",
      " k_block6c__0project_conv_c1_dc (Concatenate)              (None, 8, 8, 192)                       0                    ['k_block6c__0project_conv_c1_p1_36_bn[0][0]',              \n",
      "                                                                                                                         'k_block6c__0project_conv_c1_p2_bn[0][0]']                 \n",
      "                                                                                                                                                                                    \n",
      " k_block6c__0project_conv_i6 (InterleaveChannels)          (None, 8, 8, 192)                       0                    ['k_block6c__0project_conv_c1_dc[0][0]']                    \n",
      "                                                                                                                                                                                    \n",
      " k_block6c__0project_conv_c2_m6_conv (Conv2D)              (None, 8, 8, 192)                       6144                 ['k_block6c__0project_conv_i6[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block6c__0project_conv_c2_m6_bn (BatchNormalization)    (None, 8, 8, 192)                       768                  ['k_block6c__0project_conv_c2_m6_conv[0][0]']               \n",
      "                                                                                                                                                                                    \n",
      " k_block6c__0project_conv_iga (Add)                        (None, 8, 8, 192)                       0                    ['k_block6c__0project_conv_c2_m6_bn[0][0]',                 \n",
      "                                                                                                                         'k_block6c__0project_conv_c1_dc[0][0]']                    \n",
      "                                                                                                                                                                                    \n",
      " k_block6c__0drop (Dropout)                                (None, 8, 8, 192)                       0                    ['k_block6c__0project_conv_iga[0][0]']                      \n",
      "                                                                                                                                                                                    \n",
      " k_block6c__0add (Add)                                     (None, 8, 8, 192)                       0                    ['k_block6c__0drop[0][0]',                                  \n",
      "                                                                                                                         'k_block6b__0add[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block6d__0expand_c1_m6_conv (Conv2D)                    (None, 8, 8, 1152)                      36864                ['k_block6c__0add[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block6d__0expand_c1_m6_bn (BatchNormalization)          (None, 8, 8, 1152)                      4608                 ['k_block6d__0expand_c1_m6_conv[0][0]']                     \n",
      "                                                                                                                                                                                    \n",
      " k_block6d__0expand_c1_m6 (Activation)                     (None, 8, 8, 1152)                      0                    ['k_block6d__0expand_c1_m6_bn[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block6d__0dwconv (DepthwiseConv2D)                      (None, 8, 8, 1152)                      28800                ['k_block6d__0expand_c1_m6[0][0]']                          \n",
      "                                                                                                                                                                                    \n",
      " k_block6d__0bn (BatchNormalization)                       (None, 8, 8, 1152)                      4608                 ['k_block6d__0dwconv[0][0]']                                \n",
      "                                                                                                                                                                                    \n",
      " k_block6d__0activation (Activation)                       (None, 8, 8, 1152)                      0                    ['k_block6d__0bn[0][0]']                                    \n",
      "                                                                                                                                                                                    \n",
      " k_block6d__0se_squeeze (GlobalAveragePooling2D)           (None, 1152)                            0                    ['k_block6d__0activation[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_block6d__0se_reshape (Reshape)                          (None, 1, 1, 1152)                      0                    ['k_block6d__0se_squeeze[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_439 (CopyChannels)                          (None, 1, 1, 384)                       0                    ['k_block6d__0se_reshape[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_block6d__0se_reduce_c1_p1_36_conv (Conv2D)              (None, 1, 1, 36)                        1188                 ['k_block6d__0se_reshape[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_block6d__0se_reduce_c1_p2_conv (Conv2D)                 (None, 1, 1, 12)                        396                  ['copy_channels_439[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block6d__0se_reduce_c1_p1_36 (Activation)               (None, 1, 1, 36)                        0                    ['k_block6d__0se_reduce_c1_p1_36_conv[0][0]']               \n",
      "                                                                                                                                                                                    \n",
      " k_block6d__0se_reduce_c1_p2 (Activation)                  (None, 1, 1, 12)                        0                    ['k_block6d__0se_reduce_c1_p2_conv[0][0]']                  \n",
      "                                                                                                                                                                                    \n",
      " k_block6d__0se_reduce_c1_dc (Concatenate)                 (None, 1, 1, 48)                        0                    ['k_block6d__0se_reduce_c1_p1_36[0][0]',                    \n",
      "                                                                                                                         'k_block6d__0se_reduce_c1_p2[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_440 (CopyChannels)                          (None, 1, 1, 16)                        0                    ['k_block6d__0se_reduce_c1_dc[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " concatenate_232 (Concatenate)                             (None, 1, 1, 64)                        0                    ['k_block6d__0se_reduce_c1_dc[0][0]',                       \n",
      "                                                                                                                         'copy_channels_440[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block6d__0se_reduce_c2_m2_conv (Conv2D)                 (None, 1, 1, 48)                        1584                 ['concatenate_232[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block6d__0se_reduce_c2_m2 (Activation)                  (None, 1, 1, 48)                        0                    ['k_block6d__0se_reduce_c2_m2_conv[0][0]']                  \n",
      "                                                                                                                                                                                    \n",
      " k_block6d__0se_reduce_iga (Add)                           (None, 1, 1, 48)                        0                    ['k_block6d__0se_reduce_c2_m2[0][0]',                       \n",
      "                                                                                                                         'k_block6d__0se_reduce_c1_dc[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_441 (CopyChannels)                          (None, 1, 1, 16)                        0                    ['k_block6d__0se_reduce_iga[0][0]']                         \n",
      "                                                                                                                                                                                    \n",
      " concatenate_233 (Concatenate)                             (None, 1, 1, 64)                        0                    ['k_block6d__0se_reduce_iga[0][0]',                         \n",
      "                                                                                                                         'copy_channels_441[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block6d__0se_expand_c1_m2_conv (Conv2D)                 (None, 1, 1, 1152)                      38016                ['concatenate_233[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block6d__0se_expand_c1_m2 (Activation)                  (None, 1, 1, 1152)                      0                    ['k_block6d__0se_expand_c1_m2_conv[0][0]']                  \n",
      "                                                                                                                                                                                    \n",
      " k_block6d__0se_excite (Multiply)                          (None, 8, 8, 1152)                      0                    ['k_block6d__0activation[0][0]',                            \n",
      "                                                                                                                         'k_block6d__0se_expand_c1_m2[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_442 (CopyChannels)                          (None, 8, 8, 384)                       0                    ['k_block6d__0se_excite[0][0]']                             \n",
      "                                                                                                                                                                                    \n",
      " k_block6d__0project_conv_c1_p1_36_conv (Conv2D)           (None, 8, 8, 180)                       5760                 ['k_block6d__0se_excite[0][0]']                             \n",
      "                                                                                                                                                                                    \n",
      " k_block6d__0project_conv_c1_p2_conv (Conv2D)              (None, 8, 8, 12)                        384                  ['copy_channels_442[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block6d__0project_conv_c1_p1_36_bn (BatchNormalization)  (None, 8, 8, 180)                      720                  ['k_block6d__0project_conv_c1_p1_36_conv[0][0]']            \n",
      "                                                                                                                                                                                    \n",
      " k_block6d__0project_conv_c1_p2_bn (BatchNormalization)    (None, 8, 8, 12)                        48                   ['k_block6d__0project_conv_c1_p2_conv[0][0]']               \n",
      "                                                                                                                                                                                    \n",
      " k_block6d__0project_conv_c1_dc (Concatenate)              (None, 8, 8, 192)                       0                    ['k_block6d__0project_conv_c1_p1_36_bn[0][0]',              \n",
      "                                                                                                                         'k_block6d__0project_conv_c1_p2_bn[0][0]']                 \n",
      "                                                                                                                                                                                    \n",
      " k_block6d__0project_conv_i6 (InterleaveChannels)          (None, 8, 8, 192)                       0                    ['k_block6d__0project_conv_c1_dc[0][0]']                    \n",
      "                                                                                                                                                                                    \n",
      " k_block6d__0project_conv_c2_m6_conv (Conv2D)              (None, 8, 8, 192)                       6144                 ['k_block6d__0project_conv_i6[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block6d__0project_conv_c2_m6_bn (BatchNormalization)    (None, 8, 8, 192)                       768                  ['k_block6d__0project_conv_c2_m6_conv[0][0]']               \n",
      "                                                                                                                                                                                    \n",
      " k_block6d__0project_conv_iga (Add)                        (None, 8, 8, 192)                       0                    ['k_block6d__0project_conv_c2_m6_bn[0][0]',                 \n",
      "                                                                                                                         'k_block6d__0project_conv_c1_dc[0][0]']                    \n",
      "                                                                                                                                                                                    \n",
      " k_block6d__0drop (Dropout)                                (None, 8, 8, 192)                       0                    ['k_block6d__0project_conv_iga[0][0]']                      \n",
      "                                                                                                                                                                                    \n",
      " k_block6d__0add (Add)                                     (None, 8, 8, 192)                       0                    ['k_block6d__0drop[0][0]',                                  \n",
      "                                                                                                                         'k_block6c__0add[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block7a__0expand_c1_m6_conv (Conv2D)                    (None, 8, 8, 1152)                      36864                ['k_block6d__0add[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block7a__0expand_c1_m6_bn (BatchNormalization)          (None, 8, 8, 1152)                      4608                 ['k_block7a__0expand_c1_m6_conv[0][0]']                     \n",
      "                                                                                                                                                                                    \n",
      " k_block7a__0expand_c1_m6 (Activation)                     (None, 8, 8, 1152)                      0                    ['k_block7a__0expand_c1_m6_bn[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " k_block7a__0dwconv (DepthwiseConv2D)                      (None, 8, 8, 1152)                      10368                ['k_block7a__0expand_c1_m6[0][0]']                          \n",
      "                                                                                                                                                                                    \n",
      " k_block7a__0bn (BatchNormalization)                       (None, 8, 8, 1152)                      4608                 ['k_block7a__0dwconv[0][0]']                                \n",
      "                                                                                                                                                                                    \n",
      " k_block7a__0activation (Activation)                       (None, 8, 8, 1152)                      0                    ['k_block7a__0bn[0][0]']                                    \n",
      "                                                                                                                                                                                    \n",
      " k_block7a__0se_squeeze (GlobalAveragePooling2D)           (None, 1152)                            0                    ['k_block7a__0activation[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_block7a__0se_reshape (Reshape)                          (None, 1, 1, 1152)                      0                    ['k_block7a__0se_squeeze[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_443 (CopyChannels)                          (None, 1, 1, 384)                       0                    ['k_block7a__0se_reshape[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_block7a__0se_reduce_c1_p1_36_conv (Conv2D)              (None, 1, 1, 36)                        1188                 ['k_block7a__0se_reshape[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_block7a__0se_reduce_c1_p2_conv (Conv2D)                 (None, 1, 1, 12)                        396                  ['copy_channels_443[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block7a__0se_reduce_c1_p1_36 (Activation)               (None, 1, 1, 36)                        0                    ['k_block7a__0se_reduce_c1_p1_36_conv[0][0]']               \n",
      "                                                                                                                                                                                    \n",
      " k_block7a__0se_reduce_c1_p2 (Activation)                  (None, 1, 1, 12)                        0                    ['k_block7a__0se_reduce_c1_p2_conv[0][0]']                  \n",
      "                                                                                                                                                                                    \n",
      " k_block7a__0se_reduce_c1_dc (Concatenate)                 (None, 1, 1, 48)                        0                    ['k_block7a__0se_reduce_c1_p1_36[0][0]',                    \n",
      "                                                                                                                         'k_block7a__0se_reduce_c1_p2[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_444 (CopyChannels)                          (None, 1, 1, 16)                        0                    ['k_block7a__0se_reduce_c1_dc[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " concatenate_234 (Concatenate)                             (None, 1, 1, 64)                        0                    ['k_block7a__0se_reduce_c1_dc[0][0]',                       \n",
      "                                                                                                                         'copy_channels_444[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block7a__0se_reduce_c2_m2_conv (Conv2D)                 (None, 1, 1, 48)                        1584                 ['concatenate_234[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block7a__0se_reduce_c2_m2 (Activation)                  (None, 1, 1, 48)                        0                    ['k_block7a__0se_reduce_c2_m2_conv[0][0]']                  \n",
      "                                                                                                                                                                                    \n",
      " k_block7a__0se_reduce_iga (Add)                           (None, 1, 1, 48)                        0                    ['k_block7a__0se_reduce_c2_m2[0][0]',                       \n",
      "                                                                                                                         'k_block7a__0se_reduce_c1_dc[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_445 (CopyChannels)                          (None, 1, 1, 16)                        0                    ['k_block7a__0se_reduce_iga[0][0]']                         \n",
      "                                                                                                                                                                                    \n",
      " concatenate_235 (Concatenate)                             (None, 1, 1, 64)                        0                    ['k_block7a__0se_reduce_iga[0][0]',                         \n",
      "                                                                                                                         'copy_channels_445[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block7a__0se_expand_c1_m2_conv (Conv2D)                 (None, 1, 1, 1152)                      38016                ['concatenate_235[0][0]']                                   \n",
      "                                                                                                                                                                                    \n",
      " k_block7a__0se_expand_c1_m2 (Activation)                  (None, 1, 1, 1152)                      0                    ['k_block7a__0se_expand_c1_m2_conv[0][0]']                  \n",
      "                                                                                                                                                                                    \n",
      " k_block7a__0se_excite (Multiply)                          (None, 8, 8, 1152)                      0                    ['k_block7a__0activation[0][0]',                            \n",
      "                                                                                                                         'k_block7a__0se_expand_c1_m2[0][0]']                       \n",
      "                                                                                                                                                                                    \n",
      " copy_channels_446 (CopyChannels)                          (None, 8, 8, 1024)                      0                    ['k_block7a__0se_excite[0][0]']                             \n",
      "                                                                                                                                                                                    \n",
      " k_block7a__0project_conv_c1_p1_36_conv (Conv2D)           (None, 8, 8, 288)                       9216                 ['k_block7a__0se_excite[0][0]']                             \n",
      "                                                                                                                                                                                    \n",
      " k_block7a__0project_conv_c1_p2_conv (Conv2D)              (None, 8, 8, 32)                        1024                 ['copy_channels_446[0][0]']                                 \n",
      "                                                                                                                                                                                    \n",
      " k_block7a__0project_conv_c1_p1_36_bn (BatchNormalization)  (None, 8, 8, 288)                      1152                 ['k_block7a__0project_conv_c1_p1_36_conv[0][0]']            \n",
      "                                                                                                                                                                                    \n",
      " k_block7a__0project_conv_c1_p2_bn (BatchNormalization)    (None, 8, 8, 32)                        128                  ['k_block7a__0project_conv_c1_p2_conv[0][0]']               \n",
      "                                                                                                                                                                                    \n",
      " k_block7a__0project_conv_c1_dc (Concatenate)              (None, 8, 8, 320)                       0                    ['k_block7a__0project_conv_c1_p1_36_bn[0][0]',              \n",
      "                                                                                                                         'k_block7a__0project_conv_c1_p2_bn[0][0]']                 \n",
      "                                                                                                                                                                                    \n",
      " k_block7a__0project_conv_i10 (InterleaveChannels)         (None, 8, 8, 320)                       0                    ['k_block7a__0project_conv_c1_dc[0][0]']                    \n",
      "                                                                                                                                                                                    \n",
      " k_block7a__0project_conv_c2_m10_conv (Conv2D)             (None, 8, 8, 320)                       10240                ['k_block7a__0project_conv_i10[0][0]']                      \n",
      "                                                                                                                                                                                    \n",
      " k_block7a__0project_conv_c2_m10_bn (BatchNormalization)   (None, 8, 8, 320)                       1280                 ['k_block7a__0project_conv_c2_m10_conv[0][0]']              \n",
      "                                                                                                                                                                                    \n",
      " k_block7a__0project_conv_iga (Add)                        (None, 8, 8, 320)                       0                    ['k_block7a__0project_conv_c2_m10_bn[0][0]',                \n",
      "                                                                                                                         'k_block7a__0project_conv_c1_dc[0][0]']                    \n",
      "                                                                                                                                                                                    \n",
      " k_top_conv_c1_m10_conv (Conv2D)                           (None, 8, 8, 1280)                      40960                ['k_block7a__0project_conv_iga[0][0]']                      \n",
      "                                                                                                                                                                                    \n",
      " k_top_conv_c1_m10_bn (BatchNormalization)                 (None, 8, 8, 1280)                      5120                 ['k_top_conv_c1_m10_conv[0][0]']                            \n",
      "                                                                                                                                                                                    \n",
      " k_avg_pool (GlobalAveragePooling2D)                       (None, 1280)                            0                    ['k_top_conv_c1_m10_bn[0][0]']                              \n",
      "                                                                                                                                                                                    \n",
      " k_top_dropout (Dropout)                                   (None, 1280)                            0                    ['k_avg_pool[0][0]']                                        \n",
      "                                                                                                                                                                                    \n",
      " k_probs (Dense)                                           (None, 10)                              12810                ['k_top_dropout[0][0]']                                     \n",
      "                                                                                                                                                                                    \n",
      "====================================================================================================================================================================================\n",
      "Total params: 996,250\n",
      "Trainable params: 950,650\n",
      "Non-trainable params: 45,600\n",
      "____________________________________________________________________________________________________________________________________________________________________________________\n",
      "Finished: kEffNetV2-33\n"
     ]
    }
   ],
   "source": [
    "work_on_efficientnet(show_model=True, run_fit=False, test_results=False, kTypes=kTypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running: kEffNetV2-33\n",
      "213  KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 3), dtype=tf.float32, name='input_12'), name='input_12', description=\"created by layer 'input_12'\")\n",
      "(None, None) channels_last\n",
      "is_inst True\n",
      "214  KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 3), dtype=tf.float32, name=None), name='k_stem_conv_pad/Pad:0', description=\"created by layer 'k_stem_conv_pad'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 32), dtype=tf.float32, name=None), name='k_stem_activation/mul:0', description=\"created by layer 'k_stem_activation'\")\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 32), dtype=tf.float32, name=None), name='k_block1a__0se_reshape/Reshape:0', description=\"created by layer 'k_block1a__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 32), dtype=tf.float32, name=None), name='k_block1a__0se_reshape/Reshape:0', description=\"created by layer 'k_block1a__0se_reshape'\")\n",
      "prev_layer_channel_count  32\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 8), dtype=tf.float32, name=None), name='k_block1a__0se_reduce_um/mul:0', description=\"created by layer 'k_block1a__0se_reduce_um'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 8), dtype=tf.float32, name=None), name='k_block1a__0se_reduce_um/mul:0', description=\"created by layer 'k_block1a__0se_reduce_um'\")\n",
      "prev_layer_channel_count  8\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 32), dtype=tf.float32, name=None), name='k_block1a__0se_excite/mul:0', description=\"created by layer 'k_block1a__0se_excite'\")\n",
      "prev_layer_channel_count  32\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 16), dtype=tf.float32, name=None), name='k_block1a__0project_conv_um_bn/FusedBatchNormV3:0', description=\"created by layer 'k_block1a__0project_conv_um_bn'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 16), dtype=tf.float32, name=None), name='k_block1a__0project_conv_um_bn/FusedBatchNormV3:0', description=\"created by layer 'k_block1a__0project_conv_um_bn'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 16), dtype=tf.float32, name=None), name='k_block1a__0project_conv_um_bn/FusedBatchNormV3:0', description=\"created by layer 'k_block1a__0project_conv_um_bn'\")\n",
      "prev_layer_channel_count  16\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 96), dtype=tf.float32, name=None), name='k_block2a__0se_reshape/Reshape:0', description=\"created by layer 'k_block2a__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 96), dtype=tf.float32, name=None), name='k_block2a__0se_reshape/Reshape:0', description=\"created by layer 'k_block2a__0se_reshape'\")\n",
      "prev_layer_channel_count  96\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 4), dtype=tf.float32, name=None), name='k_block2a__0se_reduce_iga/add:0', description=\"created by layer 'k_block2a__0se_reduce_iga'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 4), dtype=tf.float32, name=None), name='k_block2a__0se_reduce_iga/add:0', description=\"created by layer 'k_block2a__0se_reduce_iga'\")\n",
      "prev_layer_channel_count  4\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 96), dtype=tf.float32, name=None), name='k_block2a__0se_excite/mul:0', description=\"created by layer 'k_block2a__0se_excite'\")\n",
      "prev_layer_channel_count  96\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 24), dtype=tf.float32, name=None), name='k_block2a__0project_conv_iga/add:0', description=\"created by layer 'k_block2a__0project_conv_iga'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 24), dtype=tf.float32, name=None), name='k_block2a__0project_conv_iga/add:0', description=\"created by layer 'k_block2a__0project_conv_iga'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 24), dtype=tf.float32, name=None), name='k_block2a__0project_conv_iga/add:0', description=\"created by layer 'k_block2a__0project_conv_iga'\")\n",
      "prev_layer_channel_count  24\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 144), dtype=tf.float32, name=None), name='k_block2b__0se_reshape/Reshape:0', description=\"created by layer 'k_block2b__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 144), dtype=tf.float32, name=None), name='k_block2b__0se_reshape/Reshape:0', description=\"created by layer 'k_block2b__0se_reshape'\")\n",
      "prev_layer_channel_count  144\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 6), dtype=tf.float32, name=None), name='k_block2b__0se_reduce_iga/add:0', description=\"created by layer 'k_block2b__0se_reduce_iga'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 6), dtype=tf.float32, name=None), name='k_block2b__0se_reduce_iga/add:0', description=\"created by layer 'k_block2b__0se_reduce_iga'\")\n",
      "prev_layer_channel_count  6\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 144), dtype=tf.float32, name=None), name='k_block2b__0se_excite/mul:0', description=\"created by layer 'k_block2b__0se_excite'\")\n",
      "prev_layer_channel_count  144\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 24), dtype=tf.float32, name=None), name='k_block2b__0add/add:0', description=\"created by layer 'k_block2b__0add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 24), dtype=tf.float32, name=None), name='k_block2b__0add/add:0', description=\"created by layer 'k_block2b__0add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 24), dtype=tf.float32, name=None), name='k_block2b__0add/add:0', description=\"created by layer 'k_block2b__0add'\")\n",
      "prev_layer_channel_count  24\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 144), dtype=tf.float32, name=None), name='k_block3a__0se_reshape/Reshape:0', description=\"created by layer 'k_block3a__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 144), dtype=tf.float32, name=None), name='k_block3a__0se_reshape/Reshape:0', description=\"created by layer 'k_block3a__0se_reshape'\")\n",
      "prev_layer_channel_count  144\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 6), dtype=tf.float32, name=None), name='k_block3a__0se_reduce_iga/add:0', description=\"created by layer 'k_block3a__0se_reduce_iga'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 6), dtype=tf.float32, name=None), name='k_block3a__0se_reduce_iga/add:0', description=\"created by layer 'k_block3a__0se_reduce_iga'\")\n",
      "prev_layer_channel_count  6\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 144), dtype=tf.float32, name=None), name='k_block3a__0se_excite/mul:0', description=\"created by layer 'k_block3a__0se_excite'\")\n",
      "prev_layer_channel_count  144\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 40), dtype=tf.float32, name=None), name='k_block3a__0project_conv_iga/add:0', description=\"created by layer 'k_block3a__0project_conv_iga'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 40), dtype=tf.float32, name=None), name='k_block3a__0project_conv_iga/add:0', description=\"created by layer 'k_block3a__0project_conv_iga'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 40), dtype=tf.float32, name=None), name='k_block3a__0project_conv_iga/add:0', description=\"created by layer 'k_block3a__0project_conv_iga'\")\n",
      "prev_layer_channel_count  40\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 240), dtype=tf.float32, name=None), name='k_block3b__0se_reshape/Reshape:0', description=\"created by layer 'k_block3b__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 240), dtype=tf.float32, name=None), name='k_block3b__0se_reshape/Reshape:0', description=\"created by layer 'k_block3b__0se_reshape'\")\n",
      "prev_layer_channel_count  240\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 10), dtype=tf.float32, name=None), name='k_block3b__0se_reduce_iga/add:0', description=\"created by layer 'k_block3b__0se_reduce_iga'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 10), dtype=tf.float32, name=None), name='k_block3b__0se_reduce_iga/add:0', description=\"created by layer 'k_block3b__0se_reduce_iga'\")\n",
      "prev_layer_channel_count  10\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 240), dtype=tf.float32, name=None), name='k_block3b__0se_excite/mul:0', description=\"created by layer 'k_block3b__0se_excite'\")\n",
      "prev_layer_channel_count  240\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 40), dtype=tf.float32, name=None), name='k_block3b__0add/add:0', description=\"created by layer 'k_block3b__0add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 40), dtype=tf.float32, name=None), name='k_block3b__0add/add:0', description=\"created by layer 'k_block3b__0add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 40), dtype=tf.float32, name=None), name='k_block3b__0add/add:0', description=\"created by layer 'k_block3b__0add'\")\n",
      "prev_layer_channel_count  40\n",
      "(None, None) channels_last\n",
      "is_inst True\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 240), dtype=tf.float32, name=None), name='k_block4a__0se_reshape/Reshape:0', description=\"created by layer 'k_block4a__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 240), dtype=tf.float32, name=None), name='k_block4a__0se_reshape/Reshape:0', description=\"created by layer 'k_block4a__0se_reshape'\")\n",
      "prev_layer_channel_count  240\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 10), dtype=tf.float32, name=None), name='k_block4a__0se_reduce_iga/add:0', description=\"created by layer 'k_block4a__0se_reduce_iga'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 10), dtype=tf.float32, name=None), name='k_block4a__0se_reduce_iga/add:0', description=\"created by layer 'k_block4a__0se_reduce_iga'\")\n",
      "prev_layer_channel_count  10\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 240), dtype=tf.float32, name=None), name='k_block4a__0se_excite/mul:0', description=\"created by layer 'k_block4a__0se_excite'\")\n",
      "prev_layer_channel_count  240\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 80), dtype=tf.float32, name=None), name='k_block4a__0project_conv_iga/add:0', description=\"created by layer 'k_block4a__0project_conv_iga'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 80), dtype=tf.float32, name=None), name='k_block4a__0project_conv_iga/add:0', description=\"created by layer 'k_block4a__0project_conv_iga'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 80), dtype=tf.float32, name=None), name='k_block4a__0project_conv_iga/add:0', description=\"created by layer 'k_block4a__0project_conv_iga'\")\n",
      "prev_layer_channel_count  80\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 480), dtype=tf.float32, name=None), name='k_block4b__0se_reshape/Reshape:0', description=\"created by layer 'k_block4b__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 480), dtype=tf.float32, name=None), name='k_block4b__0se_reshape/Reshape:0', description=\"created by layer 'k_block4b__0se_reshape'\")\n",
      "prev_layer_channel_count  480\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 20), dtype=tf.float32, name=None), name='k_block4b__0se_reduce_iga/add:0', description=\"created by layer 'k_block4b__0se_reduce_iga'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 20), dtype=tf.float32, name=None), name='k_block4b__0se_reduce_iga/add:0', description=\"created by layer 'k_block4b__0se_reduce_iga'\")\n",
      "prev_layer_channel_count  20\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 480), dtype=tf.float32, name=None), name='k_block4b__0se_excite/mul:0', description=\"created by layer 'k_block4b__0se_excite'\")\n",
      "prev_layer_channel_count  480\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 80), dtype=tf.float32, name=None), name='k_block4b__0add/add:0', description=\"created by layer 'k_block4b__0add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 80), dtype=tf.float32, name=None), name='k_block4b__0add/add:0', description=\"created by layer 'k_block4b__0add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 80), dtype=tf.float32, name=None), name='k_block4b__0add/add:0', description=\"created by layer 'k_block4b__0add'\")\n",
      "prev_layer_channel_count  80\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 480), dtype=tf.float32, name=None), name='k_block4c__0se_reshape/Reshape:0', description=\"created by layer 'k_block4c__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 480), dtype=tf.float32, name=None), name='k_block4c__0se_reshape/Reshape:0', description=\"created by layer 'k_block4c__0se_reshape'\")\n",
      "prev_layer_channel_count  480\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 20), dtype=tf.float32, name=None), name='k_block4c__0se_reduce_iga/add:0', description=\"created by layer 'k_block4c__0se_reduce_iga'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 20), dtype=tf.float32, name=None), name='k_block4c__0se_reduce_iga/add:0', description=\"created by layer 'k_block4c__0se_reduce_iga'\")\n",
      "prev_layer_channel_count  20\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 480), dtype=tf.float32, name=None), name='k_block4c__0se_excite/mul:0', description=\"created by layer 'k_block4c__0se_excite'\")\n",
      "prev_layer_channel_count  480\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 80), dtype=tf.float32, name=None), name='k_block4c__0add/add:0', description=\"created by layer 'k_block4c__0add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 80), dtype=tf.float32, name=None), name='k_block4c__0add/add:0', description=\"created by layer 'k_block4c__0add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 80), dtype=tf.float32, name=None), name='k_block4c__0add/add:0', description=\"created by layer 'k_block4c__0add'\")\n",
      "prev_layer_channel_count  80\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 480), dtype=tf.float32, name=None), name='k_block5a__0se_reshape/Reshape:0', description=\"created by layer 'k_block5a__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 480), dtype=tf.float32, name=None), name='k_block5a__0se_reshape/Reshape:0', description=\"created by layer 'k_block5a__0se_reshape'\")\n",
      "prev_layer_channel_count  480\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 20), dtype=tf.float32, name=None), name='k_block5a__0se_reduce_iga/add:0', description=\"created by layer 'k_block5a__0se_reduce_iga'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 20), dtype=tf.float32, name=None), name='k_block5a__0se_reduce_iga/add:0', description=\"created by layer 'k_block5a__0se_reduce_iga'\")\n",
      "prev_layer_channel_count  20\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 480), dtype=tf.float32, name=None), name='k_block5a__0se_excite/mul:0', description=\"created by layer 'k_block5a__0se_excite'\")\n",
      "prev_layer_channel_count  480\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 112), dtype=tf.float32, name=None), name='k_block5a__0project_conv_iga/add:0', description=\"created by layer 'k_block5a__0project_conv_iga'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 112), dtype=tf.float32, name=None), name='k_block5a__0project_conv_iga/add:0', description=\"created by layer 'k_block5a__0project_conv_iga'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 112), dtype=tf.float32, name=None), name='k_block5a__0project_conv_iga/add:0', description=\"created by layer 'k_block5a__0project_conv_iga'\")\n",
      "prev_layer_channel_count  112\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 672), dtype=tf.float32, name=None), name='k_block5b__0se_reshape/Reshape:0', description=\"created by layer 'k_block5b__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 672), dtype=tf.float32, name=None), name='k_block5b__0se_reshape/Reshape:0', description=\"created by layer 'k_block5b__0se_reshape'\")\n",
      "prev_layer_channel_count  672\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 28), dtype=tf.float32, name=None), name='k_block5b__0se_reduce_iga/add:0', description=\"created by layer 'k_block5b__0se_reduce_iga'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 28), dtype=tf.float32, name=None), name='k_block5b__0se_reduce_iga/add:0', description=\"created by layer 'k_block5b__0se_reduce_iga'\")\n",
      "prev_layer_channel_count  28\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 672), dtype=tf.float32, name=None), name='k_block5b__0se_excite/mul:0', description=\"created by layer 'k_block5b__0se_excite'\")\n",
      "prev_layer_channel_count  672\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 112), dtype=tf.float32, name=None), name='k_block5b__0add/add:0', description=\"created by layer 'k_block5b__0add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 112), dtype=tf.float32, name=None), name='k_block5b__0add/add:0', description=\"created by layer 'k_block5b__0add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 112), dtype=tf.float32, name=None), name='k_block5b__0add/add:0', description=\"created by layer 'k_block5b__0add'\")\n",
      "prev_layer_channel_count  112\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 672), dtype=tf.float32, name=None), name='k_block5c__0se_reshape/Reshape:0', description=\"created by layer 'k_block5c__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 672), dtype=tf.float32, name=None), name='k_block5c__0se_reshape/Reshape:0', description=\"created by layer 'k_block5c__0se_reshape'\")\n",
      "prev_layer_channel_count  672\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 28), dtype=tf.float32, name=None), name='k_block5c__0se_reduce_iga/add:0', description=\"created by layer 'k_block5c__0se_reduce_iga'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 28), dtype=tf.float32, name=None), name='k_block5c__0se_reduce_iga/add:0', description=\"created by layer 'k_block5c__0se_reduce_iga'\")\n",
      "prev_layer_channel_count  28\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 672), dtype=tf.float32, name=None), name='k_block5c__0se_excite/mul:0', description=\"created by layer 'k_block5c__0se_excite'\")\n",
      "prev_layer_channel_count  672\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 112), dtype=tf.float32, name=None), name='k_block5c__0add/add:0', description=\"created by layer 'k_block5c__0add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 112), dtype=tf.float32, name=None), name='k_block5c__0add/add:0', description=\"created by layer 'k_block5c__0add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 112), dtype=tf.float32, name=None), name='k_block5c__0add/add:0', description=\"created by layer 'k_block5c__0add'\")\n",
      "prev_layer_channel_count  112\n",
      "(None, None) channels_last\n",
      "is_inst True\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 672), dtype=tf.float32, name=None), name='k_block6a__0se_reshape/Reshape:0', description=\"created by layer 'k_block6a__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 672), dtype=tf.float32, name=None), name='k_block6a__0se_reshape/Reshape:0', description=\"created by layer 'k_block6a__0se_reshape'\")\n",
      "prev_layer_channel_count  672\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 28), dtype=tf.float32, name=None), name='k_block6a__0se_reduce_iga/add:0', description=\"created by layer 'k_block6a__0se_reduce_iga'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 28), dtype=tf.float32, name=None), name='k_block6a__0se_reduce_iga/add:0', description=\"created by layer 'k_block6a__0se_reduce_iga'\")\n",
      "prev_layer_channel_count  28\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 672), dtype=tf.float32, name=None), name='k_block6a__0se_excite/mul:0', description=\"created by layer 'k_block6a__0se_excite'\")\n",
      "prev_layer_channel_count  672\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 192), dtype=tf.float32, name=None), name='k_block6a__0project_conv_iga/add:0', description=\"created by layer 'k_block6a__0project_conv_iga'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 192), dtype=tf.float32, name=None), name='k_block6a__0project_conv_iga/add:0', description=\"created by layer 'k_block6a__0project_conv_iga'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 192), dtype=tf.float32, name=None), name='k_block6a__0project_conv_iga/add:0', description=\"created by layer 'k_block6a__0project_conv_iga'\")\n",
      "prev_layer_channel_count  192\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 1152), dtype=tf.float32, name=None), name='k_block6b__0se_reshape/Reshape:0', description=\"created by layer 'k_block6b__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 1152), dtype=tf.float32, name=None), name='k_block6b__0se_reshape/Reshape:0', description=\"created by layer 'k_block6b__0se_reshape'\")\n",
      "prev_layer_channel_count  1152\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 48), dtype=tf.float32, name=None), name='k_block6b__0se_reduce_iga/add:0', description=\"created by layer 'k_block6b__0se_reduce_iga'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 48), dtype=tf.float32, name=None), name='k_block6b__0se_reduce_iga/add:0', description=\"created by layer 'k_block6b__0se_reduce_iga'\")\n",
      "prev_layer_channel_count  48\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 1152), dtype=tf.float32, name=None), name='k_block6b__0se_excite/mul:0', description=\"created by layer 'k_block6b__0se_excite'\")\n",
      "prev_layer_channel_count  1152\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 192), dtype=tf.float32, name=None), name='k_block6b__0add/add:0', description=\"created by layer 'k_block6b__0add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 192), dtype=tf.float32, name=None), name='k_block6b__0add/add:0', description=\"created by layer 'k_block6b__0add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 192), dtype=tf.float32, name=None), name='k_block6b__0add/add:0', description=\"created by layer 'k_block6b__0add'\")\n",
      "prev_layer_channel_count  192\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 1152), dtype=tf.float32, name=None), name='k_block6c__0se_reshape/Reshape:0', description=\"created by layer 'k_block6c__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 1152), dtype=tf.float32, name=None), name='k_block6c__0se_reshape/Reshape:0', description=\"created by layer 'k_block6c__0se_reshape'\")\n",
      "prev_layer_channel_count  1152\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 48), dtype=tf.float32, name=None), name='k_block6c__0se_reduce_iga/add:0', description=\"created by layer 'k_block6c__0se_reduce_iga'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 48), dtype=tf.float32, name=None), name='k_block6c__0se_reduce_iga/add:0', description=\"created by layer 'k_block6c__0se_reduce_iga'\")\n",
      "prev_layer_channel_count  48\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 1152), dtype=tf.float32, name=None), name='k_block6c__0se_excite/mul:0', description=\"created by layer 'k_block6c__0se_excite'\")\n",
      "prev_layer_channel_count  1152\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 192), dtype=tf.float32, name=None), name='k_block6c__0add/add:0', description=\"created by layer 'k_block6c__0add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 192), dtype=tf.float32, name=None), name='k_block6c__0add/add:0', description=\"created by layer 'k_block6c__0add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 192), dtype=tf.float32, name=None), name='k_block6c__0add/add:0', description=\"created by layer 'k_block6c__0add'\")\n",
      "prev_layer_channel_count  192\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 1152), dtype=tf.float32, name=None), name='k_block6d__0se_reshape/Reshape:0', description=\"created by layer 'k_block6d__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 1152), dtype=tf.float32, name=None), name='k_block6d__0se_reshape/Reshape:0', description=\"created by layer 'k_block6d__0se_reshape'\")\n",
      "prev_layer_channel_count  1152\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 48), dtype=tf.float32, name=None), name='k_block6d__0se_reduce_iga/add:0', description=\"created by layer 'k_block6d__0se_reduce_iga'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 48), dtype=tf.float32, name=None), name='k_block6d__0se_reduce_iga/add:0', description=\"created by layer 'k_block6d__0se_reduce_iga'\")\n",
      "prev_layer_channel_count  48\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 1152), dtype=tf.float32, name=None), name='k_block6d__0se_excite/mul:0', description=\"created by layer 'k_block6d__0se_excite'\")\n",
      "prev_layer_channel_count  1152\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 192), dtype=tf.float32, name=None), name='k_block6d__0add/add:0', description=\"created by layer 'k_block6d__0add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 192), dtype=tf.float32, name=None), name='k_block6d__0add/add:0', description=\"created by layer 'k_block6d__0add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 192), dtype=tf.float32, name=None), name='k_block6d__0add/add:0', description=\"created by layer 'k_block6d__0add'\")\n",
      "prev_layer_channel_count  192\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 1152), dtype=tf.float32, name=None), name='k_block7a__0se_reshape/Reshape:0', description=\"created by layer 'k_block7a__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 1152), dtype=tf.float32, name=None), name='k_block7a__0se_reshape/Reshape:0', description=\"created by layer 'k_block7a__0se_reshape'\")\n",
      "prev_layer_channel_count  1152\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 48), dtype=tf.float32, name=None), name='k_block7a__0se_reduce_iga/add:0', description=\"created by layer 'k_block7a__0se_reduce_iga'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 48), dtype=tf.float32, name=None), name='k_block7a__0se_reduce_iga/add:0', description=\"created by layer 'k_block7a__0se_reduce_iga'\")\n",
      "prev_layer_channel_count  48\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 1152), dtype=tf.float32, name=None), name='k_block7a__0se_excite/mul:0', description=\"created by layer 'k_block7a__0se_excite'\")\n",
      "prev_layer_channel_count  1152\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 320), dtype=tf.float32, name=None), name='k_block7a__0project_conv_iga/add:0', description=\"created by layer 'k_block7a__0project_conv_iga'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 320), dtype=tf.float32, name=None), name='k_block7a__0project_conv_iga/add:0', description=\"created by layer 'k_block7a__0project_conv_iga'\")\n",
      "prev_layer_channel_count  320\n",
      "x = cai.layers.kPointwiseConv2D   KerasTensor(type_spec=TensorSpec(shape=(None, None, None, 1280), dtype=tf.float32, name=None), name='k_top_conv_c1_m10_bn/FusedBatchNormV3:0', description=\"created by layer 'k_top_conv_c1_m10_bn'\")\n",
      "Epoch 1/50\n",
      "  2/704 [..............................] - ETA: 9:08:43 - loss: 6.8362 - accuracy: 0.1406 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m work_on_efficientnet(show_model\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, run_fit\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, test_results\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, kTypes\u001b[39m=\u001b[39;49mkTypes)\n",
      "Cell \u001b[1;32mIn[52], line 49\u001b[0m, in \u001b[0;36mwork_on_efficientnet\u001b[1;34m(show_model, run_fit, test_results, calc_f1, kTypes)\u001b[0m\n\u001b[0;32m     37\u001b[0m train_flow \u001b[39m=\u001b[39m train_datagen\u001b[39m.\u001b[39mflow(\n\u001b[0;32m     38\u001b[0m     x_train, y_train,\n\u001b[0;32m     39\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m     40\u001b[0m     shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     41\u001b[0m     seed\u001b[39m=\u001b[39mseed\n\u001b[0;32m     42\u001b[0m )\n\u001b[0;32m     43\u001b[0m validation_flow \u001b[39m=\u001b[39m valid_datagen\u001b[39m.\u001b[39mflow(\n\u001b[0;32m     44\u001b[0m     x_val, y_val,\n\u001b[0;32m     45\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m     46\u001b[0m     shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m     47\u001b[0m     seed\u001b[39m=\u001b[39mseed\n\u001b[0;32m     48\u001b[0m )\n\u001b[1;32m---> 49\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m     50\u001b[0m   x \u001b[39m=\u001b[39;49m train_flow,\n\u001b[0;32m     51\u001b[0m   epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m     52\u001b[0m   batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m     53\u001b[0m   validation_data\u001b[39m=\u001b[39;49mvalidation_flow,\n\u001b[0;32m     54\u001b[0m   callbacks\u001b[39m=\u001b[39;49m[save_best, tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mcallbacks\u001b[39m.\u001b[39;49mLearningRateScheduler(cyclical_adv_lrscheduler25)],\n\u001b[0;32m     55\u001b[0m   workers\u001b[39m=\u001b[39;49mcpus_num,\n\u001b[0;32m     56\u001b[0m   max_queue_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m\n\u001b[0;32m     57\u001b[0m )\n\u001b[0;32m     58\u001b[0m plt\u001b[39m.\u001b[39mfigure()\n\u001b[0;32m     59\u001b[0m plt\u001b[39m.\u001b[39mylabel(\u001b[39m\"\u001b[39m\u001b[39mAccuracy (training and validation)\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\stan_\\lidc-idri-preproc\\diploma_work\\EfficientNet\\.conda\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\stan_\\lidc-idri-preproc\\diploma_work\\EfficientNet\\.conda\\lib\\site-packages\\keras\\engine\\training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1683\u001b[0m ):\n\u001b[0;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_no_variable_creation_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "work_on_efficientnet(show_model=False, run_fit=True, test_results=False, kTypes=kTypes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
