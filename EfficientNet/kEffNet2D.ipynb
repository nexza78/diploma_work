{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kblock(inputs, activation_fn=swish, drop_rate=0., name='',\n",
    "          filters_in=32, filters_out=16, kernel_size=3, strides=1,\n",
    "          expand_ratio=1, se_ratio=0., id_skip=True, kType=1,\n",
    "          dropout_all_blocks=False):\n",
    "    \"\"\"A mobile inverted residual block.\n",
    "    # Arguments\n",
    "        inputs: input tensor.\n",
    "        activation_fn: activation function.\n",
    "        drop_rate: float between 0 and 1, fraction of the input units to drop.\n",
    "        name: string, block label.\n",
    "        filters_in: integer, the number of input filters.\n",
    "        filters_out: integer, the number of output filters.\n",
    "        kernel_size: integer, the dimension of the convolution window.\n",
    "        strides: integer, the stride of the convolution.\n",
    "        expand_ratio: integer, scaling coefficient for the input filters.\n",
    "        se_ratio: float between 0 and 1, fraction to squeeze the input filters.\n",
    "        id_skip: boolean.\n",
    "    # Returns\n",
    "        output tensor for the block.\n",
    "    \"\"\"\n",
    "    bn_axis = 3\n",
    "\n",
    "    # Expansion phase\n",
    "    filters = filters_in * expand_ratio\n",
    "    if expand_ratio != 1:\n",
    "        #x = layers.Conv2D(filters, 1,\n",
    "        #                 padding='same',\n",
    "        #                  use_bias=False,\n",
    "        #                  kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "        #                  name=name + 'expand_conv')(inputs)\n",
    "        #x = layers.BatchNormalization(axis=bn_axis, name=name + 'expand_bn')(x)\n",
    "        #x = layers.Activation(activation_fn, name=name + 'expand_activation')(x)\n",
    "        x = cai.layers.kPointwiseConv2D(last_tensor=inputs, filters=filters, channel_axis=bn_axis, name=name+'expand', activation=activation_fn, has_batch_norm=True, use_bias=False, kType=kType)\n",
    "    else:\n",
    "        x = inputs\n",
    "\n",
    "    # Depthwise Convolution\n",
    "    if strides == 2:\n",
    "        x = layers.ZeroPadding2D(padding=correct_pad(backend, x, kernel_size),\n",
    "                                 name=name + 'dwconv_pad')(x)\n",
    "        conv_pad = 'valid'\n",
    "    else:\n",
    "        conv_pad = 'same'\n",
    "    x = layers.DepthwiseConv2D(kernel_size,\n",
    "                               strides=strides,\n",
    "                               padding=conv_pad,\n",
    "                               use_bias=False,\n",
    "                               depthwise_initializer=CONV_KERNEL_INITIALIZER,\n",
    "                               name=name + 'dwconv')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name=name + 'bn')(x)\n",
    "    x = layers.Activation(activation_fn, name=name + 'activation')(x)\n",
    "\n",
    "    # Squeeze and Excitation phase\n",
    "    if 0 < se_ratio <= 1:\n",
    "        filters_se = max(1, int(filters_in * se_ratio))\n",
    "        se = layers.GlobalAveragePooling2D(name=name + 'se_squeeze')(x)\n",
    "        if bn_axis == 1:\n",
    "            se = layers.Reshape((filters, 1, 1), name=name + 'se_reshape')(se)\n",
    "        else:\n",
    "            se = layers.Reshape((1, 1, filters), name=name + 'se_reshape')(se)\n",
    "        #se = layers.Conv2D(filters_se, 1,\n",
    "        #                   padding='same',\n",
    "        #                   activation=activation_fn,\n",
    "        #                   kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "        #                   name=name + 'se_reduce')(se)\n",
    "        se = cai.layers.kPointwiseConv2D(last_tensor=se, filters=filters_se, channel_axis=bn_axis, name=name+'se_reduce', activation=activation_fn, has_batch_norm=False, use_bias=True, kType=kType)\n",
    "        #se = layers.Conv2D(filters, 1,\n",
    "        #                   padding='same',\n",
    "        #                   activation='sigmoid',\n",
    "        #                   kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "        #                   name=name + 'se_expand')(se)\n",
    "        se = cai.layers.kPointwiseConv2D(last_tensor=se, filters=filters, channel_axis=bn_axis, name=name+'se_expand', activation='sigmoid', has_batch_norm=False, use_bias=True, kType=kType)\n",
    "        x = layers.multiply([x, se], name=name + 'se_excite')\n",
    "\n",
    "    # Output phase\n",
    "    #x = layers.Conv2D(filters_out, 1,\n",
    "    #                  padding='same',\n",
    "    #                  use_bias=False,\n",
    "    #                  kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "    #                  name=name + 'project_conv')(x)\n",
    "    # x = layers.BatchNormalization(axis=bn_axis, name=name + 'project_bn')(x)\n",
    "    x = cai.layers.kPointwiseConv2D(last_tensor=x, filters=filters_out, channel_axis=bn_axis, name=name+'project_conv', activation=None, has_batch_norm=True, use_bias=False, kType=kType)\n",
    "\n",
    "    if (drop_rate > 0)  and (dropout_all_blocks):\n",
    "        x = layers.Dropout(drop_rate,\n",
    "                noise_shape=(None, 1, 1, 1),\n",
    "                name=name + 'drop')(x)\n",
    "\n",
    "    if (id_skip is True and strides == 1 and filters_in == filters_out):\n",
    "        if (drop_rate > 0)  and (not dropout_all_blocks):\n",
    "            x = layers.Dropout(drop_rate,\n",
    "                               noise_shape=(None, 1, 1, 1),\n",
    "                               name=name + 'drop')(x)\n",
    "        x = layers.add([x, inputs], name=name + 'add')\n",
    "    return x\n",
    "\n",
    "def kblockLastName(drop_rate=0., name='',\n",
    "          filters_in=32, filters_out=16, strides=1,\n",
    "          id_skip=True,\n",
    "          dropout_all_blocks=False):\n",
    "    last_name = name + 'project_conv'\n",
    "\n",
    "    if (drop_rate > 0)  and (dropout_all_blocks):\n",
    "        last_name = name + 'drop'\n",
    "\n",
    "    if (id_skip is True and strides == 1 and filters_in == filters_out):\n",
    "        last_name = name + 'add'\n",
    "    return last_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/joaopauloschuler/k-neural-api/blob/master/cai/efficientnet.py\n",
    "\n",
    "def kEffNet2D(\n",
    "        width_coefficient,\n",
    "        depth_coefficient,\n",
    "        skip_stride_cnt=-1,\n",
    "        dropout_rate=0.2,\n",
    "        drop_connect_rate=0.2,\n",
    "        depth_divisor=8,\n",
    "        activation_fn=swish,\n",
    "        blocks_args=DEFAULT_BLOCKS_ARGS,\n",
    "        model_name='efficientnet',\n",
    "        include_top=True,\n",
    "        input_tensor=None,\n",
    "        input_shape=None,\n",
    "        pooling=None,\n",
    "        classes=1000,\n",
    "        kType=2,\n",
    "        concat_paths=True,\n",
    "        dropout_all_blocks=False,\n",
    "        name_prefix='k_',\n",
    "        **kwargs):\n",
    "    \"\"\"Instantiates the EfficientNet architecture using given scaling coefficients.\n",
    "    Optionally loads weights pre-trained on ImageNet.\n",
    "    Note that the data format convention used by the model is\n",
    "    the one specified in your Keras config at `~/.keras/keras.json`.\n",
    "    # Arguments\n",
    "        width_coefficient: float, scaling coefficient for network width.\n",
    "        depth_coefficient: float, scaling coefficient for network depth.\n",
    "        skip_stride_cnt: number of layers to skip stride. This parameter is used with smalll images such as CIFAR-10.\n",
    "        dropout_rate: float, dropout rate before final classifier layer.\n",
    "        drop_connect_rate: float, dropout rate at skip connections.\n",
    "        depth_divisor: integer, a unit of network width.\n",
    "        activation_fn: activation function.\n",
    "        blocks_args: list of dicts, parameters to construct block modules.\n",
    "        model_name: string, model name.\n",
    "        include_top: whether to include the fully-connected\n",
    "            layer at the top of the network.\n",
    "        input_tensor: optional Keras tensor\n",
    "            (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False.\n",
    "            It should have exactly 3 inputs channels.\n",
    "        pooling: optional pooling mode for feature extraction\n",
    "            when `include_top` is `False`.\n",
    "            - `None` means that the output of the model will be\n",
    "                the 4D tensor output of the\n",
    "                last convolutional layer.\n",
    "            - `avg` means that global average pooling\n",
    "                will be applied to the output of the\n",
    "                last convolutional layer, and thus\n",
    "                the output of the model will be a 2D tensor.\n",
    "            - `max` means that global max pooling will\n",
    "                be applied.\n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    # Raises\n",
    "        ValueError: in case of invalid input shape.\n",
    "    \"\"\"\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = layers.Input(shape=input_shape)\n",
    "    else:\n",
    "        if not backend.is_keras_tensor(input_tensor):\n",
    "            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    bn_axis = 3\n",
    "\n",
    "    def round_filters(filters, divisor=depth_divisor):\n",
    "        \"\"\"Round number of filters based on depth multiplier.\"\"\"\n",
    "        filters *= width_coefficient\n",
    "        new_filters = max(divisor, int(filters + divisor / 2) // divisor * divisor)\n",
    "        # Make sure that round down does not go down by more than 10%.\n",
    "        if new_filters < 0.9 * filters:\n",
    "            new_filters += divisor\n",
    "        return int(new_filters)\n",
    "\n",
    "    def round_repeats(repeats):\n",
    "        \"\"\"Round number of repeats based on depth multiplier.\"\"\"\n",
    "        return int(math.ceil(depth_coefficient * repeats))\n",
    "\n",
    "    if isinstance(kType, (int)):\n",
    "        kTypeList = [kType]\n",
    "    else:\n",
    "        kTypeList = kType\n",
    "    \n",
    "    # Build stem\n",
    "    x = img_input\n",
    "    x = layers.ZeroPadding2D(padding=correct_pad(backend, x, 3),\n",
    "                             name=name_prefix+'stem_conv_pad')(x)\n",
    "    first_stride = 1 if skip_stride_cnt >= 0 else 2\n",
    "    x = layers.Conv2D(round_filters(32), 3,\n",
    "                      strides=first_stride,\n",
    "                      padding='valid',\n",
    "                      use_bias=False,\n",
    "                      kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "                      name=name_prefix+'stem_conv')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name=name_prefix+'stem_bn')(x)\n",
    "    x = layers.Activation(activation_fn, name=name_prefix+'stem_activation')(x)\n",
    "\n",
    "    root_layer = x\n",
    "    output_layers = []\n",
    "    path_cnt = 0\n",
    "    for kType in kTypeList:\n",
    "        x = root_layer\n",
    "        blocks_args_cp = deepcopy(blocks_args)\n",
    "        b = 0\n",
    "        blocks = float(sum(args['repeats'] for args in blocks_args_cp))\n",
    "        #only the first branch can backpropagate to the input.\n",
    "        #if path_cnt>0:\n",
    "        #    x = keras.layers.Lambda(lambda x: tensorflow.stop_gradient(x))(x)\n",
    "        for (i, args) in enumerate(blocks_args_cp):\n",
    "            assert args['repeats'] > 0\n",
    "            # Update block input and output filters based on depth multiplier.\n",
    "            args['filters_in'] = round_filters(args['filters_in'])\n",
    "            args['filters_out'] = round_filters(args['filters_out'])\n",
    "\n",
    "            for j in range(round_repeats(args.pop('repeats'))):\n",
    "                #should skip the stride\n",
    "                if (skip_stride_cnt > i) and (j == 0) and (args['strides'] > 1):\n",
    "                    args['strides'] = 1\n",
    "                # The first block needs to take care of stride and filter size increase.\n",
    "                if (j > 0):\n",
    "                    args['strides'] = 1\n",
    "                    args['filters_in'] = args['filters_out']\n",
    "                x = kblock(x, activation_fn, drop_connect_rate * b / blocks,\n",
    "                          name=name_prefix+'block{}{}_'.format(i + 1, chr(j + 97))+'_'+str(path_cnt), **args,\n",
    "                          kType=kType, dropout_all_blocks=dropout_all_blocks)\n",
    "                b += 1\n",
    "        if (len(kTypeList)>1):\n",
    "            x = layers.Activation('relu', name=name_prefix+'end_relu'+'_'+str(path_cnt))(x)\n",
    "        output_layers.append(x)\n",
    "        path_cnt = path_cnt +1\n",
    "        \n",
    "    if (len(output_layers)==1):\n",
    "        x = output_layers[0]\n",
    "    else:\n",
    "        if concat_paths:\n",
    "            x = keras.layers.Concatenate(axis=bn_axis, name=name_prefix+'global_concat')(output_layers)\n",
    "        else:\n",
    "            x = keras.layers.add(output_layers, name=name_prefix+'global_add')\n",
    "\n",
    "    # Build top\n",
    "    #x = layers.Conv2D(round_filters(1280), 1,\n",
    "    #                  padding='same',\n",
    "    #                  use_bias=False,\n",
    "    #                  kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "    #                  name='top_conv')(x)\n",
    "    #x = layers.BatchNormalization(axis=bn_axis, name='top_bn')(x)\n",
    "    #x = layers.Activation(activation_fn, name='top_activation')(x)\n",
    "    x = cai.layers.kPointwiseConv2D(last_tensor=x, filters=round_filters(1280), channel_axis=bn_axis, name=name_prefix+'top_conv', activation=None, has_batch_norm=True, use_bias=False, kType=kType)\n",
    "\n",
    "    if pooling == 'avg':\n",
    "        x = layers.GlobalAveragePooling2D(name=name_prefix+'avg_pool')(x)\n",
    "    elif pooling == 'max':\n",
    "        x = layers.GlobalMaxPooling2D(name=name_prefix+'max_pool')(x)\n",
    "    elif pooling == 'avgmax':\n",
    "        x = cai.layers.GlobalAverageMaxPooling2D(x, name=name_prefix+'avgmax_pool')\n",
    "\n",
    "    if include_top:\n",
    "        if (dropout_rate > 0):\n",
    "            x = layers.Dropout(dropout_rate, name=name_prefix+'top_dropout')(x)\n",
    "        x = layers.Dense(classes,\n",
    "            activation='softmax', # 'softmax'\n",
    "            kernel_initializer=DENSE_KERNEL_INITIALIZER,\n",
    "            name=name_prefix+'probs')(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = utils.get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "\n",
    "    # Create model.\n",
    "    model = models.Model(inputs, x, name=model_name)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kEfficientNetB0(include_top=True,\n",
    "                   input_tensor=None,\n",
    "                   input_shape=None,\n",
    "                   pooling='avg',\n",
    "                   classes=1000,\n",
    "                   kType=2,\n",
    "                   dropout_rate=0.2,\n",
    "                   drop_connect_rate=0.2,\n",
    "                   skip_stride_cnt=-1,\n",
    "                   activation_fn=swish,\n",
    "                   dropout_all_blocks=False,\n",
    "                   **kwargs):\n",
    "    return kEfficientNet(1.0, 1.0, skip_stride_cnt=skip_stride_cnt, # 224,\n",
    "                        model_name='kEffNet-b0',\n",
    "                        include_top=include_top,\n",
    "                        input_tensor=input_tensor, input_shape=input_shape,\n",
    "                        pooling=pooling, classes=classes,\n",
    "                        kType=kType,\n",
    "                        dropout_rate=dropout_rate,\n",
    "                        drop_connect_rate=drop_connect_rate,\n",
    "                        activation_fn=activation_fn,\n",
    "                        dropout_all_blocks=dropout_all_blocks,\n",
    "                        **kwargs)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
