{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "\n",
    "import math\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "import tensorflow\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cai.util\n",
    "import cai.models\n",
    "import cai.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_pad(backend, inputs, kernel_size):\n",
    "    \"\"\"Returns a tuple for zero-padding for 2D convolution with downsampling.\n",
    "    # Arguments\n",
    "        input_size: An integer or tuple/list of 2 integers.\n",
    "        kernel_size: An integer or tuple/list of 2 integers.\n",
    "    # Returns\n",
    "        A tuple.\n",
    "    \"\"\"\n",
    "    img_dim = 1 # 2 if backend.image_data_format() == 'channels_first' else 1\n",
    "    #извлечение чисел - первое равно h/w, второе - n_channels\n",
    "    input_size = backend.int_shape(inputs)[img_dim:(img_dim + 2)]\n",
    "    print(input_size, backend.image_data_format())\n",
    "\n",
    "    if isinstance(kernel_size, int):\n",
    "        print('is_inst', isinstance(kernel_size, int))\n",
    "        kernel_size = (kernel_size, kernel_size)\n",
    "\n",
    "    if input_size[0] is None:\n",
    "        adjust = (1, 1)\n",
    "    else:\n",
    "        adjust = (1 - input_size[0] % 2, 1 - input_size[1] % 2)\n",
    "\n",
    "    correct = (kernel_size[0] // 2, kernel_size[1] // 2)\n",
    "\n",
    "    return ((correct[0] - adjust[0], correct[0]),\n",
    "            (correct[1] - adjust[1], correct[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.random.rand(32, 32,32, 3)\n",
    "\n",
    "kernel_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32) channels_last\n",
      "is_inst True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0, 1), (0, 1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_pad(backend,  inputs, kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swish(x):\n",
    "    \"\"\"Swish activation function.\n",
    "    # Arguments\n",
    "        x: Input tensor.\n",
    "    # Returns\n",
    "        The Swish activation: `x * sigmoid(x)`.\n",
    "    # References\n",
    "        [Searching for Activation Functions](https://arxiv.org/abs/1710.05941)\n",
    "    \"\"\"\n",
    "    if backend.backend() == 'tensorflow':\n",
    "        try:\n",
    "            # The native TF implementation has a more\n",
    "            # memory-efficient gradient implementation\n",
    "            return backend.tf.nn.swish(x)\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "    return x * backend.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEFAULT_BLOCKS_ARGS = [\n",
    "    {'kernel_size': 3, 'repeats': 1, 'filters_in': 32, 'filters_out': 16,\n",
    "     'expand_ratio': 1, 'id_skip': True, 'strides': 1, 'se_ratio': 0.25},\n",
    "    {'kernel_size': 3, 'repeats': 2, 'filters_in': 16, 'filters_out': 24,\n",
    "     'expand_ratio': 6, 'id_skip': True, 'strides': 2, 'se_ratio': 0.25},\n",
    "    {'kernel_size': 5, 'repeats': 2, 'filters_in': 24, 'filters_out': 40,\n",
    "     'expand_ratio': 6, 'id_skip': True, 'strides': 2, 'se_ratio': 0.25},\n",
    "    {'kernel_size': 3, 'repeats': 3, 'filters_in': 40, 'filters_out': 80,\n",
    "     'expand_ratio': 6, 'id_skip': True, 'strides': 2, 'se_ratio': 0.25},\n",
    "    {'kernel_size': 5, 'repeats': 3, 'filters_in': 80, 'filters_out': 112,\n",
    "     'expand_ratio': 6, 'id_skip': True, 'strides': 1, 'se_ratio': 0.25},\n",
    "    {'kernel_size': 5, 'repeats': 4, 'filters_in': 112, 'filters_out': 192,\n",
    "     'expand_ratio': 6, 'id_skip': True, 'strides': 2, 'se_ratio': 0.25},\n",
    "    {'kernel_size': 3, 'repeats': 1, 'filters_in': 192, 'filters_out': 320,\n",
    "     'expand_ratio': 6, 'id_skip': True, 'strides': 1, 'se_ratio': 0.25}\n",
    "] \n",
    "\n",
    "CONV_KERNEL_INITIALIZER = {\n",
    "    'class_name': 'VarianceScaling',\n",
    "    'config': {\n",
    "        'scale': 2.0,\n",
    "        'mode': 'fan_out',\n",
    "        # EfficientNet actually uses an untruncated normal distribution for\n",
    "        # initializing conv layers, but keras.initializers.VarianceScaling use\n",
    "        # a truncated distribution.\n",
    "        # We decided against a custom initializer for better serializability.\n",
    "        'distribution': 'normal'\n",
    "    }\n",
    "}\n",
    "\n",
    "DENSE_KERNEL_INITIALIZER = {\n",
    "    'class_name': 'VarianceScaling',\n",
    "    'config': {\n",
    "        'scale': 1. / 3.,\n",
    "        'mode': 'fan_out',\n",
    "        'distribution': 'uniform'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def kConv2D(last_tensor, filters=32, channel_axis=3, name=None, activation=None, has_batch_norm=True, has_batch_scale=True, use_bias=True, kernel_size=1, stride_size=1, padding='same', kType=2):\n",
    "    print(\"last_tensor  \", last_tensor)\n",
    "    prev_layer_channel_count = tensorflow.keras.backend.int_shape(last_tensor)[channel_axis]\n",
    "    print(\"prev_layer_channel_count \", prev_layer_channel_count)\n",
    "\n",
    "    \n",
    "    if kType == 0:\n",
    "        return kConv2DType0(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding)\n",
    "    #elif kType == 1:\n",
    "    #    return kConv2DType1(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding)\n",
    "    #elif kType == D6_16ch():\n",
    "    #    return kConv2DType2(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=16)\n",
    "    #elif kType == kT3_16ch():\n",
    "    #    return kConv2DType3(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding)\n",
    "    #elif kType == 4:\n",
    "    #    return kConv2DType4(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding)\n",
    "    #elif kType == 5:\n",
    "    #    return kConv2DType5(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding)\n",
    "    #elif kType == 6:\n",
    "    #    return kConv2DType6(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding)\n",
    "    #elif kType == 7:\n",
    "    #    return kConv2DType7(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, bin_conv_count=0)\n",
    "    #elif kType == 8:\n",
    "    #    return kConv2DType7(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, bin_conv_count=1)\n",
    "    #elif kType == 9:\n",
    "    #    return kConv2DType7(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, bin_conv_count=2)\n",
    "    #elif kType == 10:\n",
    "    #    return kConv2DType7(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, bin_conv_count=4)\n",
    "    #elif kType == 11:\n",
    "    #    return kConv2DType7(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, bin_conv_count=5)\n",
    "    #elif kType == 12:\n",
    "    #    return kConv2DType7(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, bin_conv_count=6)\n",
    "    elif kType == cai.layers.D6_32ch():\n",
    "        return cai.layers.kConv2DType2(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=32)\n",
    "    #elif kType == D6_8ch():\n",
    "    #    return kConv2DType2(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=8)\n",
    "    #elif kType == D6_4ch():\n",
    "    #    return kConv2DType2(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=4)\n",
    "    #elif kType == 16:\n",
    "    #    if prev_layer_channel_count >= filters:\n",
    "    #        return kConv2DType2(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=32)\n",
    "    #    else:\n",
    "    #        return kConv2DType2(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=16)\n",
    "    #elif kType == 17:\n",
    "    #    if prev_layer_channel_count < filters:\n",
    "    #        return kConv2DType2(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=32)\n",
    "    #    else:\n",
    "    #        return kConv2DType2(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=16)\n",
    "    #elif kType == 18:\n",
    "    #    if prev_layer_channel_count >= filters:\n",
    "    #        return kConv2DType7(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, bin_conv_count=5)\n",
    "    #    else:\n",
    "    #        return kConv2DType2(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=16)\n",
    "    #elif kType == 19:\n",
    "    #    return kConv2DType8(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=16)\n",
    "    #elif kType == 20:\n",
    "    #    return kConv2DType8(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=32)\n",
    "    #elif kType == 21:\n",
    "    #    return kConv2DType8(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=16, always_intergroup=True)\n",
    "    #elif kType == 22:\n",
    "    #    return kConv2DType8(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=32, always_intergroup=True)\n",
    "    #elif kType == kT3_32ch():\n",
    "    #    return kConv2DType3(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=32)\n",
    "    #elif kType == D6_64ch():\n",
    "    #    return kConv2DType2(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=64)\n",
    "    #elif kType == kT3_64ch():\n",
    "    #    return kConv2DType3(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=64)\n",
    "    #elif kType == D6_128ch():\n",
    "    #    return kConv2DType2(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=128)\n",
    "    #elif kType == kT3_128ch():\n",
    "    #    return kConv2DType3(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=128)\n",
    "    #elif kType == 28:\n",
    "    #    return kConv2DType9(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=16, always_intergroup=True)\n",
    "    #elif kType == 29:\n",
    "    #    return kConv2DType9(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=32, always_intergroup=True)\n",
    "    #elif kType == 30:\n",
    "    #    return kConv2DType9(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=64, always_intergroup=True)\n",
    "    #elif kType == 31:\n",
    "    #    return kConv2DType9(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=128, always_intergroup=True)\n",
    "    #elif kType == D6v3_16ch():\n",
    "    #    return kConv2DType10(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, min_channels_per_group=16, kernel_size=kernel_size, stride_size=stride_size, padding=padding)\n",
    "    #elif kType == D6v3_32ch():\n",
    "    #    return kConv2DType10(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, min_channels_per_group=32, kernel_size=kernel_size, stride_size=stride_size, padding=padding)\n",
    "    #elif kType == D6v3_64ch():\n",
    "    #    return kConv2DType10(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, min_channels_per_group=64, kernel_size=kernel_size, stride_size=stride_size, padding=padding)\n",
    "    #elif kType == D6v3_128ch():\n",
    "    #    return kConv2DType10(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, min_channels_per_group=128, kernel_size=kernel_size, stride_size=stride_size, padding=padding)\n",
    "    #elif kType == kT3v3_16ch():\n",
    "    #    return kConv2DType10(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, min_channels_per_group=16, kernel_size=kernel_size, stride_size=stride_size, padding=padding, never_intergroup=True)\n",
    "    #elif kType == kT3v3_32ch():\n",
    "    #    return kConv2DType10(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, min_channels_per_group=32, kernel_size=kernel_size, stride_size=stride_size, padding=padding, never_intergroup=True)\n",
    "    #elif kType == kT3v3_64ch():\n",
    "    #    return kConv2DType10(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, min_channels_per_group=64, kernel_size=kernel_size, stride_size=stride_size, padding=padding, never_intergroup=True)\n",
    "    #elif kType == kT3v3_128ch():\n",
    "    #    return kConv2DType10(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, min_channels_per_group=128, kernel_size=kernel_size, stride_size=stride_size, padding=padding, never_intergroup=True)\n",
    "    #elif kType == D6_12ch():\n",
    "    #    return kConv2DType2(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=12)\n",
    "    #elif kType == D6_24ch():\n",
    "    #    return kConv2DType2(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=kernel_size, stride_size=stride_size, padding=padding, min_channels_per_group=24)\n",
    "    #elif kType == D6v3_12ch():\n",
    "    #    return kConv2DType10(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, min_channels_per_group=12, kernel_size=kernel_size, stride_size=stride_size, padding=padding)\n",
    "    #elif kType == D6v3_24ch():\n",
    "    #    return kConv2DType10(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, min_channels_per_group=24, kernel_size=kernel_size, stride_size=stride_size, padding=padding)\n",
    "    #elif kType == D6v3_8ch():\n",
    "    #    return kConv2DType10(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, min_channels_per_group=8, kernel_size=kernel_size, stride_size=stride_size, padding=padding)\n",
    "    #elif kType == D6v3_4ch():\n",
    "    #    return kConv2DType10(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, min_channels_per_group=4, kernel_size=kernel_size, stride_size=stride_size, padding=padding)\n",
    "    #elif kType == D6v3_2ch():\n",
    "    #    return kConv2DType10(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, min_channels_per_group=2, kernel_size=kernel_size, stride_size=stride_size, padding=padding)\n",
    "    #elif kType == kT3v3_4ch():\n",
    "    #    return kConv2DType10(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, min_channels_per_group=4, kernel_size=kernel_size, stride_size=stride_size, padding=padding, never_intergroup=True)\n",
    "    #elif kType == kT3v3_8ch():\n",
    "    #    return kConv2DType10(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, min_channels_per_group=8, kernel_size=kernel_size, stride_size=stride_size, padding=padding, never_intergroup=True)\n",
    "\n",
    "def kPointwiseConv2D(last_tensor, filters=32, channel_axis=3, name=None, activation=None, has_batch_norm=True, has_batch_scale=True, use_bias=True, kType=2):\n",
    "    \"\"\"\n",
    "    Parameter efficient pointwise convolution as shown in these papers:\n",
    "    https://www.researchgate.net/publication/360226228_Grouped_Pointwise_Convolutions_Reduce_Parameters_in_Convolutional_Neural_Networks\n",
    "    https://www.researchgate.net/publication/363413038_An_Enhanced_Scheme_for_Reducing_the_Complexity_of_Pointwise_Convolutions_in_CNNs_for_Image_Classification_Based_on_Interleaved_Grouped_Filters_without_Divisibility_Constraints\n",
    "    \"\"\"\n",
    "    return kConv2D(last_tensor, filters=filters, channel_axis=channel_axis, name=name, activation=activation, has_batch_norm=has_batch_norm, has_batch_scale=has_batch_scale, use_bias=use_bias, kernel_size=1, stride_size=1, padding='same', kType=kType)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def kblock(inputs, activation_fn=swish, drop_rate=0., name='',\n",
    "          filters_in=32, filters_out=16, kernel_size=3, strides=1,\n",
    "          expand_ratio=1, se_ratio=0., id_skip=True, kType=1,\n",
    "          dropout_all_blocks=False):\n",
    "    \"\"\"A mobile inverted residual block.\n",
    "    # Arguments\n",
    "        inputs: input tensor.\n",
    "        activation_fn: activation function.\n",
    "        drop_rate: float between 0 and 1, fraction of the input units to drop.\n",
    "        name: string, block label.\n",
    "        filters_in: integer, the number of input filters.\n",
    "        filters_out: integer, the number of output filters.\n",
    "        kernel_size: integer, the dimension of the convolution window.\n",
    "        strides: integer, the stride of the convolution.\n",
    "        expand_ratio: integer, scaling coefficient for the input filters.\n",
    "        se_ratio: float between 0 and 1, fraction to squeeze the input filters.\n",
    "        id_skip: boolean.\n",
    "    # Returns\n",
    "        output tensor for the block.\n",
    "    \"\"\"\n",
    "    bn_axis = 3\n",
    "\n",
    "    # Expansion phase\n",
    "    filters = filters_in * expand_ratio\n",
    "    \n",
    "    if expand_ratio != 1:\n",
    "        #x = layers.Conv2D(filters, 1,\n",
    "        #                 padding='same',\n",
    "        #                  use_bias=False,\n",
    "        #                  kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "        #                  name=name + 'expand_conv')(inputs)\n",
    "        #x = layers.BatchNormalization(axis=bn_axis, name=name + 'expand_bn')(x)\n",
    "        #x = layers.Activation(activation_fn, name=name + 'expand_activation')(x)\n",
    "        x = cai.layers.kPointwiseConv2D(last_tensor=inputs, filters=filters, channel_axis=bn_axis, name=name+'expand', activation=activation_fn, has_batch_norm=True, use_bias=False, kType=kType)\n",
    "    else:\n",
    "        x = inputs\n",
    "\n",
    "    # Depthwise Convolution\n",
    "    if strides == 2:\n",
    "        x = layers.ZeroPadding2D(padding=correct_pad(backend, x, kernel_size),\n",
    "                                 name=name + 'dwconv_pad')(x)\n",
    "        conv_pad = 'valid'\n",
    "    else:\n",
    "        conv_pad = 'same'\n",
    "    x = layers.DepthwiseConv2D(kernel_size,\n",
    "                               strides=strides,\n",
    "                               padding=conv_pad,\n",
    "                               use_bias=False,\n",
    "                               depthwise_initializer=CONV_KERNEL_INITIALIZER,\n",
    "                               name=name + 'dwconv')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name=name + 'bn')(x)\n",
    "    x = layers.Activation(activation_fn, name=name + 'activation')(x)\n",
    "\n",
    "    # Squeeze and Excitation phase\n",
    "    if 0 < se_ratio <= 1:\n",
    "        filters_se = max(1, int(filters_in * se_ratio))\n",
    "        se = layers.GlobalAveragePooling2D(name=name + 'se_squeeze')(x)\n",
    "        if bn_axis == 1:\n",
    "            se = layers.Reshape((filters, 1, 1), name=name + 'se_reshape')(se)\n",
    "        else:\n",
    "            se = layers.Reshape((1, 1, filters), name=name + 'se_reshape')(se)\n",
    "        #se = layers.Conv2D(filters_se, 1,\n",
    "        #                   padding='same',\n",
    "        #                   activation=activation_fn,\n",
    "        #                   kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "        #                   name=name + 'se_reduce')(se)\n",
    "        print(\"kPointwiseConv2D 1v se = \", se)\n",
    "        se = kPointwiseConv2D(last_tensor=se, filters=filters_se, channel_axis=bn_axis, name=name+'se_reduce', activation=activation_fn, has_batch_norm=False, use_bias=True, kType=kType)\n",
    "        #se = layers.Conv2D(filters, 1,\n",
    "        #                   padding='same',\n",
    "        #                   activation='sigmoid',\n",
    "        #                   kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "        #                   name=name + 'se_expand')(se)\n",
    "        print(\"kPointwiseConv3D 2v se = \", se)\n",
    "        se = kPointwiseConv2D(last_tensor=se, filters=filters, channel_axis=bn_axis, name=name+'se_expand', activation='sigmoid', has_batch_norm=False, use_bias=True, kType=kType)\n",
    "        x = layers.multiply([x, se], name=name + 'se_excite')\n",
    "\n",
    "    # Output phase\n",
    "    #x = layers.Conv2D(filters_out, 1,\n",
    "    #                  padding='same',\n",
    "    #                  use_bias=False,\n",
    "    #                  kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "    #                  name=name + 'project_conv')(x)\n",
    "    # x = layers.BatchNormalization(axis=bn_axis, name=name + 'project_bn')(x)\n",
    "    x = cai.layers.kPointwiseConv2D(last_tensor=x, filters=filters_out, channel_axis=bn_axis, name=name+'project_conv', activation=None, has_batch_norm=True, use_bias=False, kType=kType)\n",
    "\n",
    "    if (drop_rate > 0)  and (dropout_all_blocks):\n",
    "        x = layers.Dropout(drop_rate,\n",
    "                noise_shape=(None, 1, 1, 1),\n",
    "                name=name + 'drop')(x)\n",
    "\n",
    "    if (id_skip is True and strides == 1 and filters_in == filters_out):\n",
    "        if (drop_rate > 0)  and (not dropout_all_blocks):\n",
    "            x = layers.Dropout(drop_rate,\n",
    "                               noise_shape=(None, 1, 1, 1),\n",
    "                               name=name + 'drop')(x)\n",
    "        x = layers.add([x, inputs], name=name + 'add')\n",
    "    return x\n",
    "\n",
    "def kblockLastName(drop_rate=0., name='',\n",
    "          filters_in=32, filters_out=16, strides=1,\n",
    "          id_skip=True,\n",
    "          dropout_all_blocks=False):\n",
    "    last_name = name + 'project_conv'\n",
    "\n",
    "    if (drop_rate > 0)  and (dropout_all_blocks):\n",
    "        last_name = name + 'drop'\n",
    "\n",
    "    if (id_skip is True and strides == 1 and filters_in == filters_out):\n",
    "        last_name = name + 'add'\n",
    "    return last_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/joaopauloschuler/k-neural-api/blob/master/cai/efficientnet.py\n",
    "\n",
    "def kEffNet2D(\n",
    "        width_coefficient,\n",
    "        depth_coefficient,\n",
    "        skip_stride_cnt=-1,\n",
    "        dropout_rate=0.2,\n",
    "        drop_connect_rate=0.2,\n",
    "        depth_divisor=8,\n",
    "        activation_fn=swish,\n",
    "        blocks_args=DEFAULT_BLOCKS_ARGS,\n",
    "        model_name='efficientnet',\n",
    "        include_top=True,\n",
    "        input_tensor=None,\n",
    "        input_shape=None,\n",
    "        pooling=None,\n",
    "        classes=1000,\n",
    "        kType=2,\n",
    "        concat_paths=True,\n",
    "        dropout_all_blocks=False,\n",
    "        name_prefix='k_',\n",
    "        **kwargs):\n",
    "    \"\"\"Instantiates the EfficientNet architecture using given scaling coefficients.\n",
    "    Optionally loads weights pre-trained on ImageNet.\n",
    "    Note that the data format convention used by the model is\n",
    "    the one specified in your Keras config at `~/.keras/keras.json`.\n",
    "    # Arguments\n",
    "        width_coefficient: float, scaling coefficient for network width.\n",
    "        depth_coefficient: float, scaling coefficient for network depth.\n",
    "        skip_stride_cnt: number of layers to skip stride. This parameter is used with smalll images such as CIFAR-10.\n",
    "        dropout_rate: float, dropout rate before final classifier layer.\n",
    "        drop_connect_rate: float, dropout rate at skip connections.\n",
    "        depth_divisor: integer, a unit of network width.\n",
    "        activation_fn: activation function.\n",
    "        blocks_args: list of dicts, parameters to construct block modules.\n",
    "        model_name: string, model name.\n",
    "        include_top: whether to include the fully-connected\n",
    "            layer at the top of the network.\n",
    "        input_tensor: optional Keras tensor\n",
    "            (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False.\n",
    "            It should have exactly 3 inputs channels.\n",
    "        pooling: optional pooling mode for feature extraction\n",
    "            when `include_top` is `False`.\n",
    "            - `None` means that the output of the model will be\n",
    "                the 4D tensor output of the\n",
    "                last convolutional layer.\n",
    "            - `avg` means that global average pooling\n",
    "                will be applied to the output of the\n",
    "                last convolutional layer, and thus\n",
    "                the output of the model will be a 2D tensor.\n",
    "            - `max` means that global max pooling will\n",
    "                be applied.\n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    # Raises\n",
    "        ValueError: in case of invalid input shape.\n",
    "    \"\"\"\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = layers.Input(shape=input_shape)\n",
    "    else:\n",
    "        if not backend.is_keras_tensor(input_tensor):\n",
    "            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    bn_axis = 3\n",
    "\n",
    "    def round_filters(filters, divisor=depth_divisor):\n",
    "        \"\"\"Round number of filters based on depth multiplier.\"\"\"\n",
    "        filters *= width_coefficient\n",
    "        new_filters = max(divisor, int(filters + divisor / 2) // divisor * divisor)\n",
    "        # Make sure that round down does not go down by more than 10%.\n",
    "        if new_filters < 0.9 * filters:\n",
    "            new_filters += divisor\n",
    "        return int(new_filters)\n",
    "\n",
    "    def round_repeats(repeats):\n",
    "        \"\"\"Round number of repeats based on depth multiplier.\"\"\"\n",
    "        return int(math.ceil(depth_coefficient * repeats))\n",
    "\n",
    "    if isinstance(kType, (int)):\n",
    "        kTypeList = [kType]\n",
    "    else:\n",
    "        kTypeList = kType\n",
    "    \n",
    "    # Build stem\n",
    "    x = img_input\n",
    "    x = layers.ZeroPadding2D(padding=correct_pad(backend, x, 3),\n",
    "                             name=name_prefix+'stem_conv_pad')(x)\n",
    "    first_stride = 1 if skip_stride_cnt >= 0 else 2\n",
    "    x = layers.Conv2D(round_filters(32), 3,\n",
    "                      strides=first_stride,\n",
    "                      padding='valid',\n",
    "                      use_bias=False,\n",
    "                      kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "                      name=name_prefix+'stem_conv')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, name=name_prefix+'stem_bn')(x)\n",
    "    x = layers.Activation(activation_fn, name=name_prefix+'stem_activation')(x)\n",
    "\n",
    "    root_layer = x\n",
    "    output_layers = []\n",
    "    path_cnt = 0\n",
    "    for kType in kTypeList:\n",
    "        x = root_layer\n",
    "        blocks_args_cp = deepcopy(blocks_args)\n",
    "        b = 0\n",
    "        blocks = float(sum(args['repeats'] for args in blocks_args_cp))\n",
    "        #only the first branch can backpropagate to the input.\n",
    "        #if path_cnt>0:\n",
    "        #    x = keras.layers.Lambda(lambda x: tensorflow.stop_gradient(x))(x)\n",
    "        for (i, args) in enumerate(blocks_args_cp):\n",
    "            assert args['repeats'] > 0\n",
    "            # Update block input and output filters based on depth multiplier.\n",
    "            args['filters_in'] = round_filters(args['filters_in'])\n",
    "            args['filters_out'] = round_filters(args['filters_out'])\n",
    "\n",
    "            for j in range(round_repeats(args.pop('repeats'))):\n",
    "                #should skip the stride\n",
    "                if (skip_stride_cnt > i) and (j == 0) and (args['strides'] > 1):\n",
    "                    args['strides'] = 1\n",
    "                # The first block needs to take care of stride and filter size increase.\n",
    "                if (j > 0):\n",
    "                    args['strides'] = 1\n",
    "                    args['filters_in'] = args['filters_out']\n",
    "                print(\"x = kblock before    \", x)\n",
    "                x = kblock(x, activation_fn, drop_connect_rate * b / blocks,\n",
    "                          name=name_prefix+'block{}{}_'.format(i + 1, chr(j + 97))+'_'+str(path_cnt), **args,\n",
    "                          kType=kType, dropout_all_blocks=dropout_all_blocks)\n",
    "                print(\"x = kblock after \", x)\n",
    "                b += 1\n",
    "        if (len(kTypeList)>1):\n",
    "            x = layers.Activation('relu', name=name_prefix+'end_relu'+'_'+str(path_cnt))(x)\n",
    "        output_layers.append(x)\n",
    "        path_cnt = path_cnt +1\n",
    "        \n",
    "    if (len(output_layers)==1):\n",
    "        x = output_layers[0]\n",
    "    else:\n",
    "        if concat_paths:\n",
    "            x = keras.layers.Concatenate(axis=bn_axis, name=name_prefix+'global_concat')(output_layers)\n",
    "        else:\n",
    "            x = keras.layers.add(output_layers, name=name_prefix+'global_add')\n",
    "\n",
    "    # Build top\n",
    "    #x = layers.Conv2D(round_filters(1280), 1,\n",
    "    #                  padding='same',\n",
    "    #                  use_bias=False,\n",
    "    #                  kernel_initializer=CONV_KERNEL_INITIALIZER,\n",
    "    #                  name='top_conv')(x)\n",
    "    #x = layers.BatchNormalization(axis=bn_axis, name='top_bn')(x)\n",
    "    #x = layers.Activation(activation_fn, name='top_activation')(x)\n",
    "    x = cai.layers.kPointwiseConv2D(last_tensor=x, filters=round_filters(1280), channel_axis=bn_axis, name=name_prefix+'top_conv', activation=None, has_batch_norm=True, use_bias=False, kType=kType)\n",
    "    print(\"x = cai.layers.kPointwiseConv2D  \", x)\n",
    "    if pooling == 'avg':\n",
    "        x = layers.GlobalAveragePooling2D(name=name_prefix+'avg_pool')(x)\n",
    "    elif pooling == 'max':\n",
    "        x = layers.GlobalMaxPooling2D(name=name_prefix+'max_pool')(x)\n",
    "    elif pooling == 'avgmax':\n",
    "        x = cai.layers.GlobalAverageMaxPooling2D(x, name=name_prefix+'avgmax_pool')\n",
    "\n",
    "    if include_top:\n",
    "        if (dropout_rate > 0):\n",
    "            x = layers.Dropout(dropout_rate, name=name_prefix+'top_dropout')(x)\n",
    "        x = layers.Dense(classes,\n",
    "            activation='softmax', # 'softmax'\n",
    "            kernel_initializer=DENSE_KERNEL_INITIALIZER,\n",
    "            name=name_prefix+'probs')(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = utils.get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "\n",
    "    # Create model.\n",
    "    model = models.Model(inputs, x, name=model_name)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kEfficientNetB0(include_top=True,\n",
    "                   input_tensor=None,\n",
    "                   input_shape=None,\n",
    "                   pooling='avg',\n",
    "                   classes=1000,\n",
    "                   kType=2,\n",
    "                   dropout_rate=0.2,\n",
    "                   drop_connect_rate=0.2,\n",
    "                   skip_stride_cnt=-1,\n",
    "                   activation_fn=swish,\n",
    "                   dropout_all_blocks=False,\n",
    "                   **kwargs):\n",
    "    return kEffNet2D(1.0, 1.0, skip_stride_cnt=skip_stride_cnt, # 224,\n",
    "                        model_name='kEffNet-b0',\n",
    "                        include_top=include_top,\n",
    "                        input_tensor=input_tensor, input_shape=input_shape,\n",
    "                        pooling=pooling, classes=classes,\n",
    "                        kType=kType,\n",
    "                        dropout_rate=dropout_rate,\n",
    "                        drop_connect_rate=drop_connect_rate,\n",
    "                        activation_fn=activation_fn,\n",
    "                        dropout_all_blocks=dropout_all_blocks,\n",
    "                        **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32) channels_last\n",
      "is_inst True\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 32), dtype=tf.float32, name=None), name='k_stem_activation/mul:0', description=\"created by layer 'k_stem_activation'\")\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 32), dtype=tf.float32, name=None), name='k_block1a__0se_reshape/Reshape:0', description=\"created by layer 'k_block1a__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 32), dtype=tf.float32, name=None), name='k_block1a__0se_reshape/Reshape:0', description=\"created by layer 'k_block1a__0se_reshape'\")\n",
      "prev_layer_channel_count  32\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 8), dtype=tf.float32, name=None), name='k_block1a__0se_reduce/mul:0', description=\"created by layer 'k_block1a__0se_reduce'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 8), dtype=tf.float32, name=None), name='k_block1a__0se_reduce/mul:0', description=\"created by layer 'k_block1a__0se_reduce'\")\n",
      "prev_layer_channel_count  8\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 32), dtype=tf.float32, name=None), name='k_block1a__0se_excite/mul:0', description=\"created by layer 'k_block1a__0se_excite'\")\n",
      "prev_layer_channel_count  32\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 16), dtype=tf.float32, name=None), name='k_block1a__0project_conv_bn/FusedBatchNormV3:0', description=\"created by layer 'k_block1a__0project_conv_bn'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 16), dtype=tf.float32, name=None), name='k_block1a__0project_conv_bn/FusedBatchNormV3:0', description=\"created by layer 'k_block1a__0project_conv_bn'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 16), dtype=tf.float32, name=None), name='k_block1a__0project_conv_bn/FusedBatchNormV3:0', description=\"created by layer 'k_block1a__0project_conv_bn'\")\n",
      "prev_layer_channel_count  16\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 96), dtype=tf.float32, name=None), name='k_block2a__0se_reshape/Reshape:0', description=\"created by layer 'k_block2a__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 96), dtype=tf.float32, name=None), name='k_block2a__0se_reshape/Reshape:0', description=\"created by layer 'k_block2a__0se_reshape'\")\n",
      "prev_layer_channel_count  96\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 4), dtype=tf.float32, name=None), name='k_block2a__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block2a__0se_reduce_inter_group_add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 4), dtype=tf.float32, name=None), name='k_block2a__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block2a__0se_reduce_inter_group_add'\")\n",
      "prev_layer_channel_count  4\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 96), dtype=tf.float32, name=None), name='k_block2a__0se_excite/mul:0', description=\"created by layer 'k_block2a__0se_excite'\")\n",
      "prev_layer_channel_count  96\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 24), dtype=tf.float32, name=None), name='k_block2a__0project_conv_inter_group_add/add:0', description=\"created by layer 'k_block2a__0project_conv_inter_group_add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 24), dtype=tf.float32, name=None), name='k_block2a__0project_conv_inter_group_add/add:0', description=\"created by layer 'k_block2a__0project_conv_inter_group_add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 24), dtype=tf.float32, name=None), name='k_block2a__0project_conv_inter_group_add/add:0', description=\"created by layer 'k_block2a__0project_conv_inter_group_add'\")\n",
      "prev_layer_channel_count  24\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 144), dtype=tf.float32, name=None), name='k_block2b__0se_reshape/Reshape:0', description=\"created by layer 'k_block2b__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 144), dtype=tf.float32, name=None), name='k_block2b__0se_reshape/Reshape:0', description=\"created by layer 'k_block2b__0se_reshape'\")\n",
      "prev_layer_channel_count  144\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 6), dtype=tf.float32, name=None), name='k_block2b__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block2b__0se_reduce_inter_group_add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 6), dtype=tf.float32, name=None), name='k_block2b__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block2b__0se_reduce_inter_group_add'\")\n",
      "prev_layer_channel_count  6\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 144), dtype=tf.float32, name=None), name='k_block2b__0se_excite/mul:0', description=\"created by layer 'k_block2b__0se_excite'\")\n",
      "prev_layer_channel_count  144\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 24), dtype=tf.float32, name=None), name='k_block2b__0add/add:0', description=\"created by layer 'k_block2b__0add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 24), dtype=tf.float32, name=None), name='k_block2b__0add/add:0', description=\"created by layer 'k_block2b__0add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 24), dtype=tf.float32, name=None), name='k_block2b__0add/add:0', description=\"created by layer 'k_block2b__0add'\")\n",
      "prev_layer_channel_count  24\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 144), dtype=tf.float32, name=None), name='k_block3a__0se_reshape/Reshape:0', description=\"created by layer 'k_block3a__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 144), dtype=tf.float32, name=None), name='k_block3a__0se_reshape/Reshape:0', description=\"created by layer 'k_block3a__0se_reshape'\")\n",
      "prev_layer_channel_count  144\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 6), dtype=tf.float32, name=None), name='k_block3a__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block3a__0se_reduce_inter_group_add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 6), dtype=tf.float32, name=None), name='k_block3a__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block3a__0se_reduce_inter_group_add'\")\n",
      "prev_layer_channel_count  6\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 144), dtype=tf.float32, name=None), name='k_block3a__0se_excite/mul:0', description=\"created by layer 'k_block3a__0se_excite'\")\n",
      "prev_layer_channel_count  144\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 40), dtype=tf.float32, name=None), name='k_block3a__0project_conv_inter_group_add/add:0', description=\"created by layer 'k_block3a__0project_conv_inter_group_add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 40), dtype=tf.float32, name=None), name='k_block3a__0project_conv_inter_group_add/add:0', description=\"created by layer 'k_block3a__0project_conv_inter_group_add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 40), dtype=tf.float32, name=None), name='k_block3a__0project_conv_inter_group_add/add:0', description=\"created by layer 'k_block3a__0project_conv_inter_group_add'\")\n",
      "prev_layer_channel_count  40\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 240), dtype=tf.float32, name=None), name='k_block3b__0se_reshape/Reshape:0', description=\"created by layer 'k_block3b__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 240), dtype=tf.float32, name=None), name='k_block3b__0se_reshape/Reshape:0', description=\"created by layer 'k_block3b__0se_reshape'\")\n",
      "prev_layer_channel_count  240\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 10), dtype=tf.float32, name=None), name='k_block3b__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block3b__0se_reduce_inter_group_add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 10), dtype=tf.float32, name=None), name='k_block3b__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block3b__0se_reduce_inter_group_add'\")\n",
      "prev_layer_channel_count  10\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 240), dtype=tf.float32, name=None), name='k_block3b__0se_excite/mul:0', description=\"created by layer 'k_block3b__0se_excite'\")\n",
      "prev_layer_channel_count  240\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 40), dtype=tf.float32, name=None), name='k_block3b__0add/add:0', description=\"created by layer 'k_block3b__0add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 40), dtype=tf.float32, name=None), name='k_block3b__0add/add:0', description=\"created by layer 'k_block3b__0add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 31, 31, 40), dtype=tf.float32, name=None), name='k_block3b__0add/add:0', description=\"created by layer 'k_block3b__0add'\")\n",
      "prev_layer_channel_count  40\n",
      "(31, 31) channels_last\n",
      "is_inst True\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 240), dtype=tf.float32, name=None), name='k_block4a__0se_reshape/Reshape:0', description=\"created by layer 'k_block4a__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 240), dtype=tf.float32, name=None), name='k_block4a__0se_reshape/Reshape:0', description=\"created by layer 'k_block4a__0se_reshape'\")\n",
      "prev_layer_channel_count  240\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 10), dtype=tf.float32, name=None), name='k_block4a__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block4a__0se_reduce_inter_group_add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 10), dtype=tf.float32, name=None), name='k_block4a__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block4a__0se_reduce_inter_group_add'\")\n",
      "prev_layer_channel_count  10\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 240), dtype=tf.float32, name=None), name='k_block4a__0se_excite/mul:0', description=\"created by layer 'k_block4a__0se_excite'\")\n",
      "prev_layer_channel_count  240\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 80), dtype=tf.float32, name=None), name='k_block4a__0project_conv_inter_group_add/add:0', description=\"created by layer 'k_block4a__0project_conv_inter_group_add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 80), dtype=tf.float32, name=None), name='k_block4a__0project_conv_inter_group_add/add:0', description=\"created by layer 'k_block4a__0project_conv_inter_group_add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 80), dtype=tf.float32, name=None), name='k_block4a__0project_conv_inter_group_add/add:0', description=\"created by layer 'k_block4a__0project_conv_inter_group_add'\")\n",
      "prev_layer_channel_count  80\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 480), dtype=tf.float32, name=None), name='k_block4b__0se_reshape/Reshape:0', description=\"created by layer 'k_block4b__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 480), dtype=tf.float32, name=None), name='k_block4b__0se_reshape/Reshape:0', description=\"created by layer 'k_block4b__0se_reshape'\")\n",
      "prev_layer_channel_count  480\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 20), dtype=tf.float32, name=None), name='k_block4b__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block4b__0se_reduce_inter_group_add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 20), dtype=tf.float32, name=None), name='k_block4b__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block4b__0se_reduce_inter_group_add'\")\n",
      "prev_layer_channel_count  20\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 480), dtype=tf.float32, name=None), name='k_block4b__0se_excite/mul:0', description=\"created by layer 'k_block4b__0se_excite'\")\n",
      "prev_layer_channel_count  480\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 80), dtype=tf.float32, name=None), name='k_block4b__0add/add:0', description=\"created by layer 'k_block4b__0add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 80), dtype=tf.float32, name=None), name='k_block4b__0add/add:0', description=\"created by layer 'k_block4b__0add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 80), dtype=tf.float32, name=None), name='k_block4b__0add/add:0', description=\"created by layer 'k_block4b__0add'\")\n",
      "prev_layer_channel_count  80\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 480), dtype=tf.float32, name=None), name='k_block4c__0se_reshape/Reshape:0', description=\"created by layer 'k_block4c__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 480), dtype=tf.float32, name=None), name='k_block4c__0se_reshape/Reshape:0', description=\"created by layer 'k_block4c__0se_reshape'\")\n",
      "prev_layer_channel_count  480\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 20), dtype=tf.float32, name=None), name='k_block4c__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block4c__0se_reduce_inter_group_add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 20), dtype=tf.float32, name=None), name='k_block4c__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block4c__0se_reduce_inter_group_add'\")\n",
      "prev_layer_channel_count  20\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 480), dtype=tf.float32, name=None), name='k_block4c__0se_excite/mul:0', description=\"created by layer 'k_block4c__0se_excite'\")\n",
      "prev_layer_channel_count  480\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 80), dtype=tf.float32, name=None), name='k_block4c__0add/add:0', description=\"created by layer 'k_block4c__0add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 80), dtype=tf.float32, name=None), name='k_block4c__0add/add:0', description=\"created by layer 'k_block4c__0add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 80), dtype=tf.float32, name=None), name='k_block4c__0add/add:0', description=\"created by layer 'k_block4c__0add'\")\n",
      "prev_layer_channel_count  80\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 480), dtype=tf.float32, name=None), name='k_block5a__0se_reshape/Reshape:0', description=\"created by layer 'k_block5a__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 480), dtype=tf.float32, name=None), name='k_block5a__0se_reshape/Reshape:0', description=\"created by layer 'k_block5a__0se_reshape'\")\n",
      "prev_layer_channel_count  480\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 20), dtype=tf.float32, name=None), name='k_block5a__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block5a__0se_reduce_inter_group_add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 20), dtype=tf.float32, name=None), name='k_block5a__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block5a__0se_reduce_inter_group_add'\")\n",
      "prev_layer_channel_count  20\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 480), dtype=tf.float32, name=None), name='k_block5a__0se_excite/mul:0', description=\"created by layer 'k_block5a__0se_excite'\")\n",
      "prev_layer_channel_count  480\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 112), dtype=tf.float32, name=None), name='k_block5a__0project_conv_inter_group_add/add:0', description=\"created by layer 'k_block5a__0project_conv_inter_group_add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 112), dtype=tf.float32, name=None), name='k_block5a__0project_conv_inter_group_add/add:0', description=\"created by layer 'k_block5a__0project_conv_inter_group_add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 112), dtype=tf.float32, name=None), name='k_block5a__0project_conv_inter_group_add/add:0', description=\"created by layer 'k_block5a__0project_conv_inter_group_add'\")\n",
      "prev_layer_channel_count  112\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 672), dtype=tf.float32, name=None), name='k_block5b__0se_reshape/Reshape:0', description=\"created by layer 'k_block5b__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 672), dtype=tf.float32, name=None), name='k_block5b__0se_reshape/Reshape:0', description=\"created by layer 'k_block5b__0se_reshape'\")\n",
      "prev_layer_channel_count  672\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 28), dtype=tf.float32, name=None), name='k_block5b__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block5b__0se_reduce_inter_group_add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 28), dtype=tf.float32, name=None), name='k_block5b__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block5b__0se_reduce_inter_group_add'\")\n",
      "prev_layer_channel_count  28\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 672), dtype=tf.float32, name=None), name='k_block5b__0se_excite/mul:0', description=\"created by layer 'k_block5b__0se_excite'\")\n",
      "prev_layer_channel_count  672\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 112), dtype=tf.float32, name=None), name='k_block5b__0add/add:0', description=\"created by layer 'k_block5b__0add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 112), dtype=tf.float32, name=None), name='k_block5b__0add/add:0', description=\"created by layer 'k_block5b__0add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 112), dtype=tf.float32, name=None), name='k_block5b__0add/add:0', description=\"created by layer 'k_block5b__0add'\")\n",
      "prev_layer_channel_count  112\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 672), dtype=tf.float32, name=None), name='k_block5c__0se_reshape/Reshape:0', description=\"created by layer 'k_block5c__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 672), dtype=tf.float32, name=None), name='k_block5c__0se_reshape/Reshape:0', description=\"created by layer 'k_block5c__0se_reshape'\")\n",
      "prev_layer_channel_count  672\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 28), dtype=tf.float32, name=None), name='k_block5c__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block5c__0se_reduce_inter_group_add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 28), dtype=tf.float32, name=None), name='k_block5c__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block5c__0se_reduce_inter_group_add'\")\n",
      "prev_layer_channel_count  28\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 672), dtype=tf.float32, name=None), name='k_block5c__0se_excite/mul:0', description=\"created by layer 'k_block5c__0se_excite'\")\n",
      "prev_layer_channel_count  672\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 112), dtype=tf.float32, name=None), name='k_block5c__0add/add:0', description=\"created by layer 'k_block5c__0add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 112), dtype=tf.float32, name=None), name='k_block5c__0add/add:0', description=\"created by layer 'k_block5c__0add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 112), dtype=tf.float32, name=None), name='k_block5c__0add/add:0', description=\"created by layer 'k_block5c__0add'\")\n",
      "prev_layer_channel_count  112\n",
      "(16, 16) channels_last\n",
      "is_inst True\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 672), dtype=tf.float32, name=None), name='k_block6a__0se_reshape/Reshape:0', description=\"created by layer 'k_block6a__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 672), dtype=tf.float32, name=None), name='k_block6a__0se_reshape/Reshape:0', description=\"created by layer 'k_block6a__0se_reshape'\")\n",
      "prev_layer_channel_count  672\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 28), dtype=tf.float32, name=None), name='k_block6a__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block6a__0se_reduce_inter_group_add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 28), dtype=tf.float32, name=None), name='k_block6a__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block6a__0se_reduce_inter_group_add'\")\n",
      "prev_layer_channel_count  28\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 672), dtype=tf.float32, name=None), name='k_block6a__0se_excite/mul:0', description=\"created by layer 'k_block6a__0se_excite'\")\n",
      "prev_layer_channel_count  672\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 192), dtype=tf.float32, name=None), name='k_block6a__0project_conv_inter_group_add/add:0', description=\"created by layer 'k_block6a__0project_conv_inter_group_add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 192), dtype=tf.float32, name=None), name='k_block6a__0project_conv_inter_group_add/add:0', description=\"created by layer 'k_block6a__0project_conv_inter_group_add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 192), dtype=tf.float32, name=None), name='k_block6a__0project_conv_inter_group_add/add:0', description=\"created by layer 'k_block6a__0project_conv_inter_group_add'\")\n",
      "prev_layer_channel_count  192\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 1152), dtype=tf.float32, name=None), name='k_block6b__0se_reshape/Reshape:0', description=\"created by layer 'k_block6b__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 1152), dtype=tf.float32, name=None), name='k_block6b__0se_reshape/Reshape:0', description=\"created by layer 'k_block6b__0se_reshape'\")\n",
      "prev_layer_channel_count  1152\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 48), dtype=tf.float32, name=None), name='k_block6b__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block6b__0se_reduce_inter_group_add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 48), dtype=tf.float32, name=None), name='k_block6b__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block6b__0se_reduce_inter_group_add'\")\n",
      "prev_layer_channel_count  48\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 1152), dtype=tf.float32, name=None), name='k_block6b__0se_excite/mul:0', description=\"created by layer 'k_block6b__0se_excite'\")\n",
      "prev_layer_channel_count  1152\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 192), dtype=tf.float32, name=None), name='k_block6b__0add/add:0', description=\"created by layer 'k_block6b__0add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 192), dtype=tf.float32, name=None), name='k_block6b__0add/add:0', description=\"created by layer 'k_block6b__0add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 192), dtype=tf.float32, name=None), name='k_block6b__0add/add:0', description=\"created by layer 'k_block6b__0add'\")\n",
      "prev_layer_channel_count  192\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 1152), dtype=tf.float32, name=None), name='k_block6c__0se_reshape/Reshape:0', description=\"created by layer 'k_block6c__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 1152), dtype=tf.float32, name=None), name='k_block6c__0se_reshape/Reshape:0', description=\"created by layer 'k_block6c__0se_reshape'\")\n",
      "prev_layer_channel_count  1152\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 48), dtype=tf.float32, name=None), name='k_block6c__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block6c__0se_reduce_inter_group_add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 48), dtype=tf.float32, name=None), name='k_block6c__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block6c__0se_reduce_inter_group_add'\")\n",
      "prev_layer_channel_count  48\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 1152), dtype=tf.float32, name=None), name='k_block6c__0se_excite/mul:0', description=\"created by layer 'k_block6c__0se_excite'\")\n",
      "prev_layer_channel_count  1152\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 192), dtype=tf.float32, name=None), name='k_block6c__0add/add:0', description=\"created by layer 'k_block6c__0add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 192), dtype=tf.float32, name=None), name='k_block6c__0add/add:0', description=\"created by layer 'k_block6c__0add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 192), dtype=tf.float32, name=None), name='k_block6c__0add/add:0', description=\"created by layer 'k_block6c__0add'\")\n",
      "prev_layer_channel_count  192\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 1152), dtype=tf.float32, name=None), name='k_block6d__0se_reshape/Reshape:0', description=\"created by layer 'k_block6d__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 1152), dtype=tf.float32, name=None), name='k_block6d__0se_reshape/Reshape:0', description=\"created by layer 'k_block6d__0se_reshape'\")\n",
      "prev_layer_channel_count  1152\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 48), dtype=tf.float32, name=None), name='k_block6d__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block6d__0se_reduce_inter_group_add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 48), dtype=tf.float32, name=None), name='k_block6d__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block6d__0se_reduce_inter_group_add'\")\n",
      "prev_layer_channel_count  48\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 1152), dtype=tf.float32, name=None), name='k_block6d__0se_excite/mul:0', description=\"created by layer 'k_block6d__0se_excite'\")\n",
      "prev_layer_channel_count  1152\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 192), dtype=tf.float32, name=None), name='k_block6d__0add/add:0', description=\"created by layer 'k_block6d__0add'\")\n",
      "x = kblock before     KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 192), dtype=tf.float32, name=None), name='k_block6d__0add/add:0', description=\"created by layer 'k_block6d__0add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 192), dtype=tf.float32, name=None), name='k_block6d__0add/add:0', description=\"created by layer 'k_block6d__0add'\")\n",
      "prev_layer_channel_count  192\n",
      "kPointwiseConv2D 1v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 1152), dtype=tf.float32, name=None), name='k_block7a__0se_reshape/Reshape:0', description=\"created by layer 'k_block7a__0se_reshape'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 1152), dtype=tf.float32, name=None), name='k_block7a__0se_reshape/Reshape:0', description=\"created by layer 'k_block7a__0se_reshape'\")\n",
      "prev_layer_channel_count  1152\n",
      "kPointwiseConv3D 2v se =  KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 48), dtype=tf.float32, name=None), name='k_block7a__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block7a__0se_reduce_inter_group_add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 1, 1, 48), dtype=tf.float32, name=None), name='k_block7a__0se_reduce_inter_group_add/add:0', description=\"created by layer 'k_block7a__0se_reduce_inter_group_add'\")\n",
      "prev_layer_channel_count  48\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 1152), dtype=tf.float32, name=None), name='k_block7a__0se_excite/mul:0', description=\"created by layer 'k_block7a__0se_excite'\")\n",
      "prev_layer_channel_count  1152\n",
      "x = kblock after  KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 320), dtype=tf.float32, name=None), name='k_block7a__0project_conv_inter_group_add/add:0', description=\"created by layer 'k_block7a__0project_conv_inter_group_add'\")\n",
      "last_tensor   KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 320), dtype=tf.float32, name=None), name='k_block7a__0project_conv_inter_group_add/add:0', description=\"created by layer 'k_block7a__0project_conv_inter_group_add'\")\n",
      "prev_layer_channel_count  320\n",
      "x = cai.layers.kPointwiseConv2D   KerasTensor(type_spec=TensorSpec(shape=(None, 8, 8, 1280), dtype=tf.float32, name=None), name='k_top_conv_group_interleaved/concatenate/concat:0', description=\"created by layer 'k_top_conv_group_interleaved'\")\n"
     ]
    }
   ],
   "source": [
    "k = kEffNet2D(width_coefficient = 1.0, depth_coefficient = 1.0, input_shape=(32, 32, 1), skip_stride_cnt=3, kType = cai.layers.D6_32ch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"efficientnet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 32, 32, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " k_stem_conv_pad (ZeroPadding2D  (None, 33, 33, 1)   0           ['input_3[0][0]']                \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " k_stem_conv (Conv2D)           (None, 31, 31, 32)   288         ['k_stem_conv_pad[0][0]']        \n",
      "                                                                                                  \n",
      " k_stem_bn (BatchNormalization)  (None, 31, 31, 32)  128         ['k_stem_conv[0][0]']            \n",
      "                                                                                                  \n",
      " k_stem_activation (Activation)  (None, 31, 31, 32)  0           ['k_stem_bn[0][0]']              \n",
      "                                                                                                  \n",
      " k_block1a__0dwconv (DepthwiseC  (None, 31, 31, 32)  288         ['k_stem_activation[0][0]']      \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " k_block1a__0bn (BatchNormaliza  (None, 31, 31, 32)  128         ['k_block1a__0dwconv[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " k_block1a__0activation (Activa  (None, 31, 31, 32)  0           ['k_block1a__0bn[0][0]']         \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " k_block1a__0se_squeeze (Global  (None, 32)          0           ['k_block1a__0activation[0][0]'] \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " k_block1a__0se_reshape (Reshap  (None, 1, 1, 32)    0           ['k_block1a__0se_squeeze[0][0]'] \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " k_block1a__0se_reduce_conv (Co  (None, 1, 1, 8)     264         ['k_block1a__0se_reshape[0][0]'] \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " k_block1a__0se_reduce (Activat  (None, 1, 1, 8)     0           ['k_block1a__0se_reduce_conv[0][0\n",
      " ion)                                                            ]']                              \n",
      "                                                                                                  \n",
      " k_block1a__0se_expand_conv (Co  (None, 1, 1, 32)    288         ['k_block1a__0se_reduce[0][0]']  \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " k_block1a__0se_expand (Activat  (None, 1, 1, 32)    0           ['k_block1a__0se_expand_conv[0][0\n",
      " ion)                                                            ]']                              \n",
      "                                                                                                  \n",
      " k_block1a__0se_excite (Multipl  (None, 31, 31, 32)  0           ['k_block1a__0activation[0][0]', \n",
      " y)                                                               'k_block1a__0se_expand[0][0]']  \n",
      "                                                                                                  \n",
      " k_block1a__0project_conv_conv   (None, 31, 31, 16)  512         ['k_block1a__0se_excite[0][0]']  \n",
      " (Conv2D)                                                                                         \n",
      "                                                                                                  \n",
      " k_block1a__0project_conv_bn (B  (None, 31, 31, 16)  64          ['k_block1a__0project_conv_conv[0\n",
      " atchNormalization)                                              ][0]']                           \n",
      "                                                                                                  \n",
      " k_block2a__0expand_conv (Conv2  (None, 31, 31, 96)  1536        ['k_block1a__0project_conv_bn[0][\n",
      " D)                                                              0]']                             \n",
      "                                                                                                  \n",
      " k_block2a__0expand_bn (BatchNo  (None, 31, 31, 96)  384         ['k_block2a__0expand_conv[0][0]']\n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " k_block2a__0expand (Activation  (None, 31, 31, 96)  0           ['k_block2a__0expand_bn[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " k_block2a__0dwconv (DepthwiseC  (None, 31, 31, 96)  864         ['k_block2a__0expand[0][0]']     \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " k_block2a__0bn (BatchNormaliza  (None, 31, 31, 96)  384         ['k_block2a__0dwconv[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " k_block2a__0activation (Activa  (None, 31, 31, 96)  0           ['k_block2a__0bn[0][0]']         \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " k_block2a__0se_squeeze (Global  (None, 96)          0           ['k_block2a__0activation[0][0]'] \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " k_block2a__0se_reshape (Reshap  (None, 1, 1, 96)    0           ['k_block2a__0se_squeeze[0][0]'] \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " k_block2a__0se_reduce_conv (Co  (None, 1, 1, 4)     196         ['k_block2a__0se_reshape[0][0]'] \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " k_block2a__0se_reduce (Activat  (None, 1, 1, 4)     0           ['k_block2a__0se_reduce_conv[0][0\n",
      " ion)                                                            ]']                              \n",
      "                                                                                                  \n",
      " k_block2a__0se_reduce_group_in  (None, 1, 1, 4)     0           ['k_block2a__0se_reduce[0][0]']  \n",
      " terleaved (InterleaveChannels)                                                                   \n",
      "                                                                                                  \n",
      " k_block2a__0se_reduce_group_in  (None, 1, 1, 4)     12          ['k_block2a__0se_reduce_group_int\n",
      " terconn_conv (Conv2D)                                           erleaved[0][0]']                 \n",
      "                                                                                                  \n",
      " k_block2a__0se_reduce_group_in  (None, 1, 1, 4)     0           ['k_block2a__0se_reduce_group_int\n",
      " terconn (Activation)                                            erconn_conv[0][0]']              \n",
      "                                                                                                  \n",
      " k_block2a__0se_reduce_inter_gr  (None, 1, 1, 4)     0           ['k_block2a__0se_reduce_group_int\n",
      " oup_add (Add)                                                   erconn[0][0]',                   \n",
      "                                                                  'k_block2a__0se_reduce[0][0]']  \n",
      "                                                                                                  \n",
      " k_block2a__0se_expand_conv (Co  (None, 1, 1, 96)    480         ['k_block2a__0se_reduce_inter_gro\n",
      " nv2D)                                                           up_add[0][0]']                   \n",
      "                                                                                                  \n",
      " k_block2a__0se_expand (Activat  (None, 1, 1, 96)    0           ['k_block2a__0se_expand_conv[0][0\n",
      " ion)                                                            ]']                              \n",
      "                                                                                                  \n",
      " k_block2a__0se_excite (Multipl  (None, 31, 31, 96)  0           ['k_block2a__0activation[0][0]', \n",
      " y)                                                               'k_block2a__0se_expand[0][0]']  \n",
      "                                                                                                  \n",
      " k_block2a__0project_conv_conv   (None, 31, 31, 24)  768         ['k_block2a__0se_excite[0][0]']  \n",
      " (Conv2D)                                                                                         \n",
      "                                                                                                  \n",
      " k_block2a__0project_conv_bn (B  (None, 31, 31, 24)  96          ['k_block2a__0project_conv_conv[0\n",
      " atchNormalization)                                              ][0]']                           \n",
      "                                                                                                  \n",
      " k_block2a__0project_conv_group  (None, 31, 31, 24)  0           ['k_block2a__0project_conv_bn[0][\n",
      " _interleaved (InterleaveChanne                                  0]']                             \n",
      " ls)                                                                                              \n",
      "                                                                                                  \n",
      " k_block2a__0project_conv_group  (None, 31, 31, 24)  192         ['k_block2a__0project_conv_group_\n",
      " _interconn_conv (Conv2D)                                        interleaved[0][0]']              \n",
      "                                                                                                  \n",
      " k_block2a__0project_conv_group  (None, 31, 31, 24)  96          ['k_block2a__0project_conv_group_\n",
      " _interconn_bn (BatchNormalizat                                  interconn_conv[0][0]']           \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " k_block2a__0project_conv_inter  (None, 31, 31, 24)  0           ['k_block2a__0project_conv_group_\n",
      " _group_add (Add)                                                interconn_bn[0][0]',             \n",
      "                                                                  'k_block2a__0project_conv_bn[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " k_block2b__0expand_conv (Conv2  (None, 31, 31, 144)  3456       ['k_block2a__0project_conv_inter_\n",
      " D)                                                              group_add[0][0]']                \n",
      "                                                                                                  \n",
      " k_block2b__0expand_bn (BatchNo  (None, 31, 31, 144)  576        ['k_block2b__0expand_conv[0][0]']\n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " k_block2b__0expand (Activation  (None, 31, 31, 144)  0          ['k_block2b__0expand_bn[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " k_block2b__0dwconv (DepthwiseC  (None, 31, 31, 144)  1296       ['k_block2b__0expand[0][0]']     \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " k_block2b__0bn (BatchNormaliza  (None, 31, 31, 144)  576        ['k_block2b__0dwconv[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " k_block2b__0activation (Activa  (None, 31, 31, 144)  0          ['k_block2b__0bn[0][0]']         \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " k_block2b__0se_squeeze (Global  (None, 144)         0           ['k_block2b__0activation[0][0]'] \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " k_block2b__0se_reshape (Reshap  (None, 1, 1, 144)   0           ['k_block2b__0se_squeeze[0][0]'] \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " k_block2b__0se_reduce_conv (Co  (None, 1, 1, 6)     294         ['k_block2b__0se_reshape[0][0]'] \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " k_block2b__0se_reduce (Activat  (None, 1, 1, 6)     0           ['k_block2b__0se_reduce_conv[0][0\n",
      " ion)                                                            ]']                              \n",
      "                                                                                                  \n",
      " k_block2b__0se_reduce_group_in  (None, 1, 1, 6)     0           ['k_block2b__0se_reduce[0][0]']  \n",
      " terleaved (InterleaveChannels)                                                                   \n",
      "                                                                                                  \n",
      " k_block2b__0se_reduce_group_in  (None, 1, 1, 6)     18          ['k_block2b__0se_reduce_group_int\n",
      " terconn_conv (Conv2D)                                           erleaved[0][0]']                 \n",
      "                                                                                                  \n",
      " k_block2b__0se_reduce_group_in  (None, 1, 1, 6)     0           ['k_block2b__0se_reduce_group_int\n",
      " terconn (Activation)                                            erconn_conv[0][0]']              \n",
      "                                                                                                  \n",
      " k_block2b__0se_reduce_inter_gr  (None, 1, 1, 6)     0           ['k_block2b__0se_reduce_group_int\n",
      " oup_add (Add)                                                   erconn[0][0]',                   \n",
      "                                                                  'k_block2b__0se_reduce[0][0]']  \n",
      "                                                                                                  \n",
      " k_block2b__0se_expand_conv (Co  (None, 1, 1, 144)   1008        ['k_block2b__0se_reduce_inter_gro\n",
      " nv2D)                                                           up_add[0][0]']                   \n",
      "                                                                                                  \n",
      " k_block2b__0se_expand (Activat  (None, 1, 1, 144)   0           ['k_block2b__0se_expand_conv[0][0\n",
      " ion)                                                            ]']                              \n",
      "                                                                                                  \n",
      " k_block2b__0se_excite (Multipl  (None, 31, 31, 144)  0          ['k_block2b__0activation[0][0]', \n",
      " y)                                                               'k_block2b__0se_expand[0][0]']  \n",
      "                                                                                                  \n",
      " k_block2b__0project_conv_conv   (None, 31, 31, 24)  864         ['k_block2b__0se_excite[0][0]']  \n",
      " (Conv2D)                                                                                         \n",
      "                                                                                                  \n",
      " k_block2b__0project_conv_bn (B  (None, 31, 31, 24)  96          ['k_block2b__0project_conv_conv[0\n",
      " atchNormalization)                                              ][0]']                           \n",
      "                                                                                                  \n",
      " k_block2b__0project_conv_group  (None, 31, 31, 24)  0           ['k_block2b__0project_conv_bn[0][\n",
      " _interleaved (InterleaveChanne                                  0]']                             \n",
      " ls)                                                                                              \n",
      "                                                                                                  \n",
      " k_block2b__0project_conv_group  (None, 31, 31, 24)  144         ['k_block2b__0project_conv_group_\n",
      " _interconn_conv (Conv2D)                                        interleaved[0][0]']              \n",
      "                                                                                                  \n",
      " k_block2b__0project_conv_group  (None, 31, 31, 24)  96          ['k_block2b__0project_conv_group_\n",
      " _interconn_bn (BatchNormalizat                                  interconn_conv[0][0]']           \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " k_block2b__0project_conv_inter  (None, 31, 31, 24)  0           ['k_block2b__0project_conv_group_\n",
      " _group_add (Add)                                                interconn_bn[0][0]',             \n",
      "                                                                  'k_block2b__0project_conv_bn[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " k_block2b__0drop (Dropout)     (None, 31, 31, 24)   0           ['k_block2b__0project_conv_inter_\n",
      "                                                                 group_add[0][0]']                \n",
      "                                                                                                  \n",
      " k_block2b__0add (Add)          (None, 31, 31, 24)   0           ['k_block2b__0drop[0][0]',       \n",
      "                                                                  'k_block2a__0project_conv_inter_\n",
      "                                                                 group_add[0][0]']                \n",
      "                                                                                                  \n",
      " k_block3a__0expand_conv (Conv2  (None, 31, 31, 144)  3456       ['k_block2b__0add[0][0]']        \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " k_block3a__0expand_bn (BatchNo  (None, 31, 31, 144)  576        ['k_block3a__0expand_conv[0][0]']\n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " k_block3a__0expand (Activation  (None, 31, 31, 144)  0          ['k_block3a__0expand_bn[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " k_block3a__0dwconv (DepthwiseC  (None, 31, 31, 144)  3600       ['k_block3a__0expand[0][0]']     \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " k_block3a__0bn (BatchNormaliza  (None, 31, 31, 144)  576        ['k_block3a__0dwconv[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " k_block3a__0activation (Activa  (None, 31, 31, 144)  0          ['k_block3a__0bn[0][0]']         \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " k_block3a__0se_squeeze (Global  (None, 144)         0           ['k_block3a__0activation[0][0]'] \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " k_block3a__0se_reshape (Reshap  (None, 1, 1, 144)   0           ['k_block3a__0se_squeeze[0][0]'] \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " k_block3a__0se_reduce_conv (Co  (None, 1, 1, 6)     294         ['k_block3a__0se_reshape[0][0]'] \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " k_block3a__0se_reduce (Activat  (None, 1, 1, 6)     0           ['k_block3a__0se_reduce_conv[0][0\n",
      " ion)                                                            ]']                              \n",
      "                                                                                                  \n",
      " k_block3a__0se_reduce_group_in  (None, 1, 1, 6)     0           ['k_block3a__0se_reduce[0][0]']  \n",
      " terleaved (InterleaveChannels)                                                                   \n",
      "                                                                                                  \n",
      " k_block3a__0se_reduce_group_in  (None, 1, 1, 6)     18          ['k_block3a__0se_reduce_group_int\n",
      " terconn_conv (Conv2D)                                           erleaved[0][0]']                 \n",
      "                                                                                                  \n",
      " k_block3a__0se_reduce_group_in  (None, 1, 1, 6)     0           ['k_block3a__0se_reduce_group_int\n",
      " terconn (Activation)                                            erconn_conv[0][0]']              \n",
      "                                                                                                  \n",
      " k_block3a__0se_reduce_inter_gr  (None, 1, 1, 6)     0           ['k_block3a__0se_reduce_group_int\n",
      " oup_add (Add)                                                   erconn[0][0]',                   \n",
      "                                                                  'k_block3a__0se_reduce[0][0]']  \n",
      "                                                                                                  \n",
      " k_block3a__0se_expand_conv (Co  (None, 1, 1, 144)   1008        ['k_block3a__0se_reduce_inter_gro\n",
      " nv2D)                                                           up_add[0][0]']                   \n",
      "                                                                                                  \n",
      " k_block3a__0se_expand (Activat  (None, 1, 1, 144)   0           ['k_block3a__0se_expand_conv[0][0\n",
      " ion)                                                            ]']                              \n",
      "                                                                                                  \n",
      " k_block3a__0se_excite (Multipl  (None, 31, 31, 144)  0          ['k_block3a__0activation[0][0]', \n",
      " y)                                                               'k_block3a__0se_expand[0][0]']  \n",
      "                                                                                                  \n",
      " k_block3a__0project_conv_conv   (None, 31, 31, 40)  1440        ['k_block3a__0se_excite[0][0]']  \n",
      " (Conv2D)                                                                                         \n",
      "                                                                                                  \n",
      " k_block3a__0project_conv_bn (B  (None, 31, 31, 40)  160         ['k_block3a__0project_conv_conv[0\n",
      " atchNormalization)                                              ][0]']                           \n",
      "                                                                                                  \n",
      " k_block3a__0project_conv_group  (None, 31, 31, 40)  0           ['k_block3a__0project_conv_bn[0][\n",
      " _interleaved (InterleaveChanne                                  0]']                             \n",
      " ls)                                                                                              \n",
      "                                                                                                  \n",
      " k_block3a__0project_conv_group  (None, 31, 31, 40)  400         ['k_block3a__0project_conv_group_\n",
      " _interconn_conv (Conv2D)                                        interleaved[0][0]']              \n",
      "                                                                                                  \n",
      " k_block3a__0project_conv_group  (None, 31, 31, 40)  160         ['k_block3a__0project_conv_group_\n",
      " _interconn_bn (BatchNormalizat                                  interconn_conv[0][0]']           \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " k_block3a__0project_conv_inter  (None, 31, 31, 40)  0           ['k_block3a__0project_conv_group_\n",
      " _group_add (Add)                                                interconn_bn[0][0]',             \n",
      "                                                                  'k_block3a__0project_conv_bn[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " k_block3b__0expand_conv (Conv2  (None, 31, 31, 240)  9600       ['k_block3a__0project_conv_inter_\n",
      " D)                                                              group_add[0][0]']                \n",
      "                                                                                                  \n",
      " k_block3b__0expand_bn (BatchNo  (None, 31, 31, 240)  960        ['k_block3b__0expand_conv[0][0]']\n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " k_block3b__0expand (Activation  (None, 31, 31, 240)  0          ['k_block3b__0expand_bn[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " k_block3b__0dwconv (DepthwiseC  (None, 31, 31, 240)  6000       ['k_block3b__0expand[0][0]']     \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " k_block3b__0bn (BatchNormaliza  (None, 31, 31, 240)  960        ['k_block3b__0dwconv[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " k_block3b__0activation (Activa  (None, 31, 31, 240)  0          ['k_block3b__0bn[0][0]']         \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " k_block3b__0se_squeeze (Global  (None, 240)         0           ['k_block3b__0activation[0][0]'] \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " k_block3b__0se_reshape (Reshap  (None, 1, 1, 240)   0           ['k_block3b__0se_squeeze[0][0]'] \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " k_block3b__0se_reduce_conv (Co  (None, 1, 1, 10)    490         ['k_block3b__0se_reshape[0][0]'] \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " k_block3b__0se_reduce (Activat  (None, 1, 1, 10)    0           ['k_block3b__0se_reduce_conv[0][0\n",
      " ion)                                                            ]']                              \n",
      "                                                                                                  \n",
      " k_block3b__0se_reduce_group_in  (None, 1, 1, 10)    0           ['k_block3b__0se_reduce[0][0]']  \n",
      " terleaved (InterleaveChannels)                                                                   \n",
      "                                                                                                  \n",
      " k_block3b__0se_reduce_group_in  (None, 1, 1, 10)    30          ['k_block3b__0se_reduce_group_int\n",
      " terconn_conv (Conv2D)                                           erleaved[0][0]']                 \n",
      "                                                                                                  \n",
      " k_block3b__0se_reduce_group_in  (None, 1, 1, 10)    0           ['k_block3b__0se_reduce_group_int\n",
      " terconn (Activation)                                            erconn_conv[0][0]']              \n",
      "                                                                                                  \n",
      " k_block3b__0se_reduce_inter_gr  (None, 1, 1, 10)    0           ['k_block3b__0se_reduce_group_int\n",
      " oup_add (Add)                                                   erconn[0][0]',                   \n",
      "                                                                  'k_block3b__0se_reduce[0][0]']  \n",
      "                                                                                                  \n",
      " k_block3b__0se_expand_conv (Co  (None, 1, 1, 240)   2640        ['k_block3b__0se_reduce_inter_gro\n",
      " nv2D)                                                           up_add[0][0]']                   \n",
      "                                                                                                  \n",
      " k_block3b__0se_expand (Activat  (None, 1, 1, 240)   0           ['k_block3b__0se_expand_conv[0][0\n",
      " ion)                                                            ]']                              \n",
      "                                                                                                  \n",
      " k_block3b__0se_excite (Multipl  (None, 31, 31, 240)  0          ['k_block3b__0activation[0][0]', \n",
      " y)                                                               'k_block3b__0se_expand[0][0]']  \n",
      "                                                                                                  \n",
      " k_block3b__0project_conv_conv   (None, 31, 31, 40)  1920        ['k_block3b__0se_excite[0][0]']  \n",
      " (Conv2D)                                                                                         \n",
      "                                                                                                  \n",
      " k_block3b__0project_conv_bn (B  (None, 31, 31, 40)  160         ['k_block3b__0project_conv_conv[0\n",
      " atchNormalization)                                              ][0]']                           \n",
      "                                                                                                  \n",
      " k_block3b__0project_conv_group  (None, 31, 31, 40)  0           ['k_block3b__0project_conv_bn[0][\n",
      " _interleaved (InterleaveChanne                                  0]']                             \n",
      " ls)                                                                                              \n",
      "                                                                                                  \n",
      " k_block3b__0project_conv_group  (None, 31, 31, 40)  320         ['k_block3b__0project_conv_group_\n",
      " _interconn_conv (Conv2D)                                        interleaved[0][0]']              \n",
      "                                                                                                  \n",
      " k_block3b__0project_conv_group  (None, 31, 31, 40)  160         ['k_block3b__0project_conv_group_\n",
      " _interconn_bn (BatchNormalizat                                  interconn_conv[0][0]']           \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " k_block3b__0project_conv_inter  (None, 31, 31, 40)  0           ['k_block3b__0project_conv_group_\n",
      " _group_add (Add)                                                interconn_bn[0][0]',             \n",
      "                                                                  'k_block3b__0project_conv_bn[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " k_block3b__0drop (Dropout)     (None, 31, 31, 40)   0           ['k_block3b__0project_conv_inter_\n",
      "                                                                 group_add[0][0]']                \n",
      "                                                                                                  \n",
      " k_block3b__0add (Add)          (None, 31, 31, 40)   0           ['k_block3b__0drop[0][0]',       \n",
      "                                                                  'k_block3a__0project_conv_inter_\n",
      "                                                                 group_add[0][0]']                \n",
      "                                                                                                  \n",
      " k_block4a__0expand_conv (Conv2  (None, 31, 31, 240)  9600       ['k_block3b__0add[0][0]']        \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " k_block4a__0expand_bn (BatchNo  (None, 31, 31, 240)  960        ['k_block4a__0expand_conv[0][0]']\n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " k_block4a__0expand (Activation  (None, 31, 31, 240)  0          ['k_block4a__0expand_bn[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " k_block4a__0dwconv_pad (ZeroPa  (None, 33, 33, 240)  0          ['k_block4a__0expand[0][0]']     \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " k_block4a__0dwconv (DepthwiseC  (None, 16, 16, 240)  2160       ['k_block4a__0dwconv_pad[0][0]'] \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " k_block4a__0bn (BatchNormaliza  (None, 16, 16, 240)  960        ['k_block4a__0dwconv[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " k_block4a__0activation (Activa  (None, 16, 16, 240)  0          ['k_block4a__0bn[0][0]']         \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " k_block4a__0se_squeeze (Global  (None, 240)         0           ['k_block4a__0activation[0][0]'] \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " k_block4a__0se_reshape (Reshap  (None, 1, 1, 240)   0           ['k_block4a__0se_squeeze[0][0]'] \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " k_block4a__0se_reduce_conv (Co  (None, 1, 1, 10)    490         ['k_block4a__0se_reshape[0][0]'] \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " k_block4a__0se_reduce (Activat  (None, 1, 1, 10)    0           ['k_block4a__0se_reduce_conv[0][0\n",
      " ion)                                                            ]']                              \n",
      "                                                                                                  \n",
      " k_block4a__0se_reduce_group_in  (None, 1, 1, 10)    0           ['k_block4a__0se_reduce[0][0]']  \n",
      " terleaved (InterleaveChannels)                                                                   \n",
      "                                                                                                  \n",
      " k_block4a__0se_reduce_group_in  (None, 1, 1, 10)    30          ['k_block4a__0se_reduce_group_int\n",
      " terconn_conv (Conv2D)                                           erleaved[0][0]']                 \n",
      "                                                                                                  \n",
      " k_block4a__0se_reduce_group_in  (None, 1, 1, 10)    0           ['k_block4a__0se_reduce_group_int\n",
      " terconn (Activation)                                            erconn_conv[0][0]']              \n",
      "                                                                                                  \n",
      " k_block4a__0se_reduce_inter_gr  (None, 1, 1, 10)    0           ['k_block4a__0se_reduce_group_int\n",
      " oup_add (Add)                                                   erconn[0][0]',                   \n",
      "                                                                  'k_block4a__0se_reduce[0][0]']  \n",
      "                                                                                                  \n",
      " k_block4a__0se_expand_conv (Co  (None, 1, 1, 240)   2640        ['k_block4a__0se_reduce_inter_gro\n",
      " nv2D)                                                           up_add[0][0]']                   \n",
      "                                                                                                  \n",
      " k_block4a__0se_expand (Activat  (None, 1, 1, 240)   0           ['k_block4a__0se_expand_conv[0][0\n",
      " ion)                                                            ]']                              \n",
      "                                                                                                  \n",
      " k_block4a__0se_excite (Multipl  (None, 16, 16, 240)  0          ['k_block4a__0activation[0][0]', \n",
      " y)                                                               'k_block4a__0se_expand[0][0]']  \n",
      "                                                                                                  \n",
      " k_block4a__0project_conv_conv   (None, 16, 16, 80)  3840        ['k_block4a__0se_excite[0][0]']  \n",
      " (Conv2D)                                                                                         \n",
      "                                                                                                  \n",
      " k_block4a__0project_conv_bn (B  (None, 16, 16, 80)  320         ['k_block4a__0project_conv_conv[0\n",
      " atchNormalization)                                              ][0]']                           \n",
      "                                                                                                  \n",
      " k_block4a__0project_conv_group  (None, 16, 16, 80)  0           ['k_block4a__0project_conv_bn[0][\n",
      " _interleaved (InterleaveChanne                                  0]']                             \n",
      " ls)                                                                                              \n",
      "                                                                                                  \n",
      " k_block4a__0project_conv_group  (None, 16, 16, 80)  1280        ['k_block4a__0project_conv_group_\n",
      " _interconn_conv (Conv2D)                                        interleaved[0][0]']              \n",
      "                                                                                                  \n",
      " k_block4a__0project_conv_group  (None, 16, 16, 80)  320         ['k_block4a__0project_conv_group_\n",
      " _interconn_bn (BatchNormalizat                                  interconn_conv[0][0]']           \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " k_block4a__0project_conv_inter  (None, 16, 16, 80)  0           ['k_block4a__0project_conv_group_\n",
      " _group_add (Add)                                                interconn_bn[0][0]',             \n",
      "                                                                  'k_block4a__0project_conv_bn[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " k_block4b__0expand_conv (Conv2  (None, 16, 16, 480)  19200      ['k_block4a__0project_conv_inter_\n",
      " D)                                                              group_add[0][0]']                \n",
      "                                                                                                  \n",
      " k_block4b__0expand_bn (BatchNo  (None, 16, 16, 480)  1920       ['k_block4b__0expand_conv[0][0]']\n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " k_block4b__0expand (Activation  (None, 16, 16, 480)  0          ['k_block4b__0expand_bn[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " k_block4b__0expand_group_inter  (None, 16, 16, 480)  0          ['k_block4b__0expand[0][0]']     \n",
      " leaved (InterleaveChannels)                                                                      \n",
      "                                                                                                  \n",
      " k_block4b__0dwconv (DepthwiseC  (None, 16, 16, 480)  4320       ['k_block4b__0expand_group_interl\n",
      " onv2D)                                                          eaved[0][0]']                    \n",
      "                                                                                                  \n",
      " k_block4b__0bn (BatchNormaliza  (None, 16, 16, 480)  1920       ['k_block4b__0dwconv[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " k_block4b__0activation (Activa  (None, 16, 16, 480)  0          ['k_block4b__0bn[0][0]']         \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " k_block4b__0se_squeeze (Global  (None, 480)         0           ['k_block4b__0activation[0][0]'] \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " k_block4b__0se_reshape (Reshap  (None, 1, 1, 480)   0           ['k_block4b__0se_squeeze[0][0]'] \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " k_block4b__0se_reduce_conv (Co  (None, 1, 1, 20)    980         ['k_block4b__0se_reshape[0][0]'] \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " k_block4b__0se_reduce (Activat  (None, 1, 1, 20)    0           ['k_block4b__0se_reduce_conv[0][0\n",
      " ion)                                                            ]']                              \n",
      "                                                                                                  \n",
      " k_block4b__0se_reduce_group_in  (None, 1, 1, 20)    0           ['k_block4b__0se_reduce[0][0]']  \n",
      " terleaved (InterleaveChannels)                                                                   \n",
      "                                                                                                  \n",
      " k_block4b__0se_reduce_group_in  (None, 1, 1, 20)    60          ['k_block4b__0se_reduce_group_int\n",
      " terconn_conv (Conv2D)                                           erleaved[0][0]']                 \n",
      "                                                                                                  \n",
      " k_block4b__0se_reduce_group_in  (None, 1, 1, 20)    0           ['k_block4b__0se_reduce_group_int\n",
      " terconn (Activation)                                            erconn_conv[0][0]']              \n",
      "                                                                                                  \n",
      " k_block4b__0se_reduce_inter_gr  (None, 1, 1, 20)    0           ['k_block4b__0se_reduce_group_int\n",
      " oup_add (Add)                                                   erconn[0][0]',                   \n",
      "                                                                  'k_block4b__0se_reduce[0][0]']  \n",
      "                                                                                                  \n",
      " k_block4b__0se_expand_conv (Co  (None, 1, 1, 480)   10080       ['k_block4b__0se_reduce_inter_gro\n",
      " nv2D)                                                           up_add[0][0]']                   \n",
      "                                                                                                  \n",
      " k_block4b__0se_expand (Activat  (None, 1, 1, 480)   0           ['k_block4b__0se_expand_conv[0][0\n",
      " ion)                                                            ]']                              \n",
      "                                                                                                  \n",
      " k_block4b__0se_excite (Multipl  (None, 16, 16, 480)  0          ['k_block4b__0activation[0][0]', \n",
      " y)                                                               'k_block4b__0se_expand[0][0]']  \n",
      "                                                                                                  \n",
      " k_block4b__0project_conv_conv   (None, 16, 16, 80)  3840        ['k_block4b__0se_excite[0][0]']  \n",
      " (Conv2D)                                                                                         \n",
      "                                                                                                  \n",
      " k_block4b__0project_conv_bn (B  (None, 16, 16, 80)  320         ['k_block4b__0project_conv_conv[0\n",
      " atchNormalization)                                              ][0]']                           \n",
      "                                                                                                  \n",
      " k_block4b__0project_conv_group  (None, 16, 16, 80)  0           ['k_block4b__0project_conv_bn[0][\n",
      " _interleaved (InterleaveChanne                                  0]']                             \n",
      " ls)                                                                                              \n",
      "                                                                                                  \n",
      " k_block4b__0project_conv_group  (None, 16, 16, 80)  640         ['k_block4b__0project_conv_group_\n",
      " _interconn_conv (Conv2D)                                        interleaved[0][0]']              \n",
      "                                                                                                  \n",
      " k_block4b__0project_conv_group  (None, 16, 16, 80)  320         ['k_block4b__0project_conv_group_\n",
      " _interconn_bn (BatchNormalizat                                  interconn_conv[0][0]']           \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " k_block4b__0project_conv_inter  (None, 16, 16, 80)  0           ['k_block4b__0project_conv_group_\n",
      " _group_add (Add)                                                interconn_bn[0][0]',             \n",
      "                                                                  'k_block4b__0project_conv_bn[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " k_block4b__0drop (Dropout)     (None, 16, 16, 80)   0           ['k_block4b__0project_conv_inter_\n",
      "                                                                 group_add[0][0]']                \n",
      "                                                                                                  \n",
      " k_block4b__0add (Add)          (None, 16, 16, 80)   0           ['k_block4b__0drop[0][0]',       \n",
      "                                                                  'k_block4a__0project_conv_inter_\n",
      "                                                                 group_add[0][0]']                \n",
      "                                                                                                  \n",
      " k_block4c__0expand_conv (Conv2  (None, 16, 16, 480)  19200      ['k_block4b__0add[0][0]']        \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " k_block4c__0expand_bn (BatchNo  (None, 16, 16, 480)  1920       ['k_block4c__0expand_conv[0][0]']\n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " k_block4c__0expand (Activation  (None, 16, 16, 480)  0          ['k_block4c__0expand_bn[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " k_block4c__0expand_group_inter  (None, 16, 16, 480)  0          ['k_block4c__0expand[0][0]']     \n",
      " leaved (InterleaveChannels)                                                                      \n",
      "                                                                                                  \n",
      " k_block4c__0dwconv (DepthwiseC  (None, 16, 16, 480)  4320       ['k_block4c__0expand_group_interl\n",
      " onv2D)                                                          eaved[0][0]']                    \n",
      "                                                                                                  \n",
      " k_block4c__0bn (BatchNormaliza  (None, 16, 16, 480)  1920       ['k_block4c__0dwconv[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " k_block4c__0activation (Activa  (None, 16, 16, 480)  0          ['k_block4c__0bn[0][0]']         \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " k_block4c__0se_squeeze (Global  (None, 480)         0           ['k_block4c__0activation[0][0]'] \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " k_block4c__0se_reshape (Reshap  (None, 1, 1, 480)   0           ['k_block4c__0se_squeeze[0][0]'] \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " k_block4c__0se_reduce_conv (Co  (None, 1, 1, 20)    980         ['k_block4c__0se_reshape[0][0]'] \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " k_block4c__0se_reduce (Activat  (None, 1, 1, 20)    0           ['k_block4c__0se_reduce_conv[0][0\n",
      " ion)                                                            ]']                              \n",
      "                                                                                                  \n",
      " k_block4c__0se_reduce_group_in  (None, 1, 1, 20)    0           ['k_block4c__0se_reduce[0][0]']  \n",
      " terleaved (InterleaveChannels)                                                                   \n",
      "                                                                                                  \n",
      " k_block4c__0se_reduce_group_in  (None, 1, 1, 20)    60          ['k_block4c__0se_reduce_group_int\n",
      " terconn_conv (Conv2D)                                           erleaved[0][0]']                 \n",
      "                                                                                                  \n",
      " k_block4c__0se_reduce_group_in  (None, 1, 1, 20)    0           ['k_block4c__0se_reduce_group_int\n",
      " terconn (Activation)                                            erconn_conv[0][0]']              \n",
      "                                                                                                  \n",
      " k_block4c__0se_reduce_inter_gr  (None, 1, 1, 20)    0           ['k_block4c__0se_reduce_group_int\n",
      " oup_add (Add)                                                   erconn[0][0]',                   \n",
      "                                                                  'k_block4c__0se_reduce[0][0]']  \n",
      "                                                                                                  \n",
      " k_block4c__0se_expand_conv (Co  (None, 1, 1, 480)   10080       ['k_block4c__0se_reduce_inter_gro\n",
      " nv2D)                                                           up_add[0][0]']                   \n",
      "                                                                                                  \n",
      " k_block4c__0se_expand (Activat  (None, 1, 1, 480)   0           ['k_block4c__0se_expand_conv[0][0\n",
      " ion)                                                            ]']                              \n",
      "                                                                                                  \n",
      " k_block4c__0se_excite (Multipl  (None, 16, 16, 480)  0          ['k_block4c__0activation[0][0]', \n",
      " y)                                                               'k_block4c__0se_expand[0][0]']  \n",
      "                                                                                                  \n",
      " k_block4c__0project_conv_conv   (None, 16, 16, 80)  3840        ['k_block4c__0se_excite[0][0]']  \n",
      " (Conv2D)                                                                                         \n",
      "                                                                                                  \n",
      " k_block4c__0project_conv_bn (B  (None, 16, 16, 80)  320         ['k_block4c__0project_conv_conv[0\n",
      " atchNormalization)                                              ][0]']                           \n",
      "                                                                                                  \n",
      " k_block4c__0project_conv_group  (None, 16, 16, 80)  0           ['k_block4c__0project_conv_bn[0][\n",
      " _interleaved (InterleaveChanne                                  0]']                             \n",
      " ls)                                                                                              \n",
      "                                                                                                  \n",
      " k_block4c__0project_conv_group  (None, 16, 16, 80)  640         ['k_block4c__0project_conv_group_\n",
      " _interconn_conv (Conv2D)                                        interleaved[0][0]']              \n",
      "                                                                                                  \n",
      " k_block4c__0project_conv_group  (None, 16, 16, 80)  320         ['k_block4c__0project_conv_group_\n",
      " _interconn_bn (BatchNormalizat                                  interconn_conv[0][0]']           \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " k_block4c__0project_conv_inter  (None, 16, 16, 80)  0           ['k_block4c__0project_conv_group_\n",
      " _group_add (Add)                                                interconn_bn[0][0]',             \n",
      "                                                                  'k_block4c__0project_conv_bn[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " k_block4c__0drop (Dropout)     (None, 16, 16, 80)   0           ['k_block4c__0project_conv_inter_\n",
      "                                                                 group_add[0][0]']                \n",
      "                                                                                                  \n",
      " k_block4c__0add (Add)          (None, 16, 16, 80)   0           ['k_block4c__0drop[0][0]',       \n",
      "                                                                  'k_block4b__0add[0][0]']        \n",
      "                                                                                                  \n",
      " k_block5a__0expand_conv (Conv2  (None, 16, 16, 480)  19200      ['k_block4c__0add[0][0]']        \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " k_block5a__0expand_bn (BatchNo  (None, 16, 16, 480)  1920       ['k_block5a__0expand_conv[0][0]']\n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " k_block5a__0expand (Activation  (None, 16, 16, 480)  0          ['k_block5a__0expand_bn[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " k_block5a__0expand_group_inter  (None, 16, 16, 480)  0          ['k_block5a__0expand[0][0]']     \n",
      " leaved (InterleaveChannels)                                                                      \n",
      "                                                                                                  \n",
      " k_block5a__0dwconv (DepthwiseC  (None, 16, 16, 480)  12000      ['k_block5a__0expand_group_interl\n",
      " onv2D)                                                          eaved[0][0]']                    \n",
      "                                                                                                  \n",
      " k_block5a__0bn (BatchNormaliza  (None, 16, 16, 480)  1920       ['k_block5a__0dwconv[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " k_block5a__0activation (Activa  (None, 16, 16, 480)  0          ['k_block5a__0bn[0][0]']         \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " k_block5a__0se_squeeze (Global  (None, 480)         0           ['k_block5a__0activation[0][0]'] \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " k_block5a__0se_reshape (Reshap  (None, 1, 1, 480)   0           ['k_block5a__0se_squeeze[0][0]'] \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " k_block5a__0se_reduce_conv (Co  (None, 1, 1, 20)    980         ['k_block5a__0se_reshape[0][0]'] \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " k_block5a__0se_reduce (Activat  (None, 1, 1, 20)    0           ['k_block5a__0se_reduce_conv[0][0\n",
      " ion)                                                            ]']                              \n",
      "                                                                                                  \n",
      " k_block5a__0se_reduce_group_in  (None, 1, 1, 20)    0           ['k_block5a__0se_reduce[0][0]']  \n",
      " terleaved (InterleaveChannels)                                                                   \n",
      "                                                                                                  \n",
      " k_block5a__0se_reduce_group_in  (None, 1, 1, 20)    60          ['k_block5a__0se_reduce_group_int\n",
      " terconn_conv (Conv2D)                                           erleaved[0][0]']                 \n",
      "                                                                                                  \n",
      " k_block5a__0se_reduce_group_in  (None, 1, 1, 20)    0           ['k_block5a__0se_reduce_group_int\n",
      " terconn (Activation)                                            erconn_conv[0][0]']              \n",
      "                                                                                                  \n",
      " k_block5a__0se_reduce_inter_gr  (None, 1, 1, 20)    0           ['k_block5a__0se_reduce_group_int\n",
      " oup_add (Add)                                                   erconn[0][0]',                   \n",
      "                                                                  'k_block5a__0se_reduce[0][0]']  \n",
      "                                                                                                  \n",
      " k_block5a__0se_expand_conv (Co  (None, 1, 1, 480)   10080       ['k_block5a__0se_reduce_inter_gro\n",
      " nv2D)                                                           up_add[0][0]']                   \n",
      "                                                                                                  \n",
      " k_block5a__0se_expand (Activat  (None, 1, 1, 480)   0           ['k_block5a__0se_expand_conv[0][0\n",
      " ion)                                                            ]']                              \n",
      "                                                                                                  \n",
      " k_block5a__0se_excite (Multipl  (None, 16, 16, 480)  0          ['k_block5a__0activation[0][0]', \n",
      " y)                                                               'k_block5a__0se_expand[0][0]']  \n",
      "                                                                                                  \n",
      " k_block5a__0project_conv_conv   (None, 16, 16, 112)  6720       ['k_block5a__0se_excite[0][0]']  \n",
      " (Conv2D)                                                                                         \n",
      "                                                                                                  \n",
      " k_block5a__0project_conv_bn (B  (None, 16, 16, 112)  448        ['k_block5a__0project_conv_conv[0\n",
      " atchNormalization)                                              ][0]']                           \n",
      "                                                                                                  \n",
      " k_block5a__0project_conv_group  (None, 16, 16, 112)  0          ['k_block5a__0project_conv_bn[0][\n",
      " _interleaved (InterleaveChanne                                  0]']                             \n",
      " ls)                                                                                              \n",
      "                                                                                                  \n",
      " k_block5a__0project_conv_group  (None, 16, 16, 112)  1568       ['k_block5a__0project_conv_group_\n",
      " _interconn_conv (Conv2D)                                        interleaved[0][0]']              \n",
      "                                                                                                  \n",
      " k_block5a__0project_conv_group  (None, 16, 16, 112)  448        ['k_block5a__0project_conv_group_\n",
      " _interconn_bn (BatchNormalizat                                  interconn_conv[0][0]']           \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " k_block5a__0project_conv_inter  (None, 16, 16, 112)  0          ['k_block5a__0project_conv_group_\n",
      " _group_add (Add)                                                interconn_bn[0][0]',             \n",
      "                                                                  'k_block5a__0project_conv_bn[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " k_block5b__0expand_conv (Conv2  (None, 16, 16, 672)  37632      ['k_block5a__0project_conv_inter_\n",
      " D)                                                              group_add[0][0]']                \n",
      "                                                                                                  \n",
      " k_block5b__0expand_bn (BatchNo  (None, 16, 16, 672)  2688       ['k_block5b__0expand_conv[0][0]']\n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " k_block5b__0expand (Activation  (None, 16, 16, 672)  0          ['k_block5b__0expand_bn[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " k_block5b__0expand_group_inter  (None, 16, 16, 672)  0          ['k_block5b__0expand[0][0]']     \n",
      " leaved (InterleaveChannels)                                                                      \n",
      "                                                                                                  \n",
      " k_block5b__0dwconv (DepthwiseC  (None, 16, 16, 672)  16800      ['k_block5b__0expand_group_interl\n",
      " onv2D)                                                          eaved[0][0]']                    \n",
      "                                                                                                  \n",
      " k_block5b__0bn (BatchNormaliza  (None, 16, 16, 672)  2688       ['k_block5b__0dwconv[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " k_block5b__0activation (Activa  (None, 16, 16, 672)  0          ['k_block5b__0bn[0][0]']         \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " k_block5b__0se_squeeze (Global  (None, 672)         0           ['k_block5b__0activation[0][0]'] \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " k_block5b__0se_reshape (Reshap  (None, 1, 1, 672)   0           ['k_block5b__0se_squeeze[0][0]'] \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " k_block5b__0se_reduce_conv (Co  (None, 1, 1, 28)    1372        ['k_block5b__0se_reshape[0][0]'] \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " k_block5b__0se_reduce (Activat  (None, 1, 1, 28)    0           ['k_block5b__0se_reduce_conv[0][0\n",
      " ion)                                                            ]']                              \n",
      "                                                                                                  \n",
      " k_block5b__0se_reduce_group_in  (None, 1, 1, 28)    0           ['k_block5b__0se_reduce[0][0]']  \n",
      " terleaved (InterleaveChannels)                                                                   \n",
      "                                                                                                  \n",
      " k_block5b__0se_reduce_group_in  (None, 1, 1, 28)    84          ['k_block5b__0se_reduce_group_int\n",
      " terconn_conv (Conv2D)                                           erleaved[0][0]']                 \n",
      "                                                                                                  \n",
      " k_block5b__0se_reduce_group_in  (None, 1, 1, 28)    0           ['k_block5b__0se_reduce_group_int\n",
      " terconn (Activation)                                            erconn_conv[0][0]']              \n",
      "                                                                                                  \n",
      " k_block5b__0se_reduce_inter_gr  (None, 1, 1, 28)    0           ['k_block5b__0se_reduce_group_int\n",
      " oup_add (Add)                                                   erconn[0][0]',                   \n",
      "                                                                  'k_block5b__0se_reduce[0][0]']  \n",
      "                                                                                                  \n",
      " k_block5b__0se_expand_conv (Co  (None, 1, 1, 672)   19488       ['k_block5b__0se_reduce_inter_gro\n",
      " nv2D)                                                           up_add[0][0]']                   \n",
      "                                                                                                  \n",
      " k_block5b__0se_expand (Activat  (None, 1, 1, 672)   0           ['k_block5b__0se_expand_conv[0][0\n",
      " ion)                                                            ]']                              \n",
      "                                                                                                  \n",
      " k_block5b__0se_excite (Multipl  (None, 16, 16, 672)  0          ['k_block5b__0activation[0][0]', \n",
      " y)                                                               'k_block5b__0se_expand[0][0]']  \n",
      "                                                                                                  \n",
      " k_block5b__0project_conv_conv   (None, 16, 16, 112)  4704       ['k_block5b__0se_excite[0][0]']  \n",
      " (Conv2D)                                                                                         \n",
      "                                                                                                  \n",
      " k_block5b__0project_conv_bn (B  (None, 16, 16, 112)  448        ['k_block5b__0project_conv_conv[0\n",
      " atchNormalization)                                              ][0]']                           \n",
      "                                                                                                  \n",
      " k_block5b__0project_conv_group  (None, 16, 16, 112)  0          ['k_block5b__0project_conv_bn[0][\n",
      " _interleaved (InterleaveChanne                                  0]']                             \n",
      " ls)                                                                                              \n",
      "                                                                                                  \n",
      " k_block5b__0project_conv_group  (None, 16, 16, 112)  784        ['k_block5b__0project_conv_group_\n",
      " _interconn_conv (Conv2D)                                        interleaved[0][0]']              \n",
      "                                                                                                  \n",
      " k_block5b__0project_conv_group  (None, 16, 16, 112)  448        ['k_block5b__0project_conv_group_\n",
      " _interconn_bn (BatchNormalizat                                  interconn_conv[0][0]']           \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " k_block5b__0project_conv_inter  (None, 16, 16, 112)  0          ['k_block5b__0project_conv_group_\n",
      " _group_add (Add)                                                interconn_bn[0][0]',             \n",
      "                                                                  'k_block5b__0project_conv_bn[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " k_block5b__0drop (Dropout)     (None, 16, 16, 112)  0           ['k_block5b__0project_conv_inter_\n",
      "                                                                 group_add[0][0]']                \n",
      "                                                                                                  \n",
      " k_block5b__0add (Add)          (None, 16, 16, 112)  0           ['k_block5b__0drop[0][0]',       \n",
      "                                                                  'k_block5a__0project_conv_inter_\n",
      "                                                                 group_add[0][0]']                \n",
      "                                                                                                  \n",
      " k_block5c__0expand_conv (Conv2  (None, 16, 16, 672)  37632      ['k_block5b__0add[0][0]']        \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " k_block5c__0expand_bn (BatchNo  (None, 16, 16, 672)  2688       ['k_block5c__0expand_conv[0][0]']\n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " k_block5c__0expand (Activation  (None, 16, 16, 672)  0          ['k_block5c__0expand_bn[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " k_block5c__0expand_group_inter  (None, 16, 16, 672)  0          ['k_block5c__0expand[0][0]']     \n",
      " leaved (InterleaveChannels)                                                                      \n",
      "                                                                                                  \n",
      " k_block5c__0dwconv (DepthwiseC  (None, 16, 16, 672)  16800      ['k_block5c__0expand_group_interl\n",
      " onv2D)                                                          eaved[0][0]']                    \n",
      "                                                                                                  \n",
      " k_block5c__0bn (BatchNormaliza  (None, 16, 16, 672)  2688       ['k_block5c__0dwconv[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " k_block5c__0activation (Activa  (None, 16, 16, 672)  0          ['k_block5c__0bn[0][0]']         \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " k_block5c__0se_squeeze (Global  (None, 672)         0           ['k_block5c__0activation[0][0]'] \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " k_block5c__0se_reshape (Reshap  (None, 1, 1, 672)   0           ['k_block5c__0se_squeeze[0][0]'] \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " k_block5c__0se_reduce_conv (Co  (None, 1, 1, 28)    1372        ['k_block5c__0se_reshape[0][0]'] \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " k_block5c__0se_reduce (Activat  (None, 1, 1, 28)    0           ['k_block5c__0se_reduce_conv[0][0\n",
      " ion)                                                            ]']                              \n",
      "                                                                                                  \n",
      " k_block5c__0se_reduce_group_in  (None, 1, 1, 28)    0           ['k_block5c__0se_reduce[0][0]']  \n",
      " terleaved (InterleaveChannels)                                                                   \n",
      "                                                                                                  \n",
      " k_block5c__0se_reduce_group_in  (None, 1, 1, 28)    84          ['k_block5c__0se_reduce_group_int\n",
      " terconn_conv (Conv2D)                                           erleaved[0][0]']                 \n",
      "                                                                                                  \n",
      " k_block5c__0se_reduce_group_in  (None, 1, 1, 28)    0           ['k_block5c__0se_reduce_group_int\n",
      " terconn (Activation)                                            erconn_conv[0][0]']              \n",
      "                                                                                                  \n",
      " k_block5c__0se_reduce_inter_gr  (None, 1, 1, 28)    0           ['k_block5c__0se_reduce_group_int\n",
      " oup_add (Add)                                                   erconn[0][0]',                   \n",
      "                                                                  'k_block5c__0se_reduce[0][0]']  \n",
      "                                                                                                  \n",
      " k_block5c__0se_expand_conv (Co  (None, 1, 1, 672)   19488       ['k_block5c__0se_reduce_inter_gro\n",
      " nv2D)                                                           up_add[0][0]']                   \n",
      "                                                                                                  \n",
      " k_block5c__0se_expand (Activat  (None, 1, 1, 672)   0           ['k_block5c__0se_expand_conv[0][0\n",
      " ion)                                                            ]']                              \n",
      "                                                                                                  \n",
      " k_block5c__0se_excite (Multipl  (None, 16, 16, 672)  0          ['k_block5c__0activation[0][0]', \n",
      " y)                                                               'k_block5c__0se_expand[0][0]']  \n",
      "                                                                                                  \n",
      " k_block5c__0project_conv_conv   (None, 16, 16, 112)  4704       ['k_block5c__0se_excite[0][0]']  \n",
      " (Conv2D)                                                                                         \n",
      "                                                                                                  \n",
      " k_block5c__0project_conv_bn (B  (None, 16, 16, 112)  448        ['k_block5c__0project_conv_conv[0\n",
      " atchNormalization)                                              ][0]']                           \n",
      "                                                                                                  \n",
      " k_block5c__0project_conv_group  (None, 16, 16, 112)  0          ['k_block5c__0project_conv_bn[0][\n",
      " _interleaved (InterleaveChanne                                  0]']                             \n",
      " ls)                                                                                              \n",
      "                                                                                                  \n",
      " k_block5c__0project_conv_group  (None, 16, 16, 112)  784        ['k_block5c__0project_conv_group_\n",
      " _interconn_conv (Conv2D)                                        interleaved[0][0]']              \n",
      "                                                                                                  \n",
      " k_block5c__0project_conv_group  (None, 16, 16, 112)  448        ['k_block5c__0project_conv_group_\n",
      " _interconn_bn (BatchNormalizat                                  interconn_conv[0][0]']           \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " k_block5c__0project_conv_inter  (None, 16, 16, 112)  0          ['k_block5c__0project_conv_group_\n",
      " _group_add (Add)                                                interconn_bn[0][0]',             \n",
      "                                                                  'k_block5c__0project_conv_bn[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " k_block5c__0drop (Dropout)     (None, 16, 16, 112)  0           ['k_block5c__0project_conv_inter_\n",
      "                                                                 group_add[0][0]']                \n",
      "                                                                                                  \n",
      " k_block5c__0add (Add)          (None, 16, 16, 112)  0           ['k_block5c__0drop[0][0]',       \n",
      "                                                                  'k_block5b__0add[0][0]']        \n",
      "                                                                                                  \n",
      " k_block6a__0expand_conv (Conv2  (None, 16, 16, 672)  37632      ['k_block5c__0add[0][0]']        \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " k_block6a__0expand_bn (BatchNo  (None, 16, 16, 672)  2688       ['k_block6a__0expand_conv[0][0]']\n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " k_block6a__0expand (Activation  (None, 16, 16, 672)  0          ['k_block6a__0expand_bn[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " k_block6a__0expand_group_inter  (None, 16, 16, 672)  0          ['k_block6a__0expand[0][0]']     \n",
      " leaved (InterleaveChannels)                                                                      \n",
      "                                                                                                  \n",
      " k_block6a__0dwconv_pad (ZeroPa  (None, 19, 19, 672)  0          ['k_block6a__0expand_group_interl\n",
      " dding2D)                                                        eaved[0][0]']                    \n",
      "                                                                                                  \n",
      " k_block6a__0dwconv (DepthwiseC  (None, 8, 8, 672)   16800       ['k_block6a__0dwconv_pad[0][0]'] \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " k_block6a__0bn (BatchNormaliza  (None, 8, 8, 672)   2688        ['k_block6a__0dwconv[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " k_block6a__0activation (Activa  (None, 8, 8, 672)   0           ['k_block6a__0bn[0][0]']         \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " k_block6a__0se_squeeze (Global  (None, 672)         0           ['k_block6a__0activation[0][0]'] \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " k_block6a__0se_reshape (Reshap  (None, 1, 1, 672)   0           ['k_block6a__0se_squeeze[0][0]'] \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " k_block6a__0se_reduce_conv (Co  (None, 1, 1, 28)    1372        ['k_block6a__0se_reshape[0][0]'] \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " k_block6a__0se_reduce (Activat  (None, 1, 1, 28)    0           ['k_block6a__0se_reduce_conv[0][0\n",
      " ion)                                                            ]']                              \n",
      "                                                                                                  \n",
      " k_block6a__0se_reduce_group_in  (None, 1, 1, 28)    0           ['k_block6a__0se_reduce[0][0]']  \n",
      " terleaved (InterleaveChannels)                                                                   \n",
      "                                                                                                  \n",
      " k_block6a__0se_reduce_group_in  (None, 1, 1, 28)    84          ['k_block6a__0se_reduce_group_int\n",
      " terconn_conv (Conv2D)                                           erleaved[0][0]']                 \n",
      "                                                                                                  \n",
      " k_block6a__0se_reduce_group_in  (None, 1, 1, 28)    0           ['k_block6a__0se_reduce_group_int\n",
      " terconn (Activation)                                            erconn_conv[0][0]']              \n",
      "                                                                                                  \n",
      " k_block6a__0se_reduce_inter_gr  (None, 1, 1, 28)    0           ['k_block6a__0se_reduce_group_int\n",
      " oup_add (Add)                                                   erconn[0][0]',                   \n",
      "                                                                  'k_block6a__0se_reduce[0][0]']  \n",
      "                                                                                                  \n",
      " k_block6a__0se_expand_conv (Co  (None, 1, 1, 672)   19488       ['k_block6a__0se_reduce_inter_gro\n",
      " nv2D)                                                           up_add[0][0]']                   \n",
      "                                                                                                  \n",
      " k_block6a__0se_expand (Activat  (None, 1, 1, 672)   0           ['k_block6a__0se_expand_conv[0][0\n",
      " ion)                                                            ]']                              \n",
      "                                                                                                  \n",
      " k_block6a__0se_excite (Multipl  (None, 8, 8, 672)   0           ['k_block6a__0activation[0][0]', \n",
      " y)                                                               'k_block6a__0se_expand[0][0]']  \n",
      "                                                                                                  \n",
      " k_block6a__0project_conv_conv   (None, 8, 8, 192)   8064        ['k_block6a__0se_excite[0][0]']  \n",
      " (Conv2D)                                                                                         \n",
      "                                                                                                  \n",
      " k_block6a__0project_conv_bn (B  (None, 8, 8, 192)   768         ['k_block6a__0project_conv_conv[0\n",
      " atchNormalization)                                              ][0]']                           \n",
      "                                                                                                  \n",
      " k_block6a__0project_conv_group  (None, 8, 8, 192)   0           ['k_block6a__0project_conv_bn[0][\n",
      " _interleaved (InterleaveChanne                                  0]']                             \n",
      " ls)                                                                                              \n",
      "                                                                                                  \n",
      " k_block6a__0project_conv_group  (None, 8, 8, 192)   2304        ['k_block6a__0project_conv_group_\n",
      " _interconn_conv (Conv2D)                                        interleaved[0][0]']              \n",
      "                                                                                                  \n",
      " k_block6a__0project_conv_group  (None, 8, 8, 192)   768         ['k_block6a__0project_conv_group_\n",
      " _interconn_bn (BatchNormalizat                                  interconn_conv[0][0]']           \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " k_block6a__0project_conv_inter  (None, 8, 8, 192)   0           ['k_block6a__0project_conv_group_\n",
      " _group_add (Add)                                                interconn_bn[0][0]',             \n",
      "                                                                  'k_block6a__0project_conv_bn[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " k_block6b__0expand_conv (Conv2  (None, 8, 8, 1152)  36864       ['k_block6a__0project_conv_inter_\n",
      " D)                                                              group_add[0][0]']                \n",
      "                                                                                                  \n",
      " k_block6b__0expand_bn (BatchNo  (None, 8, 8, 1152)  4608        ['k_block6b__0expand_conv[0][0]']\n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " k_block6b__0expand (Activation  (None, 8, 8, 1152)  0           ['k_block6b__0expand_bn[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " k_block6b__0expand_group_inter  (None, 8, 8, 1152)  0           ['k_block6b__0expand[0][0]']     \n",
      " leaved (InterleaveChannels)                                                                      \n",
      "                                                                                                  \n",
      " k_block6b__0dwconv (DepthwiseC  (None, 8, 8, 1152)  28800       ['k_block6b__0expand_group_interl\n",
      " onv2D)                                                          eaved[0][0]']                    \n",
      "                                                                                                  \n",
      " k_block6b__0bn (BatchNormaliza  (None, 8, 8, 1152)  4608        ['k_block6b__0dwconv[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " k_block6b__0activation (Activa  (None, 8, 8, 1152)  0           ['k_block6b__0bn[0][0]']         \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " k_block6b__0se_squeeze (Global  (None, 1152)        0           ['k_block6b__0activation[0][0]'] \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " k_block6b__0se_reshape (Reshap  (None, 1, 1, 1152)  0           ['k_block6b__0se_squeeze[0][0]'] \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " k_block6b__0se_reduce_conv (Co  (None, 1, 1, 48)    2352        ['k_block6b__0se_reshape[0][0]'] \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " k_block6b__0se_reduce (Activat  (None, 1, 1, 48)    0           ['k_block6b__0se_reduce_conv[0][0\n",
      " ion)                                                            ]']                              \n",
      "                                                                                                  \n",
      " k_block6b__0se_reduce_group_in  (None, 1, 1, 48)    0           ['k_block6b__0se_reduce[0][0]']  \n",
      " terleaved (InterleaveChannels)                                                                   \n",
      "                                                                                                  \n",
      " k_block6b__0se_reduce_group_in  (None, 1, 1, 48)    144         ['k_block6b__0se_reduce_group_int\n",
      " terconn_conv (Conv2D)                                           erleaved[0][0]']                 \n",
      "                                                                                                  \n",
      " k_block6b__0se_reduce_group_in  (None, 1, 1, 48)    0           ['k_block6b__0se_reduce_group_int\n",
      " terconn (Activation)                                            erconn_conv[0][0]']              \n",
      "                                                                                                  \n",
      " k_block6b__0se_reduce_inter_gr  (None, 1, 1, 48)    0           ['k_block6b__0se_reduce_group_int\n",
      " oup_add (Add)                                                   erconn[0][0]',                   \n",
      "                                                                  'k_block6b__0se_reduce[0][0]']  \n",
      "                                                                                                  \n",
      " k_block6b__0se_expand_conv (Co  (None, 1, 1, 1152)  56448       ['k_block6b__0se_reduce_inter_gro\n",
      " nv2D)                                                           up_add[0][0]']                   \n",
      "                                                                                                  \n",
      " k_block6b__0se_expand (Activat  (None, 1, 1, 1152)  0           ['k_block6b__0se_expand_conv[0][0\n",
      " ion)                                                            ]']                              \n",
      "                                                                                                  \n",
      " k_block6b__0se_excite (Multipl  (None, 8, 8, 1152)  0           ['k_block6b__0activation[0][0]', \n",
      " y)                                                               'k_block6b__0se_expand[0][0]']  \n",
      "                                                                                                  \n",
      " k_block6b__0project_conv_conv   (None, 8, 8, 192)   6912        ['k_block6b__0se_excite[0][0]']  \n",
      " (Conv2D)                                                                                         \n",
      "                                                                                                  \n",
      " k_block6b__0project_conv_bn (B  (None, 8, 8, 192)   768         ['k_block6b__0project_conv_conv[0\n",
      " atchNormalization)                                              ][0]']                           \n",
      "                                                                                                  \n",
      " k_block6b__0project_conv_group  (None, 8, 8, 192)   0           ['k_block6b__0project_conv_bn[0][\n",
      " _interleaved (InterleaveChanne                                  0]']                             \n",
      " ls)                                                                                              \n",
      "                                                                                                  \n",
      " k_block6b__0project_conv_group  (None, 8, 8, 192)   1152        ['k_block6b__0project_conv_group_\n",
      " _interconn_conv (Conv2D)                                        interleaved[0][0]']              \n",
      "                                                                                                  \n",
      " k_block6b__0project_conv_group  (None, 8, 8, 192)   768         ['k_block6b__0project_conv_group_\n",
      " _interconn_bn (BatchNormalizat                                  interconn_conv[0][0]']           \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " k_block6b__0project_conv_inter  (None, 8, 8, 192)   0           ['k_block6b__0project_conv_group_\n",
      " _group_add (Add)                                                interconn_bn[0][0]',             \n",
      "                                                                  'k_block6b__0project_conv_bn[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " k_block6b__0drop (Dropout)     (None, 8, 8, 192)    0           ['k_block6b__0project_conv_inter_\n",
      "                                                                 group_add[0][0]']                \n",
      "                                                                                                  \n",
      " k_block6b__0add (Add)          (None, 8, 8, 192)    0           ['k_block6b__0drop[0][0]',       \n",
      "                                                                  'k_block6a__0project_conv_inter_\n",
      "                                                                 group_add[0][0]']                \n",
      "                                                                                                  \n",
      " k_block6c__0expand_conv (Conv2  (None, 8, 8, 1152)  36864       ['k_block6b__0add[0][0]']        \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " k_block6c__0expand_bn (BatchNo  (None, 8, 8, 1152)  4608        ['k_block6c__0expand_conv[0][0]']\n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " k_block6c__0expand (Activation  (None, 8, 8, 1152)  0           ['k_block6c__0expand_bn[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " k_block6c__0expand_group_inter  (None, 8, 8, 1152)  0           ['k_block6c__0expand[0][0]']     \n",
      " leaved (InterleaveChannels)                                                                      \n",
      "                                                                                                  \n",
      " k_block6c__0dwconv (DepthwiseC  (None, 8, 8, 1152)  28800       ['k_block6c__0expand_group_interl\n",
      " onv2D)                                                          eaved[0][0]']                    \n",
      "                                                                                                  \n",
      " k_block6c__0bn (BatchNormaliza  (None, 8, 8, 1152)  4608        ['k_block6c__0dwconv[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " k_block6c__0activation (Activa  (None, 8, 8, 1152)  0           ['k_block6c__0bn[0][0]']         \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " k_block6c__0se_squeeze (Global  (None, 1152)        0           ['k_block6c__0activation[0][0]'] \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " k_block6c__0se_reshape (Reshap  (None, 1, 1, 1152)  0           ['k_block6c__0se_squeeze[0][0]'] \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " k_block6c__0se_reduce_conv (Co  (None, 1, 1, 48)    2352        ['k_block6c__0se_reshape[0][0]'] \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " k_block6c__0se_reduce (Activat  (None, 1, 1, 48)    0           ['k_block6c__0se_reduce_conv[0][0\n",
      " ion)                                                            ]']                              \n",
      "                                                                                                  \n",
      " k_block6c__0se_reduce_group_in  (None, 1, 1, 48)    0           ['k_block6c__0se_reduce[0][0]']  \n",
      " terleaved (InterleaveChannels)                                                                   \n",
      "                                                                                                  \n",
      " k_block6c__0se_reduce_group_in  (None, 1, 1, 48)    144         ['k_block6c__0se_reduce_group_int\n",
      " terconn_conv (Conv2D)                                           erleaved[0][0]']                 \n",
      "                                                                                                  \n",
      " k_block6c__0se_reduce_group_in  (None, 1, 1, 48)    0           ['k_block6c__0se_reduce_group_int\n",
      " terconn (Activation)                                            erconn_conv[0][0]']              \n",
      "                                                                                                  \n",
      " k_block6c__0se_reduce_inter_gr  (None, 1, 1, 48)    0           ['k_block6c__0se_reduce_group_int\n",
      " oup_add (Add)                                                   erconn[0][0]',                   \n",
      "                                                                  'k_block6c__0se_reduce[0][0]']  \n",
      "                                                                                                  \n",
      " k_block6c__0se_expand_conv (Co  (None, 1, 1, 1152)  56448       ['k_block6c__0se_reduce_inter_gro\n",
      " nv2D)                                                           up_add[0][0]']                   \n",
      "                                                                                                  \n",
      " k_block6c__0se_expand (Activat  (None, 1, 1, 1152)  0           ['k_block6c__0se_expand_conv[0][0\n",
      " ion)                                                            ]']                              \n",
      "                                                                                                  \n",
      " k_block6c__0se_excite (Multipl  (None, 8, 8, 1152)  0           ['k_block6c__0activation[0][0]', \n",
      " y)                                                               'k_block6c__0se_expand[0][0]']  \n",
      "                                                                                                  \n",
      " k_block6c__0project_conv_conv   (None, 8, 8, 192)   6912        ['k_block6c__0se_excite[0][0]']  \n",
      " (Conv2D)                                                                                         \n",
      "                                                                                                  \n",
      " k_block6c__0project_conv_bn (B  (None, 8, 8, 192)   768         ['k_block6c__0project_conv_conv[0\n",
      " atchNormalization)                                              ][0]']                           \n",
      "                                                                                                  \n",
      " k_block6c__0project_conv_group  (None, 8, 8, 192)   0           ['k_block6c__0project_conv_bn[0][\n",
      " _interleaved (InterleaveChanne                                  0]']                             \n",
      " ls)                                                                                              \n",
      "                                                                                                  \n",
      " k_block6c__0project_conv_group  (None, 8, 8, 192)   1152        ['k_block6c__0project_conv_group_\n",
      " _interconn_conv (Conv2D)                                        interleaved[0][0]']              \n",
      "                                                                                                  \n",
      " k_block6c__0project_conv_group  (None, 8, 8, 192)   768         ['k_block6c__0project_conv_group_\n",
      " _interconn_bn (BatchNormalizat                                  interconn_conv[0][0]']           \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " k_block6c__0project_conv_inter  (None, 8, 8, 192)   0           ['k_block6c__0project_conv_group_\n",
      " _group_add (Add)                                                interconn_bn[0][0]',             \n",
      "                                                                  'k_block6c__0project_conv_bn[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " k_block6c__0drop (Dropout)     (None, 8, 8, 192)    0           ['k_block6c__0project_conv_inter_\n",
      "                                                                 group_add[0][0]']                \n",
      "                                                                                                  \n",
      " k_block6c__0add (Add)          (None, 8, 8, 192)    0           ['k_block6c__0drop[0][0]',       \n",
      "                                                                  'k_block6b__0add[0][0]']        \n",
      "                                                                                                  \n",
      " k_block6d__0expand_conv (Conv2  (None, 8, 8, 1152)  36864       ['k_block6c__0add[0][0]']        \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " k_block6d__0expand_bn (BatchNo  (None, 8, 8, 1152)  4608        ['k_block6d__0expand_conv[0][0]']\n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " k_block6d__0expand (Activation  (None, 8, 8, 1152)  0           ['k_block6d__0expand_bn[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " k_block6d__0expand_group_inter  (None, 8, 8, 1152)  0           ['k_block6d__0expand[0][0]']     \n",
      " leaved (InterleaveChannels)                                                                      \n",
      "                                                                                                  \n",
      " k_block6d__0dwconv (DepthwiseC  (None, 8, 8, 1152)  28800       ['k_block6d__0expand_group_interl\n",
      " onv2D)                                                          eaved[0][0]']                    \n",
      "                                                                                                  \n",
      " k_block6d__0bn (BatchNormaliza  (None, 8, 8, 1152)  4608        ['k_block6d__0dwconv[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " k_block6d__0activation (Activa  (None, 8, 8, 1152)  0           ['k_block6d__0bn[0][0]']         \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " k_block6d__0se_squeeze (Global  (None, 1152)        0           ['k_block6d__0activation[0][0]'] \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " k_block6d__0se_reshape (Reshap  (None, 1, 1, 1152)  0           ['k_block6d__0se_squeeze[0][0]'] \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " k_block6d__0se_reduce_conv (Co  (None, 1, 1, 48)    2352        ['k_block6d__0se_reshape[0][0]'] \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " k_block6d__0se_reduce (Activat  (None, 1, 1, 48)    0           ['k_block6d__0se_reduce_conv[0][0\n",
      " ion)                                                            ]']                              \n",
      "                                                                                                  \n",
      " k_block6d__0se_reduce_group_in  (None, 1, 1, 48)    0           ['k_block6d__0se_reduce[0][0]']  \n",
      " terleaved (InterleaveChannels)                                                                   \n",
      "                                                                                                  \n",
      " k_block6d__0se_reduce_group_in  (None, 1, 1, 48)    144         ['k_block6d__0se_reduce_group_int\n",
      " terconn_conv (Conv2D)                                           erleaved[0][0]']                 \n",
      "                                                                                                  \n",
      " k_block6d__0se_reduce_group_in  (None, 1, 1, 48)    0           ['k_block6d__0se_reduce_group_int\n",
      " terconn (Activation)                                            erconn_conv[0][0]']              \n",
      "                                                                                                  \n",
      " k_block6d__0se_reduce_inter_gr  (None, 1, 1, 48)    0           ['k_block6d__0se_reduce_group_int\n",
      " oup_add (Add)                                                   erconn[0][0]',                   \n",
      "                                                                  'k_block6d__0se_reduce[0][0]']  \n",
      "                                                                                                  \n",
      " k_block6d__0se_expand_conv (Co  (None, 1, 1, 1152)  56448       ['k_block6d__0se_reduce_inter_gro\n",
      " nv2D)                                                           up_add[0][0]']                   \n",
      "                                                                                                  \n",
      " k_block6d__0se_expand (Activat  (None, 1, 1, 1152)  0           ['k_block6d__0se_expand_conv[0][0\n",
      " ion)                                                            ]']                              \n",
      "                                                                                                  \n",
      " k_block6d__0se_excite (Multipl  (None, 8, 8, 1152)  0           ['k_block6d__0activation[0][0]', \n",
      " y)                                                               'k_block6d__0se_expand[0][0]']  \n",
      "                                                                                                  \n",
      " k_block6d__0project_conv_conv   (None, 8, 8, 192)   6912        ['k_block6d__0se_excite[0][0]']  \n",
      " (Conv2D)                                                                                         \n",
      "                                                                                                  \n",
      " k_block6d__0project_conv_bn (B  (None, 8, 8, 192)   768         ['k_block6d__0project_conv_conv[0\n",
      " atchNormalization)                                              ][0]']                           \n",
      "                                                                                                  \n",
      " k_block6d__0project_conv_group  (None, 8, 8, 192)   0           ['k_block6d__0project_conv_bn[0][\n",
      " _interleaved (InterleaveChanne                                  0]']                             \n",
      " ls)                                                                                              \n",
      "                                                                                                  \n",
      " k_block6d__0project_conv_group  (None, 8, 8, 192)   1152        ['k_block6d__0project_conv_group_\n",
      " _interconn_conv (Conv2D)                                        interleaved[0][0]']              \n",
      "                                                                                                  \n",
      " k_block6d__0project_conv_group  (None, 8, 8, 192)   768         ['k_block6d__0project_conv_group_\n",
      " _interconn_bn (BatchNormalizat                                  interconn_conv[0][0]']           \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " k_block6d__0project_conv_inter  (None, 8, 8, 192)   0           ['k_block6d__0project_conv_group_\n",
      " _group_add (Add)                                                interconn_bn[0][0]',             \n",
      "                                                                  'k_block6d__0project_conv_bn[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " k_block6d__0drop (Dropout)     (None, 8, 8, 192)    0           ['k_block6d__0project_conv_inter_\n",
      "                                                                 group_add[0][0]']                \n",
      "                                                                                                  \n",
      " k_block6d__0add (Add)          (None, 8, 8, 192)    0           ['k_block6d__0drop[0][0]',       \n",
      "                                                                  'k_block6c__0add[0][0]']        \n",
      "                                                                                                  \n",
      " k_block7a__0expand_conv (Conv2  (None, 8, 8, 1152)  36864       ['k_block6d__0add[0][0]']        \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " k_block7a__0expand_bn (BatchNo  (None, 8, 8, 1152)  4608        ['k_block7a__0expand_conv[0][0]']\n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " k_block7a__0expand (Activation  (None, 8, 8, 1152)  0           ['k_block7a__0expand_bn[0][0]']  \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " k_block7a__0expand_group_inter  (None, 8, 8, 1152)  0           ['k_block7a__0expand[0][0]']     \n",
      " leaved (InterleaveChannels)                                                                      \n",
      "                                                                                                  \n",
      " k_block7a__0dwconv (DepthwiseC  (None, 8, 8, 1152)  10368       ['k_block7a__0expand_group_interl\n",
      " onv2D)                                                          eaved[0][0]']                    \n",
      "                                                                                                  \n",
      " k_block7a__0bn (BatchNormaliza  (None, 8, 8, 1152)  4608        ['k_block7a__0dwconv[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " k_block7a__0activation (Activa  (None, 8, 8, 1152)  0           ['k_block7a__0bn[0][0]']         \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " k_block7a__0se_squeeze (Global  (None, 1152)        0           ['k_block7a__0activation[0][0]'] \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " k_block7a__0se_reshape (Reshap  (None, 1, 1, 1152)  0           ['k_block7a__0se_squeeze[0][0]'] \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " k_block7a__0se_reduce_conv (Co  (None, 1, 1, 48)    2352        ['k_block7a__0se_reshape[0][0]'] \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " k_block7a__0se_reduce (Activat  (None, 1, 1, 48)    0           ['k_block7a__0se_reduce_conv[0][0\n",
      " ion)                                                            ]']                              \n",
      "                                                                                                  \n",
      " k_block7a__0se_reduce_group_in  (None, 1, 1, 48)    0           ['k_block7a__0se_reduce[0][0]']  \n",
      " terleaved (InterleaveChannels)                                                                   \n",
      "                                                                                                  \n",
      " k_block7a__0se_reduce_group_in  (None, 1, 1, 48)    144         ['k_block7a__0se_reduce_group_int\n",
      " terconn_conv (Conv2D)                                           erleaved[0][0]']                 \n",
      "                                                                                                  \n",
      " k_block7a__0se_reduce_group_in  (None, 1, 1, 48)    0           ['k_block7a__0se_reduce_group_int\n",
      " terconn (Activation)                                            erconn_conv[0][0]']              \n",
      "                                                                                                  \n",
      " k_block7a__0se_reduce_inter_gr  (None, 1, 1, 48)    0           ['k_block7a__0se_reduce_group_int\n",
      " oup_add (Add)                                                   erconn[0][0]',                   \n",
      "                                                                  'k_block7a__0se_reduce[0][0]']  \n",
      "                                                                                                  \n",
      " k_block7a__0se_expand_conv (Co  (None, 1, 1, 1152)  56448       ['k_block7a__0se_reduce_inter_gro\n",
      " nv2D)                                                           up_add[0][0]']                   \n",
      "                                                                                                  \n",
      " k_block7a__0se_expand (Activat  (None, 1, 1, 1152)  0           ['k_block7a__0se_expand_conv[0][0\n",
      " ion)                                                            ]']                              \n",
      "                                                                                                  \n",
      " k_block7a__0se_excite (Multipl  (None, 8, 8, 1152)  0           ['k_block7a__0activation[0][0]', \n",
      " y)                                                               'k_block7a__0se_expand[0][0]']  \n",
      "                                                                                                  \n",
      " k_block7a__0project_conv_conv   (None, 8, 8, 320)   11520       ['k_block7a__0se_excite[0][0]']  \n",
      " (Conv2D)                                                                                         \n",
      "                                                                                                  \n",
      " k_block7a__0project_conv_bn (B  (None, 8, 8, 320)   1280        ['k_block7a__0project_conv_conv[0\n",
      " atchNormalization)                                              ][0]']                           \n",
      "                                                                                                  \n",
      " k_block7a__0project_conv_group  (None, 8, 8, 320)   0           ['k_block7a__0project_conv_bn[0][\n",
      " _interleaved (InterleaveChanne                                  0]']                             \n",
      " ls)                                                                                              \n",
      "                                                                                                  \n",
      " k_block7a__0project_conv_group  (None, 8, 8, 320)   3200        ['k_block7a__0project_conv_group_\n",
      " _interconn_conv (Conv2D)                                        interleaved[0][0]']              \n",
      "                                                                                                  \n",
      " k_block7a__0project_conv_group  (None, 8, 8, 320)   1280        ['k_block7a__0project_conv_group_\n",
      " _interconn_bn (BatchNormalizat                                  interconn_conv[0][0]']           \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " k_block7a__0project_conv_inter  (None, 8, 8, 320)   0           ['k_block7a__0project_conv_group_\n",
      " _group_add (Add)                                                interconn_bn[0][0]',             \n",
      "                                                                  'k_block7a__0project_conv_bn[0][\n",
      "                                                                 0]']                             \n",
      "                                                                                                  \n",
      " k_top_conv_conv (Conv2D)       (None, 8, 8, 1280)   40960       ['k_block7a__0project_conv_inter_\n",
      "                                                                 group_add[0][0]']                \n",
      "                                                                                                  \n",
      " k_top_conv_bn (BatchNormalizat  (None, 8, 8, 1280)  5120        ['k_top_conv_conv[0][0]']        \n",
      " ion)                                                                                             \n",
      "                                                                                                  \n",
      " k_top_conv_group_interleaved (  (None, 8, 8, 1280)  0           ['k_top_conv_bn[0][0]']          \n",
      " InterleaveChannels)                                                                              \n",
      "                                                                                                  \n",
      " k_top_dropout (Dropout)        (None, 8, 8, 1280)   0           ['k_top_conv_group_interleaved[0]\n",
      "                                                                 [0]']                            \n",
      "                                                                                                  \n",
      " k_probs (Dense)                (None, 8, 8, 1000)   1281000     ['k_top_dropout[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,372,416\n",
      "Trainable params: 2,326,816\n",
      "Non-trainable params: 45,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "k.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def work_on_efficientnet(show_model=False, run_fit=False, test_results=False, calc_f1=False):\n",
    "    monitor='val_accuracy'\n",
    "    if (calc_f1): \n",
    "        test_results=True\n",
    "    if (show_model):\n",
    "        input_shape = (target_size_x, target_size_y, 3)\n",
    "    else:\n",
    "        input_shape = (None, None, 3)\n",
    "    for kType in [cai.layers.D6v3_16ch(), cai.layers.D6v3_32ch()]: #\n",
    "        basefilename = '/content/drive/MyDrive/output/JP30I02-EfficientNet-CIFAR10-'+str(kType)\n",
    "        best_result_file_name = basefilename+'-best_result.hdf5'\n",
    "        print('Running: '+basefilename)\n",
    "        model = cai.efficientnet.kEfficientNetB0(\n",
    "            include_top=True,\n",
    "            skip_stride_cnt=3,\n",
    "            input_shape=input_shape,\n",
    "            classes=num_classes,\n",
    "            kType=kType)\n",
    "        \n",
    "        optimizer = keras.optimizers.RMSprop()\n",
    "        optimizer = mixed_precision.LossScaleOptimizer(optimizer)\n",
    "        model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        if (show_model): \n",
    "            model.summary(line_length=180)\n",
    "            print('model flops:',get_flops(model))\n",
    "\n",
    "        save_best = keras.callbacks.ModelCheckpoint(\n",
    "                filepath=best_result_file_name,\n",
    "                monitor=monitor,\n",
    "                verbose=1,\n",
    "                save_best_only=True,\n",
    "                save_weights_only=False,\n",
    "                mode='max',\n",
    "                save_freq='epoch')\n",
    "\n",
    "        if (run_fit): \n",
    "                train_flow = train_datagen.flow(\n",
    "                    x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    seed=seed,\n",
    "                    subset='training'\n",
    "                )\n",
    "                validation_flow = train_datagen.flow(\n",
    "                    x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=True,\n",
    "                    seed=seed,\n",
    "                    subset='validation'\n",
    "                )\n",
    "                history = model.fit(\n",
    "                x = train_flow,\n",
    "                epochs=epochs,\n",
    "                batch_size=batch_size,\n",
    "                validation_data=validation_flow,\n",
    "                callbacks=[save_best, tf.keras.callbacks.LearningRateScheduler(cyclical_adv_lrscheduler25)],\n",
    "                workers=cpus_num,\n",
    "                max_queue_size=128\n",
    "                )\n",
    "                plt.figure()\n",
    "                plt.ylabel(\"Accuracy (training and validation)\")\n",
    "                plt.xlabel(\"Epochs\")\n",
    "                plt.ylim([0,1])\n",
    "                plt.plot(history.history[\"accuracy\"])\n",
    "                plt.plot(history.history[\"val_accuracy\"])\n",
    "        if (test_results):\n",
    "            test_flow = test_datagen.flow(\n",
    "                x_test, y_test,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                seed=seed\n",
    "            )\n",
    "            print('Best Model Results: '+best_result_file_name)\n",
    "            model = cai.models.load_kereas_model(best_result_file_name)\n",
    "            evaluated = model.evaluate(\n",
    "                x=test_flow,\n",
    "                batch_size=batch_size,\n",
    "                use_multiprocessing=False,\n",
    "                workers=cpus_num\n",
    "            )\n",
    "            for metric, name in zip(evaluated,[\"loss\",\"acc\"]):\n",
    "                print(name,metric)\n",
    "        if (calc_f1):\n",
    "            model = cai.models.load_kereas_model(best_result_file_name)\n",
    "            pred_y = model.predict(x_test)\n",
    "            print(\"Predicted Shape:\", pred_y.shape)\n",
    "            pred_classes_y = np.array(list(np.argmax(pred_y, axis=1)))\n",
    "            test_classes_y = np.array(list(np.argmax(y_test, axis=1)))\n",
    "            print(\"Pred classes shape:\",pred_classes_y.shape)\n",
    "            print(\"Test classes shape:\",test_classes_y.shape)\n",
    "            report = classification_report(test_classes_y, pred_classes_y, digits=4)\n",
    "            print(report)\n",
    "        print('Finished: '+basefilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if channels_per_group==2:\n",
    "   kTypes = [cai.layers.D6v3_2ch()]\n",
    "elif channels_per_group==4:\n",
    "   kTypes = [cai.layers.D6v3_4ch()]\n",
    "elif channels_per_group==8:\n",
    "   kTypes = [cai.layers.D6v3_8ch()]\n",
    "elif channels_per_group==12:\n",
    "   kTypes = [cai.layers.D6v3_12ch()]\n",
    "elif channels_per_group==16:\n",
    "   kTypes = [cai.layers.D6v3_16ch()]\n",
    "else:\n",
    "   kTypes = [cai.layers.D6v3_32ch()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
