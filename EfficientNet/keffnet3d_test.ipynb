{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Global Settings\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.layers\n",
    "import tensorflow.keras.models\n",
    "import tensorflow.keras.datasets\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/hasibzunair/3D-image-classification-tutorial/releases/download/v0.2/CT-0.zip\n",
      "1065471431/1065471431 [==============================] - 526s 0us/step\n",
      "Downloading data from https://github.com/hasibzunair/3D-image-classification-tutorial/releases/download/v0.2/CT-23.zip\n",
      "1045162547/1045162547 [==============================] - 626s 1us/step\n"
     ]
    }
   ],
   "source": [
    "url = \"https://github.com/hasibzunair/3D-image-classification-tutorial/releases/download/v0.2/CT-0.zip\"\n",
    "filename = os.path.join(os.getcwd(), \"CT-0.zip\")\n",
    "keras.utils.get_file(filename, url)\n",
    "\n",
    "# Download url of abnormal CT scans.\n",
    "url = \"https://github.com/hasibzunair/3D-image-classification-tutorial/releases/download/v0.2/CT-23.zip\"\n",
    "filename = os.path.join(os.getcwd(), \"CT-23.zip\")\n",
    "keras.utils.get_file(filename, url)\n",
    "\n",
    "# Make a directory to store the data.\n",
    "os.makedirs(\"MosMedData\")\n",
    "\n",
    "# Unzip data in the newly created directory.\n",
    "with zipfile.ZipFile(\"CT-0.zip\", \"r\") as z_fp:\n",
    "    z_fp.extractall(\"./MosMedData/\")\n",
    "\n",
    "with zipfile.ZipFile(\"CT-23.zip\", \"r\") as z_fp:\n",
    "    z_fp.extractall(\"./MosMedData/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "\n",
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "def read_nifti_file(filepath):\n",
    "    \"\"\"Read and load volume\"\"\"\n",
    "    # Read file\n",
    "    scan = nib.load(filepath)\n",
    "    # Get raw data\n",
    "    scan = scan.get_fdata()\n",
    "    return scan\n",
    "\n",
    "\n",
    "def normalize(volume):\n",
    "    \"\"\"Normalize the volume\"\"\"\n",
    "    min = -1000\n",
    "    max = 400\n",
    "    volume[volume < min] = min\n",
    "    volume[volume > max] = max\n",
    "    volume = (volume - min) / (max - min)\n",
    "    volume = volume.astype(\"float32\")\n",
    "    return volume\n",
    "\n",
    "\n",
    "def resize_volume(img):\n",
    "    \"\"\"Resize across z-axis\"\"\"\n",
    "    # Set the desired depth\n",
    "    desired_depth = 64\n",
    "    desired_width = 128\n",
    "    desired_height = 128\n",
    "    # Get current depth\n",
    "    current_depth = img.shape[-1]\n",
    "    current_width = img.shape[0]\n",
    "    current_height = img.shape[1]\n",
    "    # Compute depth factor\n",
    "    depth = current_depth / desired_depth\n",
    "    width = current_width / desired_width\n",
    "    height = current_height / desired_height\n",
    "    depth_factor = 1 / depth\n",
    "    width_factor = 1 / width\n",
    "    height_factor = 1 / height\n",
    "    # Rotate\n",
    "    img = ndimage.rotate(img, 90, reshape=False)\n",
    "    # Resize across z-axis\n",
    "    img = ndimage.zoom(img, (width_factor, height_factor, depth_factor), order=1)\n",
    "    return img\n",
    "\n",
    "\n",
    "def process_scan(path):\n",
    "    \"\"\"Read and resize volume\"\"\"\n",
    "    # Read scan\n",
    "    volume = read_nifti_file(path)\n",
    "    # Normalize\n",
    "    volume = normalize(volume)\n",
    "    # Resize width, height and depth\n",
    "    volume = resize_volume(volume)\n",
    "    return volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge nibabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CT scans with normal lung tissue: 100\n",
      "CT scans with abnormal lung tissue: 100\n"
     ]
    }
   ],
   "source": [
    "# Folder \"CT-0\" consist of CT scans having normal lung tissue,\n",
    "# no CT-signs of viral pneumonia.\n",
    "normal_scan_paths = [\n",
    "    os.path.join(os.getcwd(), \"MosMedData/CT-0\", x)\n",
    "    for x in os.listdir(\"MosMedData/CT-0\")\n",
    "]\n",
    "# Folder \"CT-23\" consist of CT scans having several ground-glass opacifications,\n",
    "# involvement of lung parenchyma.\n",
    "abnormal_scan_paths = [\n",
    "    os.path.join(os.getcwd(), \"MosMedData/CT-23\", x)\n",
    "    for x in os.listdir(\"MosMedData/CT-23\")\n",
    "]\n",
    "\n",
    "print(\"CT scans with normal lung tissue: \" + str(len(normal_scan_paths)))\n",
    "print(\"CT scans with abnormal lung tissue: \" + str(len(abnormal_scan_paths)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in train and validation are 140 and 40.\n"
     ]
    }
   ],
   "source": [
    "# Read and process the scans.\n",
    "# Each scan is resized across height, width, and depth and rescaled.\n",
    "abnormal_scans = np.array([process_scan(path) for path in abnormal_scan_paths])\n",
    "normal_scans = np.array([process_scan(path) for path in normal_scan_paths])\n",
    "\n",
    "# For the CT scans having presence of viral pneumonia\n",
    "# assign 1, for the normal ones assign 0.\n",
    "abnormal_labels = np.array([1 for _ in range(len(abnormal_scans))])\n",
    "normal_labels = np.array([0 for _ in range(len(normal_scans))])\n",
    "\n",
    "# Split data in the ratio 70-30 for training and validation.\n",
    "X_train = np.concatenate((abnormal_scans[:70], normal_scans[:70]), axis=0)\n",
    "y_train = np.concatenate((abnormal_labels[:70], normal_labels[:70]), axis=0)\n",
    "X_val = np.concatenate((abnormal_scans[70:90], normal_scans[70:90]), axis=0)\n",
    "y_val = np.concatenate((abnormal_labels[70:90], normal_labels[70:90]), axis=0)\n",
    "X_test = np.concatenate((abnormal_scans[90:], normal_scans[90:]), axis=0)\n",
    "y_test = np.concatenate((abnormal_labels[90:], normal_labels[90:]), axis=0)\n",
    "print(\"Number of samples in train and validation are %d and %d.\" % (X_train.shape[0], X_val.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#dataset=tensorflow.keras.datasets.cifar10 #@param [\"tensorflow.keras.datasets.cifar10\", \"tensorflow.keras.datasets.cifar100\", \"tensorflow.keras.datasets.mnist\", \"tensorflow.keras.datasets.fashion_mnist\"] {type:\"raw\"} \n",
    "batch_size=64 # @param [16, 32, 64, 128, 256, 512] {type:\"raw\"} \n",
    "channels_per_group=32 # @param [2, 4, 8, 12, 16, 32] {type:\"raw\"}\n",
    "epochs=50 # @param [2, 25, 50, 75, 100, 100, 200, 400] {type:\"raw\"}\n",
    "verbose=True #@param {type:\"boolean\"}\n",
    "bipolar_input=True #@param {type:\"boolean\"}\n",
    "seed=7\n",
    "\n",
    "global_input_shape = (128, 128, 64, 1)\n",
    "\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.12.0\n",
      "Keras version: 2.12.0\n",
      "CPU cores: 8\n",
      "RAM: 16.859602944 GB\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import cai.layers\n",
    "import cai.datasets\n",
    "import cai.efficientnet\n",
    "import cai.util\n",
    "import gc\n",
    "import multiprocessing\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "print(\"Tensorflow version:\", tf.version.VERSION)\n",
    "print(\"Keras version:\", keras.__version__)\n",
    "print(\"CPU cores:\", multiprocessing.cpu_count())\n",
    "import psutil\n",
    "print('RAM:', (psutil.virtual_memory().total / 1e9),'GB')\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if channels_per_group==2:\n",
    "   kTypes = [cai.layers.D6v3_2ch()]\n",
    "elif channels_per_group==4:\n",
    "   kTypes = [cai.layers.D6v3_4ch()]\n",
    "elif channels_per_group==8:\n",
    "   kTypes = [cai.layers.D6v3_8ch()]\n",
    "elif channels_per_group==12:\n",
    "   kTypes = [cai.layers.D6v3_12ch()]\n",
    "elif channels_per_group==16:\n",
    "   kTypes = [cai.layers.D6v3_16ch()]\n",
    "else:\n",
    "   kTypes = [cai.layers.D6v3_32ch()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shapes: (140, 128, 128, 64) (140,)\n",
      "Validation shapes: (40, 128, 128, 64) (40,)\n",
      "Test shapes: (20, 128, 128, 64) (20,)\n"
     ]
    }
   ],
   "source": [
    "base_model_name='kEffNet3DV2_test'\n",
    "\n",
    "#x_train, y_train, x_val, y_val, x_test, y_test = cai.datasets.load_dataset_with_validation(dataset,\n",
    "#  lab=False, verbose=verbose, bipolar=bipolar_input,\n",
    "#  base_model_name=base_model_name,\n",
    "#  validation_size=0.1, validation_flip_horizontal=True,\n",
    "#  validation_flip_vertical=False)\n",
    "\n",
    "print(\"Train shapes:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation shapes:\", X_val.shape, y_val.shape)\n",
    "print(\"Test shapes:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val   =   X_val.reshape(40, 128, 128, 64, 1)  \n",
    "X_test  =  X_test.reshape(20, 128, 128, 64, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(140, 128, 128, 64, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_datagen = cai.util.create_image_generator(rotation_range=20, \n",
    "#  width_shift_range=0.3, height_shift_range=0.3, channel_shift_range=0.0)\n",
    "#valid_datagen = cai.util.create_image_generator_no_augmentation()\n",
    "#test_datagen = cai.util.create_image_generator_no_augmentation()\n",
    "cpus_num = max([multiprocessing.cpu_count(), 8])\n",
    "\n",
    "def cyclical_adv_lrscheduler25(epoch):\n",
    "    \"\"\"CAI Cyclical and Advanced Learning Rate Scheduler.\n",
    "    # Arguments\n",
    "        epoch: integer with current epoch count.\n",
    "    # Returns\n",
    "        float with desired learning rate.\n",
    "    \"\"\"\n",
    "    base_learning = 0.001\n",
    "    local_epoch = epoch % 25\n",
    "    if local_epoch < 7:\n",
    "       return base_learning * (1 + 0.5*local_epoch)\n",
    "    else:\n",
    "       return (base_learning * 4) * ( 0.85**(local_epoch-7) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def work_on_efficientnet(show_model=False, run_fit=False, test_results=False, calc_f1=False, kTypes=[]):\n",
    "  monitor='val_loss'\n",
    "  if (show_model):\n",
    "    input_shape = global_input_shape\n",
    "  else:\n",
    "    input_shape = (None, None, global_input_shape[2])\n",
    "  for kType in kTypes:\n",
    "      basefilename = 'kEffNetV2-'+str(kType)\n",
    "      best_result_file_name = basefilename+'-best_result.hdf5'\n",
    "      print('Running: '+basefilename)\n",
    "      model = cai.efficientnet.kEfficientNetB0(\n",
    "        include_top=True,\n",
    "        skip_stride_cnt=3,\n",
    "        input_shape=input_shape,\n",
    "        classes=num_classes,\n",
    "        kType=kType)\n",
    "      \n",
    "      optimizer = keras.optimizers.RMSprop()\n",
    "      model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=optimizer,\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "      if (show_model): \n",
    "        model.summary(line_length=180)\n",
    "\n",
    "      save_best = keras.callbacks.ModelCheckpoint(\n",
    "            filepath=best_result_file_name,\n",
    "            monitor=monitor,\n",
    "            verbose=1,\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False,\n",
    "            mode='min',\n",
    "            save_freq='epoch')\n",
    "\n",
    "      if (run_fit): \n",
    "            train_flow = train_datagen.flow(\n",
    "                X_train, y_train,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                seed=seed\n",
    "            )\n",
    "            validation_flow = valid_datagen.flow(\n",
    "                X_val, y_val,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=False,\n",
    "                seed=seed\n",
    "            )\n",
    "            history = model.fit(\n",
    "              x = train_flow,\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=validation_flow,\n",
    "              callbacks=[save_best, tf.keras.callbacks.LearningRateScheduler(cyclical_adv_lrscheduler25)],\n",
    "              workers=cpus_num,\n",
    "              max_queue_size=128\n",
    "            )\n",
    "            plt.figure()\n",
    "            plt.ylabel(\"Accuracy (training and validation)\")\n",
    "            plt.xlabel(\"Epochs\")\n",
    "            plt.ylim([0,1])\n",
    "            plt.plot(history.history[\"accuracy\"])\n",
    "            plt.plot(history.history[\"val_accuracy\"])\n",
    "      if (test_results):\n",
    "        test_flow = test_datagen.flow(\n",
    "            X_test, y_test,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            seed=seed\n",
    "        )\n",
    "        print('Best Model Results: '+best_result_file_name)\n",
    "        model = cai.models.load_kereas_model(best_result_file_name)\n",
    "        evaluated = model.evaluate(\n",
    "            x=test_flow,\n",
    "            batch_size=batch_size,\n",
    "            use_multiprocessing=False,\n",
    "            workers=cpus_num\n",
    "        )\n",
    "        for metric, name in zip(evaluated,[\"loss\",\"acc\"]):\n",
    "              print(name,metric)\n",
    "      if (calc_f1):\n",
    "        cai.datasets.test_flips_on_saved_model(X_test, y_test, best_result_file_name, has_flip_x=True, has_flip_y=True, has_bw=False, center_crop=0.15)\n",
    "      print('Finished: '+basefilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
